{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DSC540_FinalProject_AlexTeboul.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8sZ5WL2bmW8"
      },
      "source": [
        "#Final Project\n",
        "#DSC 540: Advanced Machine Learning\n",
        "**Author**: Alex Teboul\n",
        "\n",
        "**Professor**: Casey Bennett\n",
        "\n",
        "**Data Source**: https://www.kaggle.com/cdc/behavioral-risk-factor-surveillance-system#2015.csv\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c72z2O41f6wh"
      },
      "source": [
        "## About this Project\n",
        "\n",
        "**Objective:** The goal of this project was to build predicitve models for coronary heart disease using the 2015 BRFSS dataset. This project follows the processes and algorithms explored in DePaul University graduate course DSC 540: Advanced Machine Learning with professor Casey Bennett. In this Google Colab notebook, I go through the process of getting the 2015 BRFSS dataset, selecting features for exploration in my predictive models based irisk factors identified in past heart disease research, exploratory data analysis, model testing, and reporting on results. Methods explored in this notebook are: Random Forests, Gradient Boosting, AdaBoost, and Neural Networks.\n",
        "\n",
        "\n",
        "1.   **Part 1:** Getting and Cleaning the Data\n",
        "*   Get the BRFSS dataset from my local google drive\n",
        "*   Select a Relevant Subset of Features\n",
        "*   Cleaning the Data (Missing Values, Modifying Values, Make Feature Names More Readable, Save Finalized Dataset to CSV)\n",
        "2.   **Part 2:** Model Building\n",
        "\n",
        "Random Forests\n",
        "*   Random Forest - w/ Feature Selection - Full Dataset\n",
        "*   Random Forest - w/o Feature Selection - Full Dataset\n",
        "*   Random Forest - w/ and w/o Feature Selection - 50-50 Balanced Dataset\n",
        "*   Random Forest - w/ Feature Selection - 60-40 Balanced Dataset\n",
        "\n",
        "AdaBoost, GradientBoost, and Neural Networks\n",
        "*   AdaBoost, GradientBoost, and Neural Network - w/o Feature Selection - Full Dataset\n",
        "*   AdaBoost, GradientBoost, and Neural Network - w/ Feature Selection - Full Dataset\n",
        "*   AdaBoost, GradientBoost, and Neural Network - w/ Feature Selection - 50-50 Dataset\n",
        "*   AdaBoost, GradientBoost, and Neural Network - w/ Feature Selection - 60-40 Dataset\n",
        "\n",
        "Support Vector Machines: *Too Slow - Never Finishes\n",
        "*   RBF-SVM - w/ Feature Selection 50-50 Dataset\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7VcNFOPgClc"
      },
      "source": [
        "#Part 1: Getting and Cleaning the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcigkoPhfb7Z"
      },
      "source": [
        "#imports\n",
        "import pandas as pd\n",
        "import random\n",
        "random.seed(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttwQ5OG4e1yg"
      },
      "source": [
        "###Get the BRFSS dataset from my local google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Od7T6A_eX04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "57db021a-102f-47f7-bd72-ca5f270f8b55"
      },
      "source": [
        "#connect to my local google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dxD5-vBe9c_"
      },
      "source": [
        "#read in the dataset\n",
        "brfss_2015_dataset_source = '/content/drive/My Drive/DSC 540: Advanced Machine Learning/2015_BRFSS.csv'\n",
        "brfss_2015_dataset = pd.read_csv(brfss_2015_dataset_source)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avOmAS86gj-E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4c74328f-bee8-4ad5-bce6-21a45aab1724"
      },
      "source": [
        "#check that all the data loaded in\n",
        "brfss_2015_dataset.shape\n",
        "\n",
        "#Start with 444,456 records and 330 features. Each record is an individual's responses to the survey."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(441456, 330)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oe_IWsqnhRjC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "ed00e572-26b5-49e0-e111-b86ca083d4d2"
      },
      "source": [
        "#check that the data loaded in is in the correct format\n",
        "pd.set_option('display.max_columns', 500)\n",
        "brfss_2015_dataset.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>_STATE</th>\n",
              "      <th>FMONTH</th>\n",
              "      <th>IDATE</th>\n",
              "      <th>IMONTH</th>\n",
              "      <th>IDAY</th>\n",
              "      <th>IYEAR</th>\n",
              "      <th>DISPCODE</th>\n",
              "      <th>SEQNO</th>\n",
              "      <th>_PSU</th>\n",
              "      <th>CTELENUM</th>\n",
              "      <th>PVTRESD1</th>\n",
              "      <th>COLGHOUS</th>\n",
              "      <th>STATERES</th>\n",
              "      <th>CELLFON3</th>\n",
              "      <th>LADULT</th>\n",
              "      <th>NUMADULT</th>\n",
              "      <th>NUMMEN</th>\n",
              "      <th>NUMWOMEN</th>\n",
              "      <th>CTELNUM1</th>\n",
              "      <th>CELLFON2</th>\n",
              "      <th>CADULT</th>\n",
              "      <th>PVTRESD2</th>\n",
              "      <th>CCLGHOUS</th>\n",
              "      <th>CSTATE</th>\n",
              "      <th>LANDLINE</th>\n",
              "      <th>HHADULT</th>\n",
              "      <th>GENHLTH</th>\n",
              "      <th>PHYSHLTH</th>\n",
              "      <th>MENTHLTH</th>\n",
              "      <th>POORHLTH</th>\n",
              "      <th>HLTHPLN1</th>\n",
              "      <th>PERSDOC2</th>\n",
              "      <th>MEDCOST</th>\n",
              "      <th>CHECKUP1</th>\n",
              "      <th>BPHIGH4</th>\n",
              "      <th>BPMEDS</th>\n",
              "      <th>BLOODCHO</th>\n",
              "      <th>CHOLCHK</th>\n",
              "      <th>TOLDHI2</th>\n",
              "      <th>CVDINFR4</th>\n",
              "      <th>CVDCRHD4</th>\n",
              "      <th>CVDSTRK3</th>\n",
              "      <th>ASTHMA3</th>\n",
              "      <th>ASTHNOW</th>\n",
              "      <th>CHCSCNCR</th>\n",
              "      <th>CHCOCNCR</th>\n",
              "      <th>CHCCOPD1</th>\n",
              "      <th>HAVARTH3</th>\n",
              "      <th>ADDEPEV2</th>\n",
              "      <th>CHCKIDNY</th>\n",
              "      <th>DIABETE3</th>\n",
              "      <th>DIABAGE2</th>\n",
              "      <th>SEX</th>\n",
              "      <th>MARITAL</th>\n",
              "      <th>EDUCA</th>\n",
              "      <th>RENTHOM1</th>\n",
              "      <th>NUMHHOL2</th>\n",
              "      <th>NUMPHON2</th>\n",
              "      <th>CPDEMO1</th>\n",
              "      <th>VETERAN3</th>\n",
              "      <th>EMPLOY1</th>\n",
              "      <th>CHILDREN</th>\n",
              "      <th>INCOME2</th>\n",
              "      <th>INTERNET</th>\n",
              "      <th>WEIGHT2</th>\n",
              "      <th>HEIGHT3</th>\n",
              "      <th>PREGNANT</th>\n",
              "      <th>QLACTLM2</th>\n",
              "      <th>USEEQUIP</th>\n",
              "      <th>BLIND</th>\n",
              "      <th>DECIDE</th>\n",
              "      <th>DIFFWALK</th>\n",
              "      <th>DIFFDRES</th>\n",
              "      <th>DIFFALON</th>\n",
              "      <th>SMOKE100</th>\n",
              "      <th>SMOKDAY2</th>\n",
              "      <th>STOPSMK2</th>\n",
              "      <th>LASTSMK2</th>\n",
              "      <th>USENOW3</th>\n",
              "      <th>ALCDAY5</th>\n",
              "      <th>AVEDRNK2</th>\n",
              "      <th>DRNK3GE5</th>\n",
              "      <th>MAXDRNKS</th>\n",
              "      <th>FRUITJU1</th>\n",
              "      <th>FRUIT1</th>\n",
              "      <th>FVBEANS</th>\n",
              "      <th>FVGREEN</th>\n",
              "      <th>FVORANG</th>\n",
              "      <th>VEGETAB1</th>\n",
              "      <th>EXERANY2</th>\n",
              "      <th>EXRACT11</th>\n",
              "      <th>EXEROFT1</th>\n",
              "      <th>EXERHMM1</th>\n",
              "      <th>EXRACT21</th>\n",
              "      <th>EXEROFT2</th>\n",
              "      <th>EXERHMM2</th>\n",
              "      <th>STRENGTH</th>\n",
              "      <th>LMTJOIN3</th>\n",
              "      <th>ARTHDIS2</th>\n",
              "      <th>ARTHSOCL</th>\n",
              "      <th>JOINPAIN</th>\n",
              "      <th>SEATBELT</th>\n",
              "      <th>FLUSHOT6</th>\n",
              "      <th>FLSHTMY2</th>\n",
              "      <th>IMFVPLAC</th>\n",
              "      <th>PNEUVAC3</th>\n",
              "      <th>HIVTST6</th>\n",
              "      <th>HIVTSTD3</th>\n",
              "      <th>WHRTST10</th>\n",
              "      <th>PDIABTST</th>\n",
              "      <th>PREDIAB1</th>\n",
              "      <th>INSULIN</th>\n",
              "      <th>BLDSUGAR</th>\n",
              "      <th>FEETCHK2</th>\n",
              "      <th>DOCTDIAB</th>\n",
              "      <th>CHKHEMO3</th>\n",
              "      <th>FEETCHK</th>\n",
              "      <th>EYEEXAM</th>\n",
              "      <th>DIABEYE</th>\n",
              "      <th>DIABEDU</th>\n",
              "      <th>PAINACT2</th>\n",
              "      <th>QLMENTL2</th>\n",
              "      <th>QLSTRES2</th>\n",
              "      <th>QLHLTH2</th>\n",
              "      <th>CAREGIV1</th>\n",
              "      <th>CRGVREL1</th>\n",
              "      <th>CRGVLNG1</th>\n",
              "      <th>CRGVHRS1</th>\n",
              "      <th>CRGVPRB1</th>\n",
              "      <th>CRGVPERS</th>\n",
              "      <th>CRGVHOUS</th>\n",
              "      <th>CRGVMST2</th>\n",
              "      <th>CRGVEXPT</th>\n",
              "      <th>VIDFCLT2</th>\n",
              "      <th>VIREDIF3</th>\n",
              "      <th>VIPRFVS2</th>\n",
              "      <th>VINOCRE2</th>\n",
              "      <th>VIEYEXM2</th>\n",
              "      <th>VIINSUR2</th>\n",
              "      <th>VICTRCT4</th>\n",
              "      <th>VIGLUMA2</th>\n",
              "      <th>VIMACDG2</th>\n",
              "      <th>CIMEMLOS</th>\n",
              "      <th>CDHOUSE</th>\n",
              "      <th>CDASSIST</th>\n",
              "      <th>CDHELP</th>\n",
              "      <th>CDSOCIAL</th>\n",
              "      <th>CDDISCUS</th>\n",
              "      <th>WTCHSALT</th>\n",
              "      <th>LONGWTCH</th>\n",
              "      <th>DRADVISE</th>\n",
              "      <th>ASTHMAGE</th>\n",
              "      <th>ASATTACK</th>\n",
              "      <th>ASERVIST</th>\n",
              "      <th>ASDRVIST</th>\n",
              "      <th>ASRCHKUP</th>\n",
              "      <th>ASACTLIM</th>\n",
              "      <th>ASYMPTOM</th>\n",
              "      <th>ASNOSLEP</th>\n",
              "      <th>ASTHMED3</th>\n",
              "      <th>ASINHALR</th>\n",
              "      <th>HAREHAB1</th>\n",
              "      <th>STREHAB1</th>\n",
              "      <th>CVDASPRN</th>\n",
              "      <th>ASPUNSAF</th>\n",
              "      <th>RLIVPAIN</th>\n",
              "      <th>RDUCHART</th>\n",
              "      <th>RDUCSTRK</th>\n",
              "      <th>ARTTODAY</th>\n",
              "      <th>ARTHWGT</th>\n",
              "      <th>ARTHEXER</th>\n",
              "      <th>ARTHEDU</th>\n",
              "      <th>TETANUS</th>\n",
              "      <th>HPVADVC2</th>\n",
              "      <th>HPVADSHT</th>\n",
              "      <th>SHINGLE2</th>\n",
              "      <th>HADMAM</th>\n",
              "      <th>HOWLONG</th>\n",
              "      <th>HADPAP2</th>\n",
              "      <th>LASTPAP2</th>\n",
              "      <th>HPVTEST</th>\n",
              "      <th>HPLSTTST</th>\n",
              "      <th>HADHYST2</th>\n",
              "      <th>PROFEXAM</th>\n",
              "      <th>LENGEXAM</th>\n",
              "      <th>BLDSTOOL</th>\n",
              "      <th>LSTBLDS3</th>\n",
              "      <th>HADSIGM3</th>\n",
              "      <th>HADSGCO1</th>\n",
              "      <th>LASTSIG3</th>\n",
              "      <th>PCPSAAD2</th>\n",
              "      <th>PCPSADI1</th>\n",
              "      <th>PCPSARE1</th>\n",
              "      <th>PSATEST1</th>\n",
              "      <th>PSATIME</th>\n",
              "      <th>PCPSARS1</th>\n",
              "      <th>PCPSADE1</th>\n",
              "      <th>PCDMDECN</th>\n",
              "      <th>SCNTMNY1</th>\n",
              "      <th>SCNTMEL1</th>\n",
              "      <th>SCNTPAID</th>\n",
              "      <th>SCNTWRK1</th>\n",
              "      <th>SCNTLPAD</th>\n",
              "      <th>SCNTLWK1</th>\n",
              "      <th>SXORIENT</th>\n",
              "      <th>TRNSGNDR</th>\n",
              "      <th>RCSGENDR</th>\n",
              "      <th>RCSRLTN2</th>\n",
              "      <th>CASTHDX2</th>\n",
              "      <th>CASTHNO2</th>\n",
              "      <th>EMTSUPRT</th>\n",
              "      <th>LSATISFY</th>\n",
              "      <th>ADPLEASR</th>\n",
              "      <th>ADDOWN</th>\n",
              "      <th>ADSLEEP</th>\n",
              "      <th>ADENERGY</th>\n",
              "      <th>ADEAT1</th>\n",
              "      <th>ADFAIL</th>\n",
              "      <th>ADTHINK</th>\n",
              "      <th>ADMOVE</th>\n",
              "      <th>MISTMNT</th>\n",
              "      <th>ADANXEV</th>\n",
              "      <th>QSTVER</th>\n",
              "      <th>QSTLANG</th>\n",
              "      <th>EXACTOT1</th>\n",
              "      <th>EXACTOT2</th>\n",
              "      <th>MSCODE</th>\n",
              "      <th>_STSTR</th>\n",
              "      <th>_STRWT</th>\n",
              "      <th>_RAWRAKE</th>\n",
              "      <th>_WT2RAKE</th>\n",
              "      <th>_CHISPNC</th>\n",
              "      <th>_CRACE1</th>\n",
              "      <th>_CPRACE</th>\n",
              "      <th>_CLLCPWT</th>\n",
              "      <th>_DUALUSE</th>\n",
              "      <th>_DUALCOR</th>\n",
              "      <th>_LLCPWT</th>\n",
              "      <th>_RFHLTH</th>\n",
              "      <th>_HCVU651</th>\n",
              "      <th>_RFHYPE5</th>\n",
              "      <th>_CHOLCHK</th>\n",
              "      <th>_RFCHOL</th>\n",
              "      <th>_MICHD</th>\n",
              "      <th>_LTASTH1</th>\n",
              "      <th>_CASTHM1</th>\n",
              "      <th>_ASTHMS1</th>\n",
              "      <th>_DRDXAR1</th>\n",
              "      <th>_PRACE1</th>\n",
              "      <th>_MRACE1</th>\n",
              "      <th>_HISPANC</th>\n",
              "      <th>_RACE</th>\n",
              "      <th>_RACEG21</th>\n",
              "      <th>_RACEGR3</th>\n",
              "      <th>_RACE_G1</th>\n",
              "      <th>_AGEG5YR</th>\n",
              "      <th>_AGE65YR</th>\n",
              "      <th>_AGE80</th>\n",
              "      <th>_AGE_G</th>\n",
              "      <th>HTIN4</th>\n",
              "      <th>HTM4</th>\n",
              "      <th>WTKG3</th>\n",
              "      <th>_BMI5</th>\n",
              "      <th>_BMI5CAT</th>\n",
              "      <th>_RFBMI5</th>\n",
              "      <th>_CHLDCNT</th>\n",
              "      <th>_EDUCAG</th>\n",
              "      <th>_INCOMG</th>\n",
              "      <th>_SMOKER3</th>\n",
              "      <th>_RFSMOK3</th>\n",
              "      <th>DRNKANY5</th>\n",
              "      <th>DROCDY3_</th>\n",
              "      <th>_RFBING5</th>\n",
              "      <th>_DRNKWEK</th>\n",
              "      <th>_RFDRHV5</th>\n",
              "      <th>FTJUDA1_</th>\n",
              "      <th>FRUTDA1_</th>\n",
              "      <th>BEANDAY_</th>\n",
              "      <th>GRENDAY_</th>\n",
              "      <th>ORNGDAY_</th>\n",
              "      <th>VEGEDA1_</th>\n",
              "      <th>_MISFRTN</th>\n",
              "      <th>_MISVEGN</th>\n",
              "      <th>_FRTRESP</th>\n",
              "      <th>_VEGRESP</th>\n",
              "      <th>_FRUTSUM</th>\n",
              "      <th>_VEGESUM</th>\n",
              "      <th>_FRTLT1</th>\n",
              "      <th>_VEGLT1</th>\n",
              "      <th>_FRT16</th>\n",
              "      <th>_VEG23</th>\n",
              "      <th>_FRUITEX</th>\n",
              "      <th>_VEGETEX</th>\n",
              "      <th>_TOTINDA</th>\n",
              "      <th>METVL11_</th>\n",
              "      <th>METVL21_</th>\n",
              "      <th>MAXVO2_</th>\n",
              "      <th>FC60_</th>\n",
              "      <th>ACTIN11_</th>\n",
              "      <th>ACTIN21_</th>\n",
              "      <th>PADUR1_</th>\n",
              "      <th>PADUR2_</th>\n",
              "      <th>PAFREQ1_</th>\n",
              "      <th>PAFREQ2_</th>\n",
              "      <th>_MINAC11</th>\n",
              "      <th>_MINAC21</th>\n",
              "      <th>STRFREQ_</th>\n",
              "      <th>PAMISS1_</th>\n",
              "      <th>PAMIN11_</th>\n",
              "      <th>PAMIN21_</th>\n",
              "      <th>PA1MIN_</th>\n",
              "      <th>PAVIG11_</th>\n",
              "      <th>PAVIG21_</th>\n",
              "      <th>PA1VIGM_</th>\n",
              "      <th>_PACAT1</th>\n",
              "      <th>_PAINDX1</th>\n",
              "      <th>_PA150R2</th>\n",
              "      <th>_PA300R2</th>\n",
              "      <th>_PA30021</th>\n",
              "      <th>_PASTRNG</th>\n",
              "      <th>_PAREC1</th>\n",
              "      <th>_PASTAE1</th>\n",
              "      <th>_LMTACT1</th>\n",
              "      <th>_LMTWRK1</th>\n",
              "      <th>_LMTSCL1</th>\n",
              "      <th>_RFSEAT2</th>\n",
              "      <th>_RFSEAT3</th>\n",
              "      <th>_FLSHOT6</th>\n",
              "      <th>_PNEUMO2</th>\n",
              "      <th>_AIDTST3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>b'01292015'</td>\n",
              "      <td>b'01'</td>\n",
              "      <td>b'29'</td>\n",
              "      <td>b'2015'</td>\n",
              "      <td>1200.0</td>\n",
              "      <td>2.015000e+09</td>\n",
              "      <td>2.015000e+09</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>510.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>888.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>305.0</td>\n",
              "      <td>310.0</td>\n",
              "      <td>320.0</td>\n",
              "      <td>310.0</td>\n",
              "      <td>305.0</td>\n",
              "      <td>101.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>888.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>112014.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>b''</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>b''</td>\n",
              "      <td>b''</td>\n",
              "      <td>3.0</td>\n",
              "      <td>11011.0</td>\n",
              "      <td>28.78156</td>\n",
              "      <td>3.0</td>\n",
              "      <td>86.344681</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.614125</td>\n",
              "      <td>341.384853</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>63.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>178.0</td>\n",
              "      <td>12701.0</td>\n",
              "      <td>4018.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.397605e-79</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.397605e-79</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.700000e+01</td>\n",
              "      <td>33.0</td>\n",
              "      <td>6.700000e+01</td>\n",
              "      <td>33.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>5.397605e-79</td>\n",
              "      <td>5.397605e-79</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>50.0</td>\n",
              "      <td>217.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.397605e-79</td>\n",
              "      <td>5.397605e-79</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2469.0</td>\n",
              "      <td>423.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.397605e-79</td>\n",
              "      <td>5.397605e-79</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>b'01202015'</td>\n",
              "      <td>b'01'</td>\n",
              "      <td>b'20'</td>\n",
              "      <td>b'2015'</td>\n",
              "      <td>1100.0</td>\n",
              "      <td>2.015000e+09</td>\n",
              "      <td>2.015000e+09</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.397605e-79</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>165.0</td>\n",
              "      <td>508.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>888.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>302.0</td>\n",
              "      <td>305.0</td>\n",
              "      <td>302.0</td>\n",
              "      <td>202.0</td>\n",
              "      <td>202.0</td>\n",
              "      <td>304.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>212.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>212.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>888.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>b''</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>b''</td>\n",
              "      <td>b''</td>\n",
              "      <td>5.0</td>\n",
              "      <td>11011.0</td>\n",
              "      <td>28.78156</td>\n",
              "      <td>1.0</td>\n",
              "      <td>28.781560</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>108.060903</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>173.0</td>\n",
              "      <td>7484.0</td>\n",
              "      <td>2509.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.397605e-79</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.397605e-79</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7.000000e+00</td>\n",
              "      <td>17.0</td>\n",
              "      <td>7.000000e+00</td>\n",
              "      <td>29.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>5.397605e-79</td>\n",
              "      <td>5.397605e-79</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>24.0</td>\n",
              "      <td>78.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.397605e-79</td>\n",
              "      <td>5.397605e-79</td>\n",
              "      <td>1.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>5.397605e-79</td>\n",
              "      <td>2876.0</td>\n",
              "      <td>493.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.397605e-79</td>\n",
              "      <td>60.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>2800.0</td>\n",
              "      <td>2800.0</td>\n",
              "      <td>168.0</td>\n",
              "      <td>5.397605e-79</td>\n",
              "      <td>5.397605e-79</td>\n",
              "      <td>5.397605e-79</td>\n",
              "      <td>168.0</td>\n",
              "      <td>5.397605e-79</td>\n",
              "      <td>168.0</td>\n",
              "      <td>5.397605e-79</td>\n",
              "      <td>5.397605e-79</td>\n",
              "      <td>5.397605e-79</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>b'02012015'</td>\n",
              "      <td>b'02'</td>\n",
              "      <td>b'01'</td>\n",
              "      <td>b'2015'</td>\n",
              "      <td>1200.0</td>\n",
              "      <td>2.015000e+09</td>\n",
              "      <td>2.015000e+09</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>158.0</td>\n",
              "      <td>511.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>b''</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>b''</td>\n",
              "      <td>b''</td>\n",
              "      <td>5.0</td>\n",
              "      <td>11011.0</td>\n",
              "      <td>28.78156</td>\n",
              "      <td>2.0</td>\n",
              "      <td>57.563120</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.614125</td>\n",
              "      <td>255.264797</td>\n",
              "      <td>2.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>180.0</td>\n",
              "      <td>7167.0</td>\n",
              "      <td>2204.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.000000e+02</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.990000e+04</td>\n",
              "      <td>9.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>4.000000e+00</td>\n",
              "      <td>5.397605e-79</td>\n",
              "      <td>5.397605e-79</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>9.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2173.0</td>\n",
              "      <td>373.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9.000000e+00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>b'01142015'</td>\n",
              "      <td>b'01'</td>\n",
              "      <td>b'14'</td>\n",
              "      <td>b'2015'</td>\n",
              "      <td>1100.0</td>\n",
              "      <td>2.015000e+09</td>\n",
              "      <td>2.015000e+09</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>180.0</td>\n",
              "      <td>507.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>888.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>555.0</td>\n",
              "      <td>101.0</td>\n",
              "      <td>555.0</td>\n",
              "      <td>301.0</td>\n",
              "      <td>301.0</td>\n",
              "      <td>201.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>888.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>777777.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>b''</td>\n",
              "      <td>4.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>97.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>b''</td>\n",
              "      <td>b''</td>\n",
              "      <td>3.0</td>\n",
              "      <td>11011.0</td>\n",
              "      <td>28.78156</td>\n",
              "      <td>3.0</td>\n",
              "      <td>86.344681</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.614125</td>\n",
              "      <td>341.384853</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>63.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>170.0</td>\n",
              "      <td>8165.0</td>\n",
              "      <td>2819.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.397605e-79</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.397605e-79</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.397605e-79</td>\n",
              "      <td>100.0</td>\n",
              "      <td>5.397605e-79</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>5.397605e-79</td>\n",
              "      <td>5.397605e-79</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>100.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.397605e-79</td>\n",
              "      <td>5.397605e-79</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2469.0</td>\n",
              "      <td>423.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.397605e-79</td>\n",
              "      <td>5.397605e-79</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>b'01142015'</td>\n",
              "      <td>b'01'</td>\n",
              "      <td>b'14'</td>\n",
              "      <td>b'2015'</td>\n",
              "      <td>1100.0</td>\n",
              "      <td>2.015000e+09</td>\n",
              "      <td>2.015000e+09</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>77.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>142.0</td>\n",
              "      <td>504.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>888.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>777.0</td>\n",
              "      <td>102.0</td>\n",
              "      <td>203.0</td>\n",
              "      <td>204.0</td>\n",
              "      <td>310.0</td>\n",
              "      <td>320.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>888.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>777777.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>777.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>b''</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>45.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>b''</td>\n",
              "      <td>b''</td>\n",
              "      <td>3.0</td>\n",
              "      <td>11011.0</td>\n",
              "      <td>28.78156</td>\n",
              "      <td>2.0</td>\n",
              "      <td>57.563120</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>258.682223</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>163.0</td>\n",
              "      <td>6441.0</td>\n",
              "      <td>2437.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.397605e-79</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.397605e-79</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>200.0</td>\n",
              "      <td>4.300000e+01</td>\n",
              "      <td>57.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>5.397605e-79</td>\n",
              "      <td>5.397605e-79</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>200.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>5.397605e-79</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2543.0</td>\n",
              "      <td>436.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.397605e-79</td>\n",
              "      <td>5.397605e-79</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   _STATE  FMONTH        IDATE IMONTH   IDAY    IYEAR  DISPCODE         SEQNO  \\\n",
              "0     1.0     1.0  b'01292015'  b'01'  b'29'  b'2015'    1200.0  2.015000e+09   \n",
              "1     1.0     1.0  b'01202015'  b'01'  b'20'  b'2015'    1100.0  2.015000e+09   \n",
              "2     1.0     1.0  b'02012015'  b'02'  b'01'  b'2015'    1200.0  2.015000e+09   \n",
              "3     1.0     1.0  b'01142015'  b'01'  b'14'  b'2015'    1100.0  2.015000e+09   \n",
              "4     1.0     1.0  b'01142015'  b'01'  b'14'  b'2015'    1100.0  2.015000e+09   \n",
              "\n",
              "           _PSU  CTELENUM  PVTRESD1  COLGHOUS  STATERES  CELLFON3  LADULT  \\\n",
              "0  2.015000e+09       1.0       1.0       NaN       1.0       2.0     NaN   \n",
              "1  2.015000e+09       1.0       1.0       NaN       1.0       2.0     NaN   \n",
              "2  2.015000e+09       1.0       1.0       NaN       1.0       2.0     NaN   \n",
              "3  2.015000e+09       1.0       1.0       NaN       1.0       2.0     NaN   \n",
              "4  2.015000e+09       1.0       1.0       NaN       1.0       2.0     NaN   \n",
              "\n",
              "   NUMADULT        NUMMEN  NUMWOMEN  CTELNUM1  CELLFON2  CADULT  PVTRESD2  \\\n",
              "0       3.0  1.000000e+00       2.0       NaN       NaN     NaN       NaN   \n",
              "1       1.0  5.397605e-79       1.0       NaN       NaN     NaN       NaN   \n",
              "2       2.0  1.000000e+00       1.0       NaN       NaN     NaN       NaN   \n",
              "3       3.0  1.000000e+00       2.0       NaN       NaN     NaN       NaN   \n",
              "4       2.0  1.000000e+00       1.0       NaN       NaN     NaN       NaN   \n",
              "\n",
              "   CCLGHOUS  CSTATE  LANDLINE  HHADULT  GENHLTH  PHYSHLTH  MENTHLTH  POORHLTH  \\\n",
              "0       NaN     NaN       NaN      NaN      5.0      15.0      18.0      10.0   \n",
              "1       NaN     NaN       NaN      NaN      3.0      88.0      88.0       NaN   \n",
              "2       NaN     NaN       NaN      NaN      4.0      15.0      88.0      88.0   \n",
              "3       NaN     NaN       NaN      NaN      5.0      30.0      30.0      30.0   \n",
              "4       NaN     NaN       NaN      NaN      5.0      20.0      88.0      30.0   \n",
              "\n",
              "   HLTHPLN1  PERSDOC2  MEDCOST  CHECKUP1  BPHIGH4  BPMEDS  BLOODCHO  CHOLCHK  \\\n",
              "0       1.0       1.0      2.0       1.0      1.0     1.0       1.0      1.0   \n",
              "1       2.0       1.0      1.0       4.0      3.0     NaN       1.0      4.0   \n",
              "2       1.0       2.0      2.0       1.0      3.0     NaN       1.0      1.0   \n",
              "3       1.0       2.0      1.0       1.0      1.0     1.0       1.0      1.0   \n",
              "4       1.0       1.0      2.0       1.0      3.0     NaN       1.0      1.0   \n",
              "\n",
              "   TOLDHI2  CVDINFR4  CVDCRHD4  CVDSTRK3  ASTHMA3  ASTHNOW  CHCSCNCR  \\\n",
              "0      1.0       2.0       2.0       2.0      1.0      1.0       2.0   \n",
              "1      2.0       2.0       2.0       2.0      2.0      NaN       2.0   \n",
              "2      1.0       7.0       2.0       1.0      2.0      NaN       2.0   \n",
              "3      1.0       2.0       2.0       2.0      2.0      NaN       2.0   \n",
              "4      2.0       2.0       2.0       2.0      2.0      NaN       2.0   \n",
              "\n",
              "   CHCOCNCR  CHCCOPD1  HAVARTH3  ADDEPEV2  CHCKIDNY  DIABETE3  DIABAGE2  SEX  \\\n",
              "0       2.0       1.0       1.0       1.0       2.0       3.0       NaN  2.0   \n",
              "1       2.0       2.0       2.0       2.0       2.0       3.0       NaN  2.0   \n",
              "2       1.0       2.0       1.0       2.0       2.0       3.0       NaN  2.0   \n",
              "3       1.0       2.0       1.0       1.0       2.0       3.0       NaN  2.0   \n",
              "4       2.0       2.0       1.0       2.0       2.0       3.0       NaN  2.0   \n",
              "\n",
              "   MARITAL  EDUCA  RENTHOM1  NUMHHOL2  NUMPHON2  CPDEMO1  VETERAN3  EMPLOY1  \\\n",
              "0      1.0    4.0       1.0       2.0       NaN      1.0       2.0      8.0   \n",
              "1      2.0    6.0       1.0       2.0       NaN      2.0       2.0      3.0   \n",
              "2      2.0    4.0       1.0       2.0       NaN      1.0       2.0      7.0   \n",
              "3      1.0    4.0       1.0       2.0       NaN      1.0       2.0      8.0   \n",
              "4      1.0    5.0       1.0       2.0       NaN      2.0       2.0      8.0   \n",
              "\n",
              "   CHILDREN  INCOME2  INTERNET  WEIGHT2  HEIGHT3  PREGNANT  QLACTLM2  \\\n",
              "0      88.0      3.0       2.0    280.0    510.0       NaN       1.0   \n",
              "1      88.0      1.0       1.0    165.0    508.0       NaN       1.0   \n",
              "2      88.0     99.0       2.0    158.0    511.0       NaN       2.0   \n",
              "3       1.0      8.0       2.0    180.0    507.0       NaN       1.0   \n",
              "4      88.0     77.0       1.0    142.0    504.0       NaN       2.0   \n",
              "\n",
              "   USEEQUIP  BLIND  DECIDE  DIFFWALK  DIFFDRES  DIFFALON  SMOKE100  SMOKDAY2  \\\n",
              "0       1.0    2.0     2.0       1.0       1.0       1.0       1.0       3.0   \n",
              "1       2.0    1.0     1.0       2.0       2.0       2.0       1.0       1.0   \n",
              "2       2.0    2.0     2.0       NaN       NaN       NaN       NaN       NaN   \n",
              "3       2.0    1.0     1.0       1.0       2.0       1.0       2.0       NaN   \n",
              "4       2.0    2.0     2.0       2.0       2.0       2.0       2.0       NaN   \n",
              "\n",
              "   STOPSMK2  LASTSMK2  USENOW3  ALCDAY5  AVEDRNK2  DRNK3GE5  MAXDRNKS  \\\n",
              "0       NaN       2.0      3.0    888.0       NaN       NaN       NaN   \n",
              "1       2.0       NaN      3.0    888.0       NaN       NaN       NaN   \n",
              "2       NaN       NaN      NaN      NaN       NaN       NaN       NaN   \n",
              "3       NaN       NaN      3.0    888.0       NaN       NaN       NaN   \n",
              "4       NaN       NaN      3.0    888.0       NaN       NaN       NaN   \n",
              "\n",
              "   FRUITJU1  FRUIT1  FVBEANS  FVGREEN  FVORANG  VEGETAB1  EXERANY2  EXRACT11  \\\n",
              "0     305.0   310.0    320.0    310.0    305.0     101.0       2.0       NaN   \n",
              "1     302.0   305.0    302.0    202.0    202.0     304.0       1.0      64.0   \n",
              "2       NaN     NaN      NaN      NaN      NaN       NaN       NaN       NaN   \n",
              "3     555.0   101.0    555.0    301.0    301.0     201.0       2.0       NaN   \n",
              "4     777.0   102.0    203.0    204.0    310.0     320.0       2.0       NaN   \n",
              "\n",
              "   EXEROFT1  EXERHMM1  EXRACT21  EXEROFT2  EXERHMM2  STRENGTH  LMTJOIN3  \\\n",
              "0       NaN       NaN       NaN       NaN       NaN     888.0       1.0   \n",
              "1     212.0     100.0      69.0     212.0     100.0     888.0       NaN   \n",
              "2       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
              "3       NaN       NaN       NaN       NaN       NaN     888.0       1.0   \n",
              "4       NaN       NaN       NaN       NaN       NaN     888.0       1.0   \n",
              "\n",
              "   ARTHDIS2  ARTHSOCL  JOINPAIN  SEATBELT  FLUSHOT6  FLSHTMY2  IMFVPLAC  \\\n",
              "0       1.0       1.0       6.0       1.0       1.0  112014.0       1.0   \n",
              "1       NaN       NaN       NaN       3.0       2.0       NaN       NaN   \n",
              "2       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
              "3       1.0       1.0       8.0       1.0       1.0  777777.0       5.0   \n",
              "4       1.0       1.0       7.0       1.0       2.0       NaN       NaN   \n",
              "\n",
              "   PNEUVAC3  HIVTST6  HIVTSTD3  WHRTST10  PDIABTST  PREDIAB1  INSULIN  \\\n",
              "0       1.0      1.0       NaN       NaN       1.0       3.0      NaN   \n",
              "1       2.0      2.0       NaN       NaN       2.0       3.0      NaN   \n",
              "2       NaN      NaN       NaN       NaN       1.0       3.0      NaN   \n",
              "3       1.0      9.0       NaN       NaN       2.0       3.0      NaN   \n",
              "4       1.0      1.0  777777.0       1.0       1.0       3.0      NaN   \n",
              "\n",
              "   BLDSUGAR  FEETCHK2  DOCTDIAB  CHKHEMO3  FEETCHK  EYEEXAM  DIABEYE  DIABEDU  \\\n",
              "0       NaN       NaN       NaN       NaN      NaN      NaN      NaN      NaN   \n",
              "1       NaN       NaN       NaN       NaN      NaN      NaN      NaN      NaN   \n",
              "2       NaN       NaN       NaN       NaN      NaN      NaN      NaN      NaN   \n",
              "3       NaN       NaN       NaN       NaN      NaN      NaN      NaN      NaN   \n",
              "4       NaN       NaN       NaN       NaN      NaN      NaN      NaN      NaN   \n",
              "\n",
              "   PAINACT2  QLMENTL2  QLSTRES2  QLHLTH2  CAREGIV1  CRGVREL1  CRGVLNG1  \\\n",
              "0       NaN       NaN       NaN      NaN       NaN       NaN       NaN   \n",
              "1       NaN       NaN       NaN      NaN       2.0       NaN       NaN   \n",
              "2       NaN       NaN       NaN      NaN       NaN       NaN       NaN   \n",
              "3       NaN       NaN       NaN      NaN       2.0       NaN       NaN   \n",
              "4       NaN       NaN       NaN      NaN       2.0       NaN       NaN   \n",
              "\n",
              "   CRGVHRS1  CRGVPRB1  CRGVPERS  CRGVHOUS  CRGVMST2  CRGVEXPT  VIDFCLT2  \\\n",
              "0       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
              "1       NaN       NaN       NaN       NaN       NaN       1.0       NaN   \n",
              "2       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
              "3       NaN       NaN       NaN       NaN       NaN       2.0       NaN   \n",
              "4       NaN       NaN       NaN       NaN       NaN       7.0       NaN   \n",
              "\n",
              "   VIREDIF3  VIPRFVS2  VINOCRE2  VIEYEXM2  VIINSUR2  VICTRCT4  VIGLUMA2  \\\n",
              "0       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
              "1       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
              "2       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
              "3       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
              "4       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
              "\n",
              "   VIMACDG2  CIMEMLOS  CDHOUSE  CDASSIST  CDHELP  CDSOCIAL  CDDISCUS  \\\n",
              "0       NaN       NaN      NaN       NaN     NaN       NaN       NaN   \n",
              "1       NaN       1.0      5.0       5.0     NaN       5.0       2.0   \n",
              "2       NaN       NaN      NaN       NaN     NaN       NaN       NaN   \n",
              "3       NaN       1.0      1.0       1.0     2.0       1.0       1.0   \n",
              "4       NaN       2.0      NaN       NaN     NaN       NaN       NaN   \n",
              "\n",
              "   WTCHSALT  LONGWTCH  DRADVISE  ASTHMAGE  ASATTACK  ASERVIST  ASDRVIST  \\\n",
              "0       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
              "1       2.0       NaN       2.0       NaN       NaN       NaN       NaN   \n",
              "2       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
              "3       2.0       NaN       2.0       NaN       NaN       NaN       NaN   \n",
              "4       1.0     777.0       2.0       NaN       NaN       NaN       NaN   \n",
              "\n",
              "   ASRCHKUP  ASACTLIM  ASYMPTOM  ASNOSLEP  ASTHMED3  ASINHALR  HAREHAB1  \\\n",
              "0       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
              "1       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
              "2       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
              "3       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
              "4       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
              "\n",
              "   STREHAB1  CVDASPRN  ASPUNSAF  RLIVPAIN  RDUCHART  RDUCSTRK  ARTTODAY  \\\n",
              "0       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
              "1       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
              "2       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
              "3       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
              "4       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
              "\n",
              "   ARTHWGT  ARTHEXER  ARTHEDU  TETANUS  HPVADVC2  HPVADSHT  SHINGLE2  HADMAM  \\\n",
              "0      NaN       NaN      NaN      NaN       NaN       NaN       NaN     NaN   \n",
              "1      NaN       NaN      NaN      NaN       NaN       NaN       NaN     NaN   \n",
              "2      NaN       NaN      NaN      NaN       NaN       NaN       NaN     NaN   \n",
              "3      NaN       NaN      NaN      NaN       NaN       NaN       NaN     NaN   \n",
              "4      NaN       NaN      NaN      NaN       NaN       NaN       NaN     NaN   \n",
              "\n",
              "   HOWLONG  HADPAP2  LASTPAP2  HPVTEST  HPLSTTST  HADHYST2  PROFEXAM  \\\n",
              "0      NaN      NaN       NaN      NaN       NaN       NaN       NaN   \n",
              "1      NaN      NaN       NaN      NaN       NaN       NaN       NaN   \n",
              "2      NaN      NaN       NaN      NaN       NaN       NaN       NaN   \n",
              "3      NaN      NaN       NaN      NaN       NaN       NaN       NaN   \n",
              "4      NaN      NaN       NaN      NaN       NaN       NaN       NaN   \n",
              "\n",
              "   LENGEXAM  BLDSTOOL  LSTBLDS3  HADSIGM3  HADSGCO1  LASTSIG3  PCPSAAD2  \\\n",
              "0       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
              "1       NaN       2.0       NaN       2.0       NaN       NaN       NaN   \n",
              "2       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
              "3       NaN       2.0       NaN       1.0       2.0       1.0       NaN   \n",
              "4       NaN       2.0       NaN       1.0       2.0       5.0       NaN   \n",
              "\n",
              "   PCPSADI1  PCPSARE1  PSATEST1  PSATIME  PCPSARS1  PCPSADE1 PCDMDECN  \\\n",
              "0       NaN       NaN       NaN      NaN       NaN       NaN      b''   \n",
              "1       NaN       NaN       NaN      NaN       NaN       NaN      b''   \n",
              "2       NaN       NaN       NaN      NaN       NaN       NaN      b''   \n",
              "3       NaN       NaN       NaN      NaN       NaN       NaN      b''   \n",
              "4       NaN       NaN       NaN      NaN       NaN       NaN      b''   \n",
              "\n",
              "   SCNTMNY1  SCNTMEL1  SCNTPAID  SCNTWRK1  SCNTLPAD  SCNTLWK1  SXORIENT  \\\n",
              "0       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
              "1       1.0       2.0       NaN       NaN       2.0      60.0       NaN   \n",
              "2       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
              "3       4.0       7.0       NaN       NaN       NaN      97.0       NaN   \n",
              "4       5.0       5.0       NaN       NaN       NaN      45.0       NaN   \n",
              "\n",
              "   TRNSGNDR  RCSGENDR  RCSRLTN2  CASTHDX2  CASTHNO2  EMTSUPRT  LSATISFY  \\\n",
              "0       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
              "1       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
              "2       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
              "3       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
              "4       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
              "\n",
              "   ADPLEASR  ADDOWN  ADSLEEP  ADENERGY  ADEAT1  ADFAIL  ADTHINK  ADMOVE  \\\n",
              "0       NaN     NaN      NaN       NaN     NaN     NaN      NaN     NaN   \n",
              "1       NaN     NaN      NaN       NaN     NaN     NaN      NaN     NaN   \n",
              "2       NaN     NaN      NaN       NaN     NaN     NaN      NaN     NaN   \n",
              "3       NaN     NaN      NaN       NaN     NaN     NaN      NaN     NaN   \n",
              "4       NaN     NaN      NaN       NaN     NaN     NaN      NaN     NaN   \n",
              "\n",
              "   MISTMNT  ADANXEV  QSTVER  QSTLANG EXACTOT1 EXACTOT2  MSCODE   _STSTR  \\\n",
              "0      NaN      NaN    10.0      1.0      b''      b''     3.0  11011.0   \n",
              "1      NaN      NaN    10.0      1.0      b''      b''     5.0  11011.0   \n",
              "2      NaN      NaN    10.0      1.0      b''      b''     5.0  11011.0   \n",
              "3      NaN      NaN    10.0      1.0      b''      b''     3.0  11011.0   \n",
              "4      NaN      NaN    10.0      1.0      b''      b''     3.0  11011.0   \n",
              "\n",
              "     _STRWT  _RAWRAKE   _WT2RAKE  _CHISPNC  _CRACE1  _CPRACE  _CLLCPWT  \\\n",
              "0  28.78156       3.0  86.344681       NaN      NaN      NaN       NaN   \n",
              "1  28.78156       1.0  28.781560       NaN      NaN      NaN       NaN   \n",
              "2  28.78156       2.0  57.563120       NaN      NaN      NaN       NaN   \n",
              "3  28.78156       3.0  86.344681       NaN      NaN      NaN       NaN   \n",
              "4  28.78156       2.0  57.563120       NaN      NaN      NaN       NaN   \n",
              "\n",
              "   _DUALUSE  _DUALCOR     _LLCPWT  _RFHLTH  _HCVU651  _RFHYPE5  _CHOLCHK  \\\n",
              "0       1.0  0.614125  341.384853      2.0       1.0       2.0       1.0   \n",
              "1       9.0       NaN  108.060903      1.0       2.0       1.0       2.0   \n",
              "2       1.0  0.614125  255.264797      2.0       9.0       1.0       1.0   \n",
              "3       1.0  0.614125  341.384853      2.0       1.0       2.0       1.0   \n",
              "4       9.0       NaN  258.682223      2.0       1.0       1.0       1.0   \n",
              "\n",
              "   _RFCHOL  _MICHD  _LTASTH1  _CASTHM1  _ASTHMS1  _DRDXAR1  _PRACE1  _MRACE1  \\\n",
              "0      2.0     2.0       2.0       2.0       1.0       1.0      1.0      1.0   \n",
              "1      1.0     2.0       1.0       1.0       3.0       2.0      1.0      1.0   \n",
              "2      2.0     NaN       1.0       1.0       3.0       1.0      1.0      1.0   \n",
              "3      2.0     2.0       1.0       1.0       3.0       1.0      1.0      1.0   \n",
              "4      1.0     2.0       1.0       1.0       3.0       1.0      1.0      1.0   \n",
              "\n",
              "   _HISPANC  _RACE  _RACEG21  _RACEGR3  _RACE_G1  _AGEG5YR  _AGE65YR  _AGE80  \\\n",
              "0       2.0    1.0       1.0       1.0       1.0       9.0       1.0    63.0   \n",
              "1       2.0    1.0       1.0       1.0       1.0       7.0       1.0    52.0   \n",
              "2       2.0    1.0       1.0       1.0       1.0      11.0       2.0    71.0   \n",
              "3       2.0    1.0       1.0       1.0       1.0       9.0       1.0    63.0   \n",
              "4       2.0    1.0       1.0       1.0       1.0       9.0       1.0    61.0   \n",
              "\n",
              "   _AGE_G  HTIN4   HTM4    WTKG3   _BMI5  _BMI5CAT  _RFBMI5  _CHLDCNT  \\\n",
              "0     5.0   70.0  178.0  12701.0  4018.0       4.0      2.0       1.0   \n",
              "1     4.0   68.0  173.0   7484.0  2509.0       3.0      2.0       1.0   \n",
              "2     6.0   71.0  180.0   7167.0  2204.0       2.0      1.0       1.0   \n",
              "3     5.0   67.0  170.0   8165.0  2819.0       3.0      2.0       2.0   \n",
              "4     5.0   64.0  163.0   6441.0  2437.0       2.0      1.0       1.0   \n",
              "\n",
              "   _EDUCAG  _INCOMG  _SMOKER3  _RFSMOK3  DRNKANY5      DROCDY3_  _RFBING5  \\\n",
              "0      2.0      2.0       3.0       1.0       2.0  5.397605e-79       1.0   \n",
              "1      4.0      1.0       1.0       2.0       2.0  5.397605e-79       1.0   \n",
              "2      2.0      9.0       9.0       9.0       9.0  9.000000e+02       9.0   \n",
              "3      2.0      5.0       4.0       1.0       2.0  5.397605e-79       1.0   \n",
              "4      3.0      9.0       4.0       1.0       2.0  5.397605e-79       1.0   \n",
              "\n",
              "       _DRNKWEK  _RFDRHV5      FTJUDA1_  FRUTDA1_      BEANDAY_  GRENDAY_  \\\n",
              "0  5.397605e-79       1.0  1.700000e+01      33.0  6.700000e+01      33.0   \n",
              "1  5.397605e-79       1.0  7.000000e+00      17.0  7.000000e+00      29.0   \n",
              "2  9.990000e+04       9.0           NaN       NaN           NaN       NaN   \n",
              "3  5.397605e-79       1.0  5.397605e-79     100.0  5.397605e-79       3.0   \n",
              "4  5.397605e-79       1.0           NaN     200.0  4.300000e+01      57.0   \n",
              "\n",
              "   ORNGDAY_  VEGEDA1_      _MISFRTN      _MISVEGN      _FRTRESP      _VEGRESP  \\\n",
              "0      17.0     100.0  5.397605e-79  5.397605e-79  1.000000e+00  1.000000e+00   \n",
              "1      29.0      13.0  5.397605e-79  5.397605e-79  1.000000e+00  1.000000e+00   \n",
              "2       NaN       NaN  2.000000e+00  4.000000e+00  5.397605e-79  5.397605e-79   \n",
              "3       3.0      14.0  5.397605e-79  5.397605e-79  1.000000e+00  1.000000e+00   \n",
              "4      33.0      67.0  1.000000e+00  5.397605e-79  5.397605e-79  1.000000e+00   \n",
              "\n",
              "   _FRUTSUM  _VEGESUM  _FRTLT1  _VEGLT1  _FRT16  _VEG23      _FRUITEX  \\\n",
              "0      50.0     217.0      2.0      1.0     1.0     1.0  5.397605e-79   \n",
              "1      24.0      78.0      2.0      2.0     1.0     1.0  5.397605e-79   \n",
              "2       NaN       NaN      9.0      9.0     1.0     1.0  1.000000e+00   \n",
              "3     100.0      20.0      1.0      2.0     1.0     1.0  5.397605e-79   \n",
              "4       NaN     200.0      9.0      1.0     1.0     1.0  1.000000e+00   \n",
              "\n",
              "       _VEGETEX  _TOTINDA  METVL11_      METVL21_  MAXVO2_  FC60_  ACTIN11_  \\\n",
              "0  5.397605e-79       2.0       NaN           NaN   2469.0  423.0       NaN   \n",
              "1  5.397605e-79       1.0      35.0  5.397605e-79   2876.0  493.0       1.0   \n",
              "2  1.000000e+00       9.0       NaN           NaN   2173.0  373.0       NaN   \n",
              "3  5.397605e-79       2.0       NaN           NaN   2469.0  423.0       NaN   \n",
              "4  5.397605e-79       2.0       NaN           NaN   2543.0  436.0       NaN   \n",
              "\n",
              "       ACTIN21_  PADUR1_  PADUR2_  PAFREQ1_  PAFREQ2_  _MINAC11      _MINAC21  \\\n",
              "0           NaN      NaN      NaN       NaN       NaN       NaN           NaN   \n",
              "1  5.397605e-79     60.0     60.0    2800.0    2800.0     168.0  5.397605e-79   \n",
              "2           NaN      NaN      NaN       NaN       NaN       NaN           NaN   \n",
              "3           NaN      NaN      NaN       NaN       NaN       NaN           NaN   \n",
              "4           NaN      NaN      NaN       NaN       NaN       NaN           NaN   \n",
              "\n",
              "       STRFREQ_      PAMISS1_  PAMIN11_      PAMIN21_  PA1MIN_      PAVIG11_  \\\n",
              "0  5.397605e-79  5.397605e-79       NaN           NaN      NaN           NaN   \n",
              "1  5.397605e-79  5.397605e-79     168.0  5.397605e-79    168.0  5.397605e-79   \n",
              "2           NaN  9.000000e+00       NaN           NaN      NaN           NaN   \n",
              "3  5.397605e-79  5.397605e-79       NaN           NaN      NaN           NaN   \n",
              "4  5.397605e-79  5.397605e-79       NaN           NaN      NaN           NaN   \n",
              "\n",
              "       PAVIG21_      PA1VIGM_  _PACAT1  _PAINDX1  _PA150R2  _PA300R2  \\\n",
              "0           NaN           NaN      4.0       2.0       3.0       3.0   \n",
              "1  5.397605e-79  5.397605e-79      2.0       1.0       1.0       2.0   \n",
              "2           NaN           NaN      9.0       9.0       9.0       9.0   \n",
              "3           NaN           NaN      4.0       2.0       3.0       3.0   \n",
              "4           NaN           NaN      4.0       2.0       3.0       3.0   \n",
              "\n",
              "   _PA30021  _PASTRNG  _PAREC1  _PASTAE1  _LMTACT1  _LMTWRK1  _LMTSCL1  \\\n",
              "0       2.0       2.0      4.0       2.0       1.0       1.0       1.0   \n",
              "1       2.0       2.0      2.0       2.0       3.0       3.0       4.0   \n",
              "2       9.0       9.0      9.0       9.0       9.0       9.0       9.0   \n",
              "3       2.0       2.0      4.0       2.0       1.0       1.0       1.0   \n",
              "4       2.0       2.0      4.0       2.0       1.0       1.0       1.0   \n",
              "\n",
              "   _RFSEAT2  _RFSEAT3  _FLSHOT6  _PNEUMO2  _AIDTST3  \n",
              "0       1.0       1.0       NaN       NaN       1.0  \n",
              "1       2.0       2.0       NaN       NaN       2.0  \n",
              "2       9.0       9.0       9.0       9.0       NaN  \n",
              "3       1.0       1.0       NaN       NaN       9.0  \n",
              "4       1.0       1.0       NaN       NaN       1.0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qay9KFf4gg0K"
      },
      "source": [
        "### Select Relevant Subset of Features\n",
        "\n",
        "The dataset originally has 330 features (columns), but based on heart disease research regarding factors influencing heart disease, only select features are included in this analysis.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxXwUYlBitL3"
      },
      "source": [
        "#### Important Risk Factors\n",
        "Research in the field has identified the following as **important risk factors** for heart disease (not in strict order of importance):\n",
        "\n",
        "*   blood pressure (high)\n",
        "*   cholesterol (high)\n",
        "*   smoking\n",
        "*   diabetes\n",
        "*   obesity\n",
        "*   age\n",
        "*   sex\n",
        "*   race\n",
        "*   diet\n",
        "*   exercise\n",
        "*   alcohol consumption\n",
        "*   BMI\n",
        "*   Household Income\n",
        "*   Marital Status\n",
        "*   Sleep\n",
        "*   Time since last checkup\n",
        "*   Education\n",
        "*   Health care coverage\n",
        "*   Mental Health\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxTFj35AiyjD"
      },
      "source": [
        "#### Selected Subset of Features from BRFSS 2015\n",
        "Given these risk factors, I tried to select features (columns/questions) in the BRFSS related to these risk factors. To help understand what the columns mean, I consult the BRFSS 2015 Codebook to see the questions and information about the questions. I try to match the variable names in the codebook to the variable names in the dataset I downloaded from Kaggle. I also reference some of the same features chosen for a research paper by Zidian Xie et al for *Building Risk Prediction Models for Type 2 Diabetes Using Machine Learning Techniques* using the 2014 BRFSS. Diabetes and Heart Disease outcomes are strongly correlated, with the primary cause of death for diabetics being heart disease complications. Given this information, it is a useful starting point.\n",
        "\n",
        "**BRFSS 2015 Codebook:** https://www.cdc.gov/brfss/annual_data/2015/pdf/codebook15_llcp.pdf\n",
        "\n",
        "**Relevant Research Paper using BRFSS for Diabetes ML:** https://www.cdc.gov/pcd/issues/2019/19_0109.htm\n",
        "\n",
        "\n",
        "The **selected features** from the BRFSS 2015 dataset are:\n",
        "\n",
        "**Response Variable / Dependent Variable:**\n",
        "*   Respondents that have ever reported having coronary heart disease (CHD) or myocardial infarction (MI) --> _MICHD\n",
        "\n",
        "\n",
        "**Independent Variables:**\n",
        "\n",
        "**High Blood Pressure**\n",
        "*   Adults who have been told they have high blood pressure by a doctor, nurse, or other health professional --> _RFHYPE5\n",
        "\n",
        "**High Cholesterol**\n",
        "*   Have you EVER been told by a doctor, nurse or other health professional that your blood cholesterol is high? --> TOLDHI2\n",
        "*   Cholesterol check within past five years --> _CHOLCHK\n",
        "\n",
        "**BMI**\n",
        "*   Body Mass Index (BMI) --> _BMI5\n",
        "\n",
        "**Smoking**\n",
        "*   Have you smoked at least 100 cigarettes in your entire life? [Note: 5 packs = 100 cigarettes] --> SMOKE100\n",
        "\n",
        "**Other Chronic Health Conditions**\n",
        "*   (Ever told) you had a stroke. --> CVDSTRK3\n",
        "*   (Ever told) you have diabetes (If \"Yes\" and respondent is female, ask \"Was this only when you were pregnant?\". If Respondent says pre-diabetes or borderline diabetes, use response code 4.) --> DIABETE3\n",
        "\n",
        "**Physical Activity**\n",
        "*   Adults who reported doing physical activity or exercise during the past 30 days other than their regular job --> _TOTINDA\n",
        "\n",
        "**Diet**\n",
        "*   Consume Fruit 1 or more times per day --> _FRTLT1\n",
        "*   Consume Vegetables 1 or more times per day --> _VEGLT1\n",
        "\n",
        "**Alcohol Consumption**\n",
        "*   Heavy drinkers (adult men having more than 14 drinks per week and adult women having more than 7 drinks per week) --> _RFDRHV5\n",
        "\n",
        "**Health Care**\n",
        "*   Do you have any kind of health care coverage, including health insurance, prepaid plans such as HMOs, or government plans such as Medicare, or Indian Health Service?  --> HLTHPLN1\n",
        "*   Was there a time in the past 12 months when you needed to see a doctor but could not because of cost? --> MEDCOST\n",
        "\n",
        "**Health General and Mental Health**\n",
        "*   Would you say that in general your health is: --> GENHLTH\n",
        "*   Now thinking about your mental health, which includes stress, depression, and problems with emotions, for how many days during the past 30 days was your mental health not good? --> MENTHLTH\n",
        "*   Now thinking about your physical health, which includes physical illness and injury, for how many days during the past 30 days was your physical health not good? --> PHYSHLTH\n",
        "*   Do you have serious difficulty walking or climbing stairs? --> DIFFWALK\n",
        "\n",
        "**Demographics**\n",
        "*   Indicate sex of respondent. --> SEX\n",
        "*   Fourteen-level age category --> _AGEG5YR\n",
        "*   What is the highest grade or year of school you completed? --> EDUCA\n",
        "*   Is your annual household income from all sources: (If respondent refuses at any income level, code \"Refused.\") --> INCOME2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGQb0kEQHjpG"
      },
      "source": [
        "####Get Subset of Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BmPHgdSgT2w"
      },
      "source": [
        "# select specific columns\n",
        "brfss_df_selected = brfss_2015_dataset[['_MICHD', \n",
        "                                         '_RFHYPE5',  \n",
        "                                         'TOLDHI2', '_CHOLCHK', \n",
        "                                         '_BMI5', \n",
        "                                         'SMOKE100', \n",
        "                                         'CVDSTRK3', 'DIABETE3', \n",
        "                                         '_TOTINDA', \n",
        "                                         '_FRTLT1', '_VEGLT1', \n",
        "                                         '_RFDRHV5', \n",
        "                                         'HLTHPLN1', 'MEDCOST', \n",
        "                                         'GENHLTH', 'MENTHLTH', 'PHYSHLTH', 'DIFFWALK', \n",
        "                                         'SEX', '_AGEG5YR', 'EDUCA', 'INCOME2' ]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZGWjQoIree7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1f99c514-4263-429e-c527-1b9af7e3d0c3"
      },
      "source": [
        "brfss_df_selected.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(441456, 22)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGvPoELQjzUH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "6750579c-4ace-49c2-c7f9-ea080335cdbe"
      },
      "source": [
        "brfss_df_selected.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>_MICHD</th>\n",
              "      <th>_RFHYPE5</th>\n",
              "      <th>TOLDHI2</th>\n",
              "      <th>_CHOLCHK</th>\n",
              "      <th>_BMI5</th>\n",
              "      <th>SMOKE100</th>\n",
              "      <th>CVDSTRK3</th>\n",
              "      <th>DIABETE3</th>\n",
              "      <th>_TOTINDA</th>\n",
              "      <th>_FRTLT1</th>\n",
              "      <th>_VEGLT1</th>\n",
              "      <th>_RFDRHV5</th>\n",
              "      <th>HLTHPLN1</th>\n",
              "      <th>MEDCOST</th>\n",
              "      <th>GENHLTH</th>\n",
              "      <th>MENTHLTH</th>\n",
              "      <th>PHYSHLTH</th>\n",
              "      <th>DIFFWALK</th>\n",
              "      <th>SEX</th>\n",
              "      <th>_AGEG5YR</th>\n",
              "      <th>EDUCA</th>\n",
              "      <th>INCOME2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4018.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2509.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2204.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>99.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2819.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2437.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>77.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   _MICHD  _RFHYPE5  TOLDHI2  _CHOLCHK   _BMI5  SMOKE100  CVDSTRK3  DIABETE3  \\\n",
              "0     2.0       2.0      1.0       1.0  4018.0       1.0       2.0       3.0   \n",
              "1     2.0       1.0      2.0       2.0  2509.0       1.0       2.0       3.0   \n",
              "2     NaN       1.0      1.0       1.0  2204.0       NaN       1.0       3.0   \n",
              "3     2.0       2.0      1.0       1.0  2819.0       2.0       2.0       3.0   \n",
              "4     2.0       1.0      2.0       1.0  2437.0       2.0       2.0       3.0   \n",
              "\n",
              "   _TOTINDA  _FRTLT1  _VEGLT1  _RFDRHV5  HLTHPLN1  MEDCOST  GENHLTH  MENTHLTH  \\\n",
              "0       2.0      2.0      1.0       1.0       1.0      2.0      5.0      18.0   \n",
              "1       1.0      2.0      2.0       1.0       2.0      1.0      3.0      88.0   \n",
              "2       9.0      9.0      9.0       9.0       1.0      2.0      4.0      88.0   \n",
              "3       2.0      1.0      2.0       1.0       1.0      1.0      5.0      30.0   \n",
              "4       2.0      9.0      1.0       1.0       1.0      2.0      5.0      88.0   \n",
              "\n",
              "   PHYSHLTH  DIFFWALK  SEX  _AGEG5YR  EDUCA  INCOME2  \n",
              "0      15.0       1.0  2.0       9.0    4.0      3.0  \n",
              "1      88.0       2.0  2.0       7.0    6.0      1.0  \n",
              "2      15.0       NaN  2.0      11.0    4.0     99.0  \n",
              "3      30.0       1.0  2.0       9.0    4.0      8.0  \n",
              "4      20.0       2.0  2.0       9.0    5.0     77.0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRPUB2I1zdjl"
      },
      "source": [
        "### Cleaning the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unlVkPjf0zh7"
      },
      "source": [
        "####Missing Values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROIt4LK6kRln",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "41153e6e-eeac-4068-cefe-339f29f49d2f"
      },
      "source": [
        "#Drop Missing Values - knocks 100,000 rows out right away\n",
        "brfss_df_selected = brfss_df_selected.dropna()\n",
        "brfss_df_selected.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(343606, 22)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0KxsYALyYWN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "01dc72ca-8470-4c01-b35b-9c0646fea43e"
      },
      "source": [
        "brfss_df_selected.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>_MICHD</th>\n",
              "      <th>_RFHYPE5</th>\n",
              "      <th>TOLDHI2</th>\n",
              "      <th>_CHOLCHK</th>\n",
              "      <th>_BMI5</th>\n",
              "      <th>SMOKE100</th>\n",
              "      <th>CVDSTRK3</th>\n",
              "      <th>DIABETE3</th>\n",
              "      <th>_TOTINDA</th>\n",
              "      <th>_FRTLT1</th>\n",
              "      <th>_VEGLT1</th>\n",
              "      <th>_RFDRHV5</th>\n",
              "      <th>HLTHPLN1</th>\n",
              "      <th>MEDCOST</th>\n",
              "      <th>GENHLTH</th>\n",
              "      <th>MENTHLTH</th>\n",
              "      <th>PHYSHLTH</th>\n",
              "      <th>DIFFWALK</th>\n",
              "      <th>SEX</th>\n",
              "      <th>_AGEG5YR</th>\n",
              "      <th>EDUCA</th>\n",
              "      <th>INCOME2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4018.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2509.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2819.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2437.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>77.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2652.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   _MICHD  _RFHYPE5  TOLDHI2  _CHOLCHK   _BMI5  SMOKE100  CVDSTRK3  DIABETE3  \\\n",
              "0     2.0       2.0      1.0       1.0  4018.0       1.0       2.0       3.0   \n",
              "1     2.0       1.0      2.0       2.0  2509.0       1.0       2.0       3.0   \n",
              "3     2.0       2.0      1.0       1.0  2819.0       2.0       2.0       3.0   \n",
              "4     2.0       1.0      2.0       1.0  2437.0       2.0       2.0       3.0   \n",
              "5     2.0       2.0      2.0       1.0  2652.0       2.0       2.0       3.0   \n",
              "\n",
              "   _TOTINDA  _FRTLT1  _VEGLT1  _RFDRHV5  HLTHPLN1  MEDCOST  GENHLTH  MENTHLTH  \\\n",
              "0       2.0      2.0      1.0       1.0       1.0      2.0      5.0      18.0   \n",
              "1       1.0      2.0      2.0       1.0       2.0      1.0      3.0      88.0   \n",
              "3       2.0      1.0      2.0       1.0       1.0      1.0      5.0      30.0   \n",
              "4       2.0      9.0      1.0       1.0       1.0      2.0      5.0      88.0   \n",
              "5       1.0      1.0      1.0       1.0       1.0      2.0      2.0      88.0   \n",
              "\n",
              "   PHYSHLTH  DIFFWALK  SEX  _AGEG5YR  EDUCA  INCOME2  \n",
              "0      15.0       1.0  2.0       9.0    4.0      3.0  \n",
              "1      88.0       2.0  2.0       7.0    6.0      1.0  \n",
              "3      30.0       1.0  2.0       9.0    4.0      8.0  \n",
              "4      20.0       2.0  2.0       9.0    5.0     77.0  \n",
              "5      88.0       2.0  2.0      11.0    3.0      6.0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcTDYuv206kn"
      },
      "source": [
        "####Modifying Values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blBecp410Vyw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3a014475-81da-4dee-822b-cda1fb200e6b"
      },
      "source": [
        "# _MICHD\n",
        "#Change 2 to 0 because this means did not have MI or CHD\n",
        "brfss_df_selected['_MICHD'] = brfss_df_selected['_MICHD'].replace({2: 0})\n",
        "brfss_df_selected._MICHD.unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67919_rQ1JHU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "778916bb-8b99-4d17-edbf-aacd40cb880b"
      },
      "source": [
        "#1 _RFHYPE5\n",
        "#Change 1 to 0 so it represetnts No high blood pressure and 2 to 1 so it represents high blood pressure\n",
        "brfss_df_selected['_RFHYPE5'] = brfss_df_selected['_RFHYPE5'].replace({1:0, 2:1})\n",
        "brfss_df_selected = brfss_df_selected[brfss_df_selected._RFHYPE5 != 9]\n",
        "brfss_df_selected._RFHYPE5.unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZoLGBfq2uOV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7434520e-e5bd-4914-af18-bb4e39de35c2"
      },
      "source": [
        "#2 TOLDHI2\n",
        "# Change 2 to 0 because it is No\n",
        "# Remove all 7 (dont knows)\n",
        "# Remove all 9 (refused)\n",
        "brfss_df_selected['TOLDHI2'] = brfss_df_selected['TOLDHI2'].replace({2:0})\n",
        "brfss_df_selected = brfss_df_selected[brfss_df_selected.TOLDHI2 != 7]\n",
        "brfss_df_selected = brfss_df_selected[brfss_df_selected.TOLDHI2 != 9]\n",
        "brfss_df_selected.TOLDHI2.unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VZOv2BaLZU0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a9a30ce0-aded-4209-f465-0cc4602c2052"
      },
      "source": [
        "#3 _CHOLCHK\n",
        "# Change 3 to 0 and 2 to 0 for Not checked cholesterol in past 5 years\n",
        "# Remove 9\n",
        "brfss_df_selected['_CHOLCHK'] = brfss_df_selected['_CHOLCHK'].replace({3:0,2:0})\n",
        "brfss_df_selected = brfss_df_selected[brfss_df_selected._CHOLCHK != 9]\n",
        "brfss_df_selected._CHOLCHK.unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5R-hbiIMhcP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "19c8b163-dafa-4c43-f48c-d8ae01f7fb32"
      },
      "source": [
        "#4 _BMI5 (no changes, just note that these are BMI * 100. So for example a BMI of 4018 is really 40.18)\n",
        "brfss_df_selected['_BMI5'] = brfss_df_selected['_BMI5'].div(100).round(0)\n",
        "brfss_df_selected._BMI5.unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([40., 25., 28., 24., 27., 30., 26., 23., 34., 33., 21., 22., 31.,\n",
              "       38., 20., 19., 32., 46., 41., 37., 36., 29., 35., 18., 54., 45.,\n",
              "       39., 47., 43., 55., 49., 42., 17., 16., 48., 44., 50., 59., 15.,\n",
              "       52., 53., 57., 51., 14., 58., 63., 61., 56., 60., 74., 62., 64.,\n",
              "       13., 66., 73., 65., 68., 85., 71., 84., 67., 70., 82., 79., 92.,\n",
              "       72., 88., 96., 81., 12., 77., 95., 75., 91., 69., 76., 87., 89.,\n",
              "       83., 98., 86., 80., 90., 78., 97.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hinFMXZTNDnk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "19f544b5-2269-4184-a33d-9fe48f1451cf"
      },
      "source": [
        "#5 SMOKE100\n",
        "# Change 2 to 0 because it is No\n",
        "# Remove all 7 (dont knows)\n",
        "# Remove all 9 (refused)\n",
        "brfss_df_selected['SMOKE100'] = brfss_df_selected['SMOKE100'].replace({2:0})\n",
        "brfss_df_selected = brfss_df_selected[brfss_df_selected.SMOKE100 != 7]\n",
        "brfss_df_selected = brfss_df_selected[brfss_df_selected.SMOKE100 != 9]\n",
        "brfss_df_selected.SMOKE100.unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Q5kMiDnNw76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "45c93e43-469f-4587-abf9-72dddbffe1fa"
      },
      "source": [
        "#6 CVDSTRK3\n",
        "# Change 2 to 0 because it is No\n",
        "# Remove all 7 (dont knows)\n",
        "# Remove all 9 (refused)\n",
        "brfss_df_selected['CVDSTRK3'] = brfss_df_selected['CVDSTRK3'].replace({2:0})\n",
        "brfss_df_selected = brfss_df_selected[brfss_df_selected.CVDSTRK3 != 7]\n",
        "brfss_df_selected = brfss_df_selected[brfss_df_selected.CVDSTRK3 != 9]\n",
        "brfss_df_selected.CVDSTRK3.unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPztu3fpOH_8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4a6d1ccb-747f-4702-d1be-b2886ce1ce30"
      },
      "source": [
        "#7 DIABETE3\n",
        "# going to make this ordinal. 0 is for no diabetes or only during pregnancy, 1 is for pre-diabetes or borderline diabetes, 2 is for yes diabetes\n",
        "# Remove all 7 (dont knows)\n",
        "# Remove all 9 (refused)\n",
        "brfss_df_selected['DIABETE3'] = brfss_df_selected['DIABETE3'].replace({2:0, 3:0, 1:2, 4:1})\n",
        "brfss_df_selected = brfss_df_selected[brfss_df_selected.DIABETE3 != 7]\n",
        "brfss_df_selected = brfss_df_selected[brfss_df_selected.DIABETE3 != 9]\n",
        "brfss_df_selected.DIABETE3.unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 2., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIJqBL3EPiow",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "413a1e5d-9c79-4bb0-daf3-f1a55ff321a3"
      },
      "source": [
        "#8 _TOTINDA\n",
        "# 1 for physical activity\n",
        "# change 2 to 0 for no physical activity\n",
        "# Remove all 9 (don't know/refused)\n",
        "brfss_df_selected['_TOTINDA'] = brfss_df_selected['_TOTINDA'].replace({2:0})\n",
        "brfss_df_selected = brfss_df_selected[brfss_df_selected._TOTINDA != 9]\n",
        "brfss_df_selected._TOTINDA.unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EYucZDKQSeo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7aa76535-7891-4cb2-e4d3-4378d852ba41"
      },
      "source": [
        "#9 _FRTLT1\n",
        "# Change 2 to 0. this means no fruit consumed per day. 1 will mean consumed 1 or more pieces of fruit per day \n",
        "# remove all dont knows and missing 9\n",
        "brfss_df_selected['_FRTLT1'] = brfss_df_selected['_FRTLT1'].replace({2:0})\n",
        "brfss_df_selected = brfss_df_selected[brfss_df_selected._FRTLT1 != 9]\n",
        "brfss_df_selected._FRTLT1.unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpCGcx_NRAhJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fb8ff83c-9210-4e05-fdcb-7d6d9a0c6d97"
      },
      "source": [
        "#10 _VEGLT1\n",
        "# Change 2 to 0. this means no vegetables consumed per day. 1 will mean consumed 1 or more pieces of vegetable per day \n",
        "# remove all dont knows and missing 9\n",
        "brfss_df_selected['_VEGLT1'] = brfss_df_selected['_VEGLT1'].replace({2:0})\n",
        "brfss_df_selected = brfss_df_selected[brfss_df_selected._VEGLT1 != 9]\n",
        "brfss_df_selected._VEGLT1.unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEkYqHoDRm4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "00d55330-b06d-4f22-8ef4-c9c0d0c72c91"
      },
      "source": [
        "#11 _RFDRHV5\n",
        "# Change 1 to 0 (1 was no for heavy drinking). change all 2 to 1 (2 was yes for heavy drinking)\n",
        "# remove all dont knows and missing 9\n",
        "brfss_df_selected['_RFDRHV5'] = brfss_df_selected['_RFDRHV5'].replace({1:0, 2:1})\n",
        "brfss_df_selected = brfss_df_selected[brfss_df_selected._RFDRHV5 != 9]\n",
        "brfss_df_selected._RFDRHV5.unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNO16De8SBEt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b124b5a5-a503-48c0-fc97-91890e9b5472"
      },
      "source": [
        "#12 HLTHPLN1\n",
        "# 1 is yes, change 2 to 0 because it is No health care access\n",
        "# remove 7 and 9 for don't know or refused\n",
        "brfss_df_selected['HLTHPLN1'] = brfss_df_selected['HLTHPLN1'].replace({2:0})\n",
        "brfss_df_selected = brfss_df_selected[brfss_df_selected.HLTHPLN1 != 7]\n",
        "brfss_df_selected = brfss_df_selected[brfss_df_selected.HLTHPLN1 != 9]\n",
        "brfss_df_selected.HLTHPLN1.unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgFtHLP8dgdx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f798dc89-fbcb-4396-c3dc-65b1561049dc"
      },
      "source": [
        "#13 MEDCOST\n",
        "# Change 2 to 0 for no, 1 is already yes\n",
        "# remove 7 for don/t know and 9 for refused\n",
        "brfss_df_selected['MEDCOST'] = brfss_df_selected['MEDCOST'].replace({2:0})\n",
        "brfss_df_selected = brfss_df_selected[brfss_df_selected.MEDCOST != 7]\n",
        "brfss_df_selected = brfss_df_selected[brfss_df_selected.MEDCOST != 9]\n",
        "brfss_df_selected.MEDCOST.unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deh43iCyeKPW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b3a52e98-9ed1-458c-c84d-b4c413f4ad62"
      },
      "source": [
        "#14 GENHLTH\n",
        "# This is an ordinal variable that I want to keep (1 is Excellent -> 5 is Poor)\n",
        "# Remove 7 and 9 for don't know and refused\n",
        "brfss_df_selected = brfss_df_selected[brfss_df_selected.GENHLTH != 7]\n",
        "brfss_df_selected = brfss_df_selected[brfss_df_selected.GENHLTH != 9]\n",
        "brfss_df_selected.GENHLTH.unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5., 3., 2., 4., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Buk40s5ae1Fq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "0fc2eec4-5b52-43b1-d877-46c0b3f45e16"
      },
      "source": [
        "#15 MENTHLTH\n",
        "# already in days so keep that, scale will be 0-30\n",
        "# change 88 to 0 because it means none (no bad mental health days)\n",
        "# remove 77 and 99 for don't know not sure and refused\n",
        "brfss_df_selected['MENTHLTH'] = brfss_df_selected['MENTHLTH'].replace({88:0})\n",
        "brfss_df_selected = brfss_df_selected[brfss_df_selected.MENTHLTH != 77]\n",
        "brfss_df_selected = brfss_df_selected[brfss_df_selected.MENTHLTH != 99]\n",
        "brfss_df_selected.MENTHLTH.unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([18.,  0., 30.,  3.,  5., 15., 10.,  6., 20.,  2., 25.,  1., 29.,\n",
              "        4.,  7.,  8., 21., 14., 26.,  9., 16., 28., 11., 12., 24., 17.,\n",
              "       13., 23., 27., 19., 22.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aj52MPd3oy9w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "15b4415a-7961-4b64-ae03-c3f32689b8de"
      },
      "source": [
        "#16 PHYSHLTH\n",
        "# already in days so keep that, scale will be 0-30\n",
        "# change 88 to 0 because it means none (no bad mental health days)\n",
        "# remove 77 and 99 for don't know not sure and refused\n",
        "brfss_df_selected['PHYSHLTH'] = brfss_df_selected['PHYSHLTH'].replace({88:0})\n",
        "brfss_df_selected = brfss_df_selected[brfss_df_selected.PHYSHLTH != 77]\n",
        "brfss_df_selected = brfss_df_selected[brfss_df_selected.PHYSHLTH != 99]\n",
        "brfss_df_selected.PHYSHLTH.unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([15.,  0., 30.,  2., 14., 28.,  7., 20.,  3., 10.,  1.,  5., 17.,\n",
              "        4., 19.,  6., 21., 12.,  8., 25., 27., 22., 29., 24.,  9., 16.,\n",
              "       18., 23., 13., 26., 11.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFNUbnyfpUMp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b879e78c-fe3a-413d-cf36-38521443bb58"
      },
      "source": [
        "#17 DIFFWALK\n",
        "# change 2 to 0 for no. 1 is already yes\n",
        "# remove 7 and 9 for don't know not sure and refused\n",
        "brfss_df_selected['DIFFWALK'] = brfss_df_selected['DIFFWALK'].replace({2:0})\n",
        "brfss_df_selected = brfss_df_selected[brfss_df_selected.DIFFWALK != 7]\n",
        "brfss_df_selected = brfss_df_selected[brfss_df_selected.DIFFWALK != 9]\n",
        "brfss_df_selected.DIFFWALK.unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMhII7O0pq2C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "06b14bb9-1d4a-4135-e9fc-107ae8f0ea83"
      },
      "source": [
        "#18 SEX\n",
        "# in other words - is respondent male (somewhat arbitrarily chose this change because men are at higher risk for heart disease)\n",
        "# change 2 to 0 (female as 0). Male is 1\n",
        "brfss_df_selected['SEX'] = brfss_df_selected['SEX'].replace({2:0})\n",
        "brfss_df_selected.SEX.unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Up4csI8ZqXJe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "403ac391-3f01-4547-eb98-6c77efd45159"
      },
      "source": [
        "#19 _AGEG5YR\n",
        "# already ordinal. 1 is 18-24 all the way up to 13 wis 80 and older. 5 year increments.\n",
        "# remove 14 because it is don't know or missing\n",
        "brfss_df_selected = brfss_df_selected[brfss_df_selected._AGEG5YR != 14]\n",
        "brfss_df_selected._AGEG5YR.unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 9.,  7., 11., 10., 13.,  8.,  4.,  6.,  2., 12.,  5.,  1.,  3.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xa6x8-JjrNYG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "052adaf3-80f5-45e0-87ea-094a4e0413cd"
      },
      "source": [
        "#20 EDUCA\n",
        "# This is already an ordinal variable with 1 being never attended school or kindergarten only up to 6 being college 4 years or more\n",
        "# Scale here is 1-6\n",
        "# Remove 9 for refused:\n",
        "brfss_df_selected = brfss_df_selected[brfss_df_selected.EDUCA != 9]\n",
        "brfss_df_selected.EDUCA.unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4., 6., 3., 5., 2., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imr2psFzv0jA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2bbb1b86-1c76-4154-e545-aba11262191c"
      },
      "source": [
        "#21 INCOME2\n",
        "# Variable is already ordinal with 1 being less than $10,000 all the way up to 8 being $75,000 or more\n",
        "# Remove 77 and 99 for don't know and refused\n",
        "brfss_df_selected = brfss_df_selected[brfss_df_selected.INCOME2 != 77]\n",
        "brfss_df_selected = brfss_df_selected[brfss_df_selected.INCOME2 != 99]\n",
        "brfss_df_selected.INCOME2.unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3., 1., 8., 6., 4., 7., 2., 5.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YC7WB5jb3DDj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4a43b38f-b4ac-4cbc-d6ef-8211c7caab85"
      },
      "source": [
        "#Check the shape of the dataset now: We have 253,680 cleaned rows and 22 columns (1 of which is our dependent variable)\n",
        "brfss_df_selected.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(253680, 22)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IucXUK1C2ReC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "1937ad64-2bf7-4311-9724-953d60bbcc0a"
      },
      "source": [
        "#Let's see what the data looks like after Modifying Values\n",
        "brfss_df_selected.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>_MICHD</th>\n",
              "      <th>_RFHYPE5</th>\n",
              "      <th>TOLDHI2</th>\n",
              "      <th>_CHOLCHK</th>\n",
              "      <th>_BMI5</th>\n",
              "      <th>SMOKE100</th>\n",
              "      <th>CVDSTRK3</th>\n",
              "      <th>DIABETE3</th>\n",
              "      <th>_TOTINDA</th>\n",
              "      <th>_FRTLT1</th>\n",
              "      <th>_VEGLT1</th>\n",
              "      <th>_RFDRHV5</th>\n",
              "      <th>HLTHPLN1</th>\n",
              "      <th>MEDCOST</th>\n",
              "      <th>GENHLTH</th>\n",
              "      <th>MENTHLTH</th>\n",
              "      <th>PHYSHLTH</th>\n",
              "      <th>DIFFWALK</th>\n",
              "      <th>SEX</th>\n",
              "      <th>_AGEG5YR</th>\n",
              "      <th>EDUCA</th>\n",
              "      <th>INCOME2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    _MICHD  _RFHYPE5  TOLDHI2  _CHOLCHK  _BMI5  SMOKE100  CVDSTRK3  DIABETE3  \\\n",
              "0      0.0       1.0      1.0       1.0   40.0       1.0       0.0       0.0   \n",
              "1      0.0       0.0      0.0       0.0   25.0       1.0       0.0       0.0   \n",
              "3      0.0       1.0      1.0       1.0   28.0       0.0       0.0       0.0   \n",
              "5      0.0       1.0      0.0       1.0   27.0       0.0       0.0       0.0   \n",
              "6      0.0       1.0      1.0       1.0   24.0       0.0       0.0       0.0   \n",
              "9      0.0       1.0      1.0       1.0   25.0       1.0       0.0       0.0   \n",
              "10     0.0       1.0      0.0       1.0   30.0       1.0       0.0       0.0   \n",
              "15     0.0       1.0      1.0       1.0   25.0       1.0       0.0       0.0   \n",
              "16     1.0       1.0      1.0       1.0   30.0       1.0       0.0       2.0   \n",
              "19     0.0       0.0      0.0       1.0   24.0       0.0       0.0       0.0   \n",
              "\n",
              "    _TOTINDA  _FRTLT1  _VEGLT1  _RFDRHV5  HLTHPLN1  MEDCOST  GENHLTH  \\\n",
              "0        0.0      0.0      1.0       0.0       1.0      0.0      5.0   \n",
              "1        1.0      0.0      0.0       0.0       0.0      1.0      3.0   \n",
              "3        0.0      1.0      0.0       0.0       1.0      1.0      5.0   \n",
              "5        1.0      1.0      1.0       0.0       1.0      0.0      2.0   \n",
              "6        1.0      1.0      1.0       0.0       1.0      0.0      2.0   \n",
              "9        1.0      1.0      1.0       0.0       1.0      0.0      2.0   \n",
              "10       0.0      0.0      0.0       0.0       1.0      0.0      3.0   \n",
              "15       1.0      0.0      1.0       0.0       1.0      0.0      3.0   \n",
              "16       0.0      1.0      1.0       0.0       1.0      0.0      5.0   \n",
              "19       0.0      0.0      1.0       0.0       1.0      0.0      2.0   \n",
              "\n",
              "    MENTHLTH  PHYSHLTH  DIFFWALK  SEX  _AGEG5YR  EDUCA  INCOME2  \n",
              "0       18.0      15.0       1.0  0.0       9.0    4.0      3.0  \n",
              "1        0.0       0.0       0.0  0.0       7.0    6.0      1.0  \n",
              "3       30.0      30.0       1.0  0.0       9.0    4.0      8.0  \n",
              "5        0.0       0.0       0.0  0.0      11.0    3.0      6.0  \n",
              "6        3.0       0.0       0.0  0.0      11.0    5.0      4.0  \n",
              "9        0.0       2.0       0.0  1.0      10.0    6.0      8.0  \n",
              "10       0.0      14.0       0.0  0.0       9.0    6.0      7.0  \n",
              "15       0.0       0.0       1.0  0.0      11.0    4.0      4.0  \n",
              "16      30.0      30.0       1.0  0.0       9.0    5.0      1.0  \n",
              "19       0.0       0.0       0.0  1.0       8.0    4.0      3.0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWt_1G9gKtUE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "d80370ca-5baf-4846-ff03-b7731864415b"
      },
      "source": [
        " #Check Class Sizes\n",
        " brfss_df_selected.groupby(['_MICHD']).size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "_MICHD\n",
              "0.0    229787\n",
              "1.0     23893\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kVmXvCHx3Kb"
      },
      "source": [
        "####Make Feature Names More Readable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAIsY3Offgsw"
      },
      "source": [
        " #Rename the columns to make them more readable\n",
        " brfss = brfss_df_selected.rename(columns = {'_MICHD':'HeartDiseaseorAttack', \n",
        "                                         '_RFHYPE5':'HighBP',  \n",
        "                                         'TOLDHI2':'HighChol', '_CHOLCHK':'CholCheck', \n",
        "                                         '_BMI5':'BMI', \n",
        "                                         'SMOKE100':'Smoker', \n",
        "                                         'CVDSTRK3':'Stroke', 'DIABETE3':'Diabetes', \n",
        "                                         '_TOTINDA':'PhysActivity', \n",
        "                                         '_FRTLT1':'Fruits', '_VEGLT1':\"Veggies\", \n",
        "                                         '_RFDRHV5':'HvyAlcoholConsump', \n",
        "                                         'HLTHPLN1':'AnyHealthcare', 'MEDCOST':'NoDocbcCost', \n",
        "                                         'GENHLTH':'GenHlth', 'MENTHLTH':'MentHlth', 'PHYSHLTH':'PhysHlth', 'DIFFWALK':'DiffWalk', \n",
        "                                         'SEX':'Sex', '_AGEG5YR':'Age', 'EDUCA':'Education', 'INCOME2':'Income' })"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAE4OwUrpyjm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "5f35afc1-250d-4209-aee1-b05f79e55370"
      },
      "source": [
        "#See the cleaned dataset with \n",
        "brfss.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>HeartDiseaseorAttack</th>\n",
              "      <th>HighBP</th>\n",
              "      <th>HighChol</th>\n",
              "      <th>CholCheck</th>\n",
              "      <th>BMI</th>\n",
              "      <th>Smoker</th>\n",
              "      <th>Stroke</th>\n",
              "      <th>Diabetes</th>\n",
              "      <th>PhysActivity</th>\n",
              "      <th>Fruits</th>\n",
              "      <th>Veggies</th>\n",
              "      <th>HvyAlcoholConsump</th>\n",
              "      <th>AnyHealthcare</th>\n",
              "      <th>NoDocbcCost</th>\n",
              "      <th>GenHlth</th>\n",
              "      <th>MentHlth</th>\n",
              "      <th>PhysHlth</th>\n",
              "      <th>DiffWalk</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>Education</th>\n",
              "      <th>Income</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    HeartDiseaseorAttack  HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  \\\n",
              "0                    0.0     1.0       1.0        1.0  40.0     1.0     0.0   \n",
              "1                    0.0     0.0       0.0        0.0  25.0     1.0     0.0   \n",
              "3                    0.0     1.0       1.0        1.0  28.0     0.0     0.0   \n",
              "5                    0.0     1.0       0.0        1.0  27.0     0.0     0.0   \n",
              "6                    0.0     1.0       1.0        1.0  24.0     0.0     0.0   \n",
              "9                    0.0     1.0       1.0        1.0  25.0     1.0     0.0   \n",
              "10                   0.0     1.0       0.0        1.0  30.0     1.0     0.0   \n",
              "15                   0.0     1.0       1.0        1.0  25.0     1.0     0.0   \n",
              "16                   1.0     1.0       1.0        1.0  30.0     1.0     0.0   \n",
              "19                   0.0     0.0       0.0        1.0  24.0     0.0     0.0   \n",
              "\n",
              "    Diabetes  PhysActivity  Fruits  Veggies  HvyAlcoholConsump  AnyHealthcare  \\\n",
              "0        0.0           0.0     0.0      1.0                0.0            1.0   \n",
              "1        0.0           1.0     0.0      0.0                0.0            0.0   \n",
              "3        0.0           0.0     1.0      0.0                0.0            1.0   \n",
              "5        0.0           1.0     1.0      1.0                0.0            1.0   \n",
              "6        0.0           1.0     1.0      1.0                0.0            1.0   \n",
              "9        0.0           1.0     1.0      1.0                0.0            1.0   \n",
              "10       0.0           0.0     0.0      0.0                0.0            1.0   \n",
              "15       0.0           1.0     0.0      1.0                0.0            1.0   \n",
              "16       2.0           0.0     1.0      1.0                0.0            1.0   \n",
              "19       0.0           0.0     0.0      1.0                0.0            1.0   \n",
              "\n",
              "    NoDocbcCost  GenHlth  MentHlth  PhysHlth  DiffWalk  Sex   Age  Education  \\\n",
              "0           0.0      5.0      18.0      15.0       1.0  0.0   9.0        4.0   \n",
              "1           1.0      3.0       0.0       0.0       0.0  0.0   7.0        6.0   \n",
              "3           1.0      5.0      30.0      30.0       1.0  0.0   9.0        4.0   \n",
              "5           0.0      2.0       0.0       0.0       0.0  0.0  11.0        3.0   \n",
              "6           0.0      2.0       3.0       0.0       0.0  0.0  11.0        5.0   \n",
              "9           0.0      2.0       0.0       2.0       0.0  1.0  10.0        6.0   \n",
              "10          0.0      3.0       0.0      14.0       0.0  0.0   9.0        6.0   \n",
              "15          0.0      3.0       0.0       0.0       1.0  0.0  11.0        4.0   \n",
              "16          0.0      5.0      30.0      30.0       1.0  0.0   9.0        5.0   \n",
              "19          0.0      2.0       0.0       0.0       0.0  1.0   8.0        4.0   \n",
              "\n",
              "    Income  \n",
              "0      3.0  \n",
              "1      1.0  \n",
              "3      8.0  \n",
              "5      6.0  \n",
              "6      4.0  \n",
              "9      8.0  \n",
              "10     7.0  \n",
              "15     4.0  \n",
              "16     1.0  \n",
              "19     3.0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmBfrX_Ss8cG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1eb56b3d-8a7d-40b6-ce41-24fe9e006ea7"
      },
      "source": [
        "#Double check shape of the dataset (rows and columns)\n",
        "brfss.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(253680, 22)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJoX16tY9qq3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "7d8b0e25-23e8-4553-ed99-85efb24fdf57"
      },
      "source": [
        " #Check how many respondents have had heart disease or a heart attack. Note the class imbalance!\n",
        " brfss.groupby(['HeartDiseaseorAttack']).size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HeartDiseaseorAttack\n",
              "0.0    229787\n",
              "1.0     23893\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJ2CXYf5BimQ"
      },
      "source": [
        "#### Save Finalized Dataset to CSV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LoL8_01-4pv"
      },
      "source": [
        "#************************************************************************************************\n",
        "brfss.to_csv('brfss2015_cleaned.csv', sep=\",\", index=False)\n",
        "#************************************************************************************************"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCeBJRyMaGio"
      },
      "source": [
        "#### Get a BALANCED 50-50 Dataset Randomly Selected\n",
        "*  The brfss dataset is clearly imbalanced. When training my models, I get about 90% accuracy on many models with AUC between 70 and 80. This may be caused by the models are learning the distribution in the data. \n",
        "*  To check these concerns, I will create a second dataset with a 50-50 balance for the HeartDiseaseorAttack response variable - just to compare performance. \n",
        "*  To do this, I will take a random sample of 23,893 instances of the 0 (or No heart Disease / Attack) and all of the 23,893 instances of the 1 (or Yes Heart Disease / Attack).\n",
        "* The if the new dataset performs comparably, then I can rest assured that it\n",
        "* With roughly 48,000 datapoints, I hope that this is sufficient to train the model and that the random selection will not greatly change the results. I have the random seed set to 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHLkrTgsaH08"
      },
      "source": [
        "#Separate the 0 and 1\n",
        "\n",
        "#Get the 1s\n",
        "is1 = brfss['HeartDiseaseorAttack'] == 1\n",
        "brfss_5050_1 = brfss[is1]\n",
        "\n",
        "#Get the 0s\n",
        "is0 = brfss['HeartDiseaseorAttack'] == 0\n",
        "brfss_5050_0 = brfss[is0] \n",
        "\n",
        "#Select the 23893 random cases for 0\n",
        "brfss_5050_0_rand1 = brfss_5050_0.take(np.random.permutation(len(brfss_5050_0))[:23893])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Je48a7lshFke"
      },
      "source": [
        "#Append the 23893 1s to the 23893 randomly selected 0s\n",
        "brfss_5050 = brfss_5050_0_rand1.append(brfss_5050_1, ignore_index = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKcAPE0Vfpyp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48271a9e-c38f-440b-edb0-92d7448f9de5"
      },
      "source": [
        "#Check that it worked. Now we have a dataset of 47,786 rows that is equally balanced with 50% 1 and 50% 0 for the target variable HeartDiseaseorAttack\n",
        "brfss_5050"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>HeartDiseaseorAttack</th>\n",
              "      <th>HighBP</th>\n",
              "      <th>HighChol</th>\n",
              "      <th>CholCheck</th>\n",
              "      <th>BMI</th>\n",
              "      <th>Smoker</th>\n",
              "      <th>Stroke</th>\n",
              "      <th>Diabetes</th>\n",
              "      <th>PhysActivity</th>\n",
              "      <th>Fruits</th>\n",
              "      <th>Veggies</th>\n",
              "      <th>HvyAlcoholConsump</th>\n",
              "      <th>AnyHealthcare</th>\n",
              "      <th>NoDocbcCost</th>\n",
              "      <th>GenHlth</th>\n",
              "      <th>MentHlth</th>\n",
              "      <th>PhysHlth</th>\n",
              "      <th>DiffWalk</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>Education</th>\n",
              "      <th>Income</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47781</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47782</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47783</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47784</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47785</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>47786 rows × 22 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       HeartDiseaseorAttack  HighBP  HighChol  CholCheck   BMI  Smoker  \\\n",
              "0                       0.0     0.0       0.0        1.0  28.0     1.0   \n",
              "1                       0.0     0.0       0.0        1.0  26.0     0.0   \n",
              "2                       0.0     0.0       1.0        1.0  27.0     1.0   \n",
              "3                       0.0     0.0       0.0        1.0  20.0     0.0   \n",
              "4                       0.0     1.0       0.0        1.0  40.0     0.0   \n",
              "...                     ...     ...       ...        ...   ...     ...   \n",
              "47781                   1.0     0.0       1.0        1.0  29.0     1.0   \n",
              "47782                   1.0     1.0       1.0        1.0  25.0     0.0   \n",
              "47783                   1.0     1.0       1.0        1.0  23.0     0.0   \n",
              "47784                   1.0     1.0       0.0        1.0  30.0     1.0   \n",
              "47785                   1.0     1.0       1.0        1.0  25.0     0.0   \n",
              "\n",
              "       Stroke  Diabetes  PhysActivity  Fruits  Veggies  HvyAlcoholConsump  \\\n",
              "0         0.0       0.0           1.0     1.0      1.0                0.0   \n",
              "1         0.0       0.0           1.0     1.0      1.0                0.0   \n",
              "2         0.0       0.0           1.0     0.0      1.0                0.0   \n",
              "3         0.0       0.0           1.0     1.0      1.0                0.0   \n",
              "4         0.0       2.0           1.0     1.0      0.0                0.0   \n",
              "...       ...       ...           ...     ...      ...                ...   \n",
              "47781     0.0       2.0           0.0     1.0      1.0                0.0   \n",
              "47782     0.0       2.0           0.0     1.0      0.0                0.0   \n",
              "47783     1.0       0.0           0.0     0.0      0.0                0.0   \n",
              "47784     0.0       0.0           1.0     1.0      1.0                0.0   \n",
              "47785     0.0       2.0           1.0     1.0      0.0                0.0   \n",
              "\n",
              "       AnyHealthcare  NoDocbcCost  GenHlth  MentHlth  PhysHlth  DiffWalk  Sex  \\\n",
              "0                1.0          1.0      5.0      30.0      30.0       1.0  1.0   \n",
              "1                1.0          0.0      2.0       0.0       0.0       0.0  0.0   \n",
              "2                0.0          0.0      1.0       0.0       0.0       0.0  1.0   \n",
              "3                1.0          0.0      2.0       4.0       2.0       0.0  0.0   \n",
              "4                1.0          1.0      1.0       0.0       1.0       0.0  0.0   \n",
              "...              ...          ...      ...       ...       ...       ...  ...   \n",
              "47781            1.0          0.0      2.0       0.0       0.0       1.0  1.0   \n",
              "47782            1.0          0.0      5.0      15.0       0.0       1.0  0.0   \n",
              "47783            1.0          1.0      4.0       0.0       5.0       0.0  1.0   \n",
              "47784            1.0          0.0      3.0       0.0       0.0       0.0  1.0   \n",
              "47785            1.0          0.0      2.0       0.0       0.0       0.0  0.0   \n",
              "\n",
              "        Age  Education  Income  \n",
              "0       8.0        6.0     5.0  \n",
              "1       4.0        6.0     8.0  \n",
              "2       9.0        6.0     8.0  \n",
              "3       6.0        6.0     8.0  \n",
              "4       4.0        4.0     2.0  \n",
              "...     ...        ...     ...  \n",
              "47781  10.0        3.0     6.0  \n",
              "47782  13.0        6.0     4.0  \n",
              "47783   8.0        3.0     2.0  \n",
              "47784  12.0        2.0     1.0  \n",
              "47785   9.0        6.0     2.0  \n",
              "\n",
              "[47786 rows x 22 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MklB0DbKicGs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2e4bca9-39fc-49f3-df37-8fbfea23064b"
      },
      "source": [
        "#See the classes are perfectly balanced now\n",
        "brfss_5050.groupby(['HeartDiseaseorAttack']).size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HeartDiseaseorAttack\n",
              "0.0    23893\n",
              "1.0    23893\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWhJLzPfil9Q"
      },
      "source": [
        "#Save the 50-50 balanced dataset to csv\n",
        "\n",
        "#************************************************************************************************\n",
        "brfss_5050.to_csv('brfss2015_5050_cleaned.csv', sep=\",\", index=False)\n",
        "#************************************************************************************************"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LE4FUQGkpihm"
      },
      "source": [
        "#### Also Get a 60-40 Dataset Randomly Selected"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnZO1Eojo6Dm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d25fe8c8-8cc5-4f9e-f09a-fe831404d5a5"
      },
      "source": [
        "#Also make a 60-40 dataset\n",
        "brfss_6040_0_rand1 = brfss_5050_0.take(np.random.permutation(len(brfss_5050_0))[:47786])\n",
        "brfss_6040 = brfss_6040_0_rand1.append(brfss_5050_1, ignore_index = True)\n",
        "#Save the 6040 balanced dataset to csv\n",
        "#************************************************************************************************\n",
        "brfss_6040.to_csv('brfss2015_6040_cleaned.csv', sep=\",\", index=False)\n",
        "#************************************************************************************************\n",
        "brfss_6040"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>HeartDiseaseorAttack</th>\n",
              "      <th>HighBP</th>\n",
              "      <th>HighChol</th>\n",
              "      <th>CholCheck</th>\n",
              "      <th>BMI</th>\n",
              "      <th>Smoker</th>\n",
              "      <th>Stroke</th>\n",
              "      <th>Diabetes</th>\n",
              "      <th>PhysActivity</th>\n",
              "      <th>Fruits</th>\n",
              "      <th>Veggies</th>\n",
              "      <th>HvyAlcoholConsump</th>\n",
              "      <th>AnyHealthcare</th>\n",
              "      <th>NoDocbcCost</th>\n",
              "      <th>GenHlth</th>\n",
              "      <th>MentHlth</th>\n",
              "      <th>PhysHlth</th>\n",
              "      <th>DiffWalk</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>Education</th>\n",
              "      <th>Income</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71674</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71675</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71676</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71677</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71678</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>71679 rows × 22 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       HeartDiseaseorAttack  HighBP  HighChol  CholCheck   BMI  Smoker  \\\n",
              "0                       0.0     0.0       0.0        1.0  29.0     1.0   \n",
              "1                       0.0     1.0       0.0        1.0  31.0     0.0   \n",
              "2                       0.0     0.0       0.0        1.0  17.0     1.0   \n",
              "3                       0.0     1.0       0.0        1.0  24.0     0.0   \n",
              "4                       0.0     0.0       1.0        1.0  22.0     0.0   \n",
              "...                     ...     ...       ...        ...   ...     ...   \n",
              "71674                   1.0     0.0       1.0        1.0  29.0     1.0   \n",
              "71675                   1.0     1.0       1.0        1.0  25.0     0.0   \n",
              "71676                   1.0     1.0       1.0        1.0  23.0     0.0   \n",
              "71677                   1.0     1.0       0.0        1.0  30.0     1.0   \n",
              "71678                   1.0     1.0       1.0        1.0  25.0     0.0   \n",
              "\n",
              "       Stroke  Diabetes  PhysActivity  Fruits  Veggies  HvyAlcoholConsump  \\\n",
              "0         0.0       0.0           1.0     1.0      1.0                0.0   \n",
              "1         0.0       2.0           1.0     1.0      1.0                0.0   \n",
              "2         0.0       0.0           1.0     1.0      1.0                0.0   \n",
              "3         0.0       0.0           1.0     0.0      1.0                1.0   \n",
              "4         0.0       0.0           0.0     0.0      1.0                0.0   \n",
              "...       ...       ...           ...     ...      ...                ...   \n",
              "71674     0.0       2.0           0.0     1.0      1.0                0.0   \n",
              "71675     0.0       2.0           0.0     1.0      0.0                0.0   \n",
              "71676     1.0       0.0           0.0     0.0      0.0                0.0   \n",
              "71677     0.0       0.0           1.0     1.0      1.0                0.0   \n",
              "71678     0.0       2.0           1.0     1.0      0.0                0.0   \n",
              "\n",
              "       AnyHealthcare  NoDocbcCost  GenHlth  MentHlth  PhysHlth  DiffWalk  Sex  \\\n",
              "0                1.0          0.0      2.0       1.0       0.0       0.0  0.0   \n",
              "1                1.0          0.0      2.0       0.0       0.0       0.0  0.0   \n",
              "2                1.0          0.0      1.0       0.0       0.0       0.0  0.0   \n",
              "3                1.0          0.0      2.0       0.0       0.0       0.0  0.0   \n",
              "4                1.0          0.0      3.0       0.0       2.0       0.0  1.0   \n",
              "...              ...          ...      ...       ...       ...       ...  ...   \n",
              "71674            1.0          0.0      2.0       0.0       0.0       1.0  1.0   \n",
              "71675            1.0          0.0      5.0      15.0       0.0       1.0  0.0   \n",
              "71676            1.0          1.0      4.0       0.0       5.0       0.0  1.0   \n",
              "71677            1.0          0.0      3.0       0.0       0.0       0.0  1.0   \n",
              "71678            1.0          0.0      2.0       0.0       0.0       0.0  0.0   \n",
              "\n",
              "        Age  Education  Income  \n",
              "0      10.0        6.0     8.0  \n",
              "1      12.0        5.0     3.0  \n",
              "2      11.0        6.0     6.0  \n",
              "3      10.0        4.0     7.0  \n",
              "4       6.0        6.0     7.0  \n",
              "...     ...        ...     ...  \n",
              "71674  10.0        3.0     6.0  \n",
              "71675  13.0        6.0     4.0  \n",
              "71676   8.0        3.0     2.0  \n",
              "71677  12.0        2.0     1.0  \n",
              "71678   9.0        6.0     2.0  \n",
              "\n",
              "[71679 rows x 22 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFZ2SN8OByr0"
      },
      "source": [
        "#Part 2: Model Building"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTM7dYfi4UyD"
      },
      "source": [
        "## Random Forests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4NNhL9SHtOr"
      },
      "source": [
        "### Random Forest - w/ Feature Selection - Full Dataset\n",
        "\n",
        "* 10 trees & 50 trees Tested (n_estimator changes)\n",
        "* RF 10 trees - 5-fold cv - with Feature Selection \n",
        ": 0.89 (+/- 0.00)  |   AUC: 0.71 (+/- 0.01)  |   Runtime: 9.93 seconds\n",
        "* RF 50 trees - 5-fold cv - with Feature Selection \n",
        " ACC: 0.89 (+/- 0.00)  |   AUC: 0.74 (+/- 0.01)  |   Runtime: 48.17 seconds\n",
        "* RF 50 trees - 10-fold cv - with Feature Selection \n",
        " ACC: 0.89 (+/- 0.00)  |   AUC: 0.74 (+/- 0.01)  |   Runtime: 103.57 seconds\n",
        "* RF Selected Features: ['BMI', 'GenHlth', 'MentHlth', 'PhysHlth', 'Age', 'Education', 'Income']\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYGWH7zkNV-f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "886cebb0-59ad-4708-df23-3f82b139331c"
      },
      "source": [
        "#SciKit DSC540 HW1\n",
        "'''created by Casey Bennett 2018, www.CaseyBennett.com'''\n",
        "\n",
        "import sys\n",
        "import csv\n",
        "import math\n",
        "import numpy as np\n",
        "from operator import itemgetter\n",
        "import time\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.externals import joblib\n",
        "from sklearn.feature_selection import RFE, VarianceThreshold, SelectFromModel\n",
        "from sklearn.feature_selection import SelectKBest, mutual_info_regression, mutual_info_classif, chi2\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import cross_validate, train_test_split\n",
        "from sklearn.preprocessing import KBinsDiscretizer, scale\n",
        "\n",
        "\n",
        "#Handle annoying warnings\n",
        "import warnings, sklearn.exceptions\n",
        "warnings.filterwarnings(\"ignore\", category=sklearn.exceptions.ConvergenceWarning)\n",
        "\n",
        "\n",
        "#############################################################################\n",
        "#\n",
        "# Global parameters\n",
        "#\n",
        "#####################\n",
        "\n",
        "target_idx=0                                        #Index of Target variable\n",
        "cross_val=1                                         #Control Switch for CV                                                                                      \n",
        "norm_target=0                                       #Normalize target switch\n",
        "norm_features=0                                     #Normalize target switch\n",
        "binning=0                                           #Control Switch for Bin Target\n",
        "bin_cnt=2                                           #If bin target, this sets number of classes\n",
        "feat_select=1                                       #Control Switch for Feature Selection\n",
        "fs_type=4                                           #Feature Selection type (1=Stepwise Backwards Removal, 2=Wrapper Select, 3=Univariate Selection)\n",
        "lv_filter=0                                         #Control switch for low variance filter on features\n",
        "feat_start=1                                        #Start column of features\n",
        "\n",
        "#Set global model parameters\n",
        "rand_st=1                                           #Set Random State variable for randomizing splits on runs\n",
        "\n",
        "\n",
        "#############################################################################\n",
        "#\n",
        "# Load Data\n",
        "#\n",
        "#####################\n",
        "\n",
        "file1= csv.reader(open('brfss2015_cleaned.csv'), delimiter=',', quotechar='\"')\n",
        "\n",
        "#Read Header Line\n",
        "header=next(file1)            \n",
        "\n",
        "#Read data\n",
        "data=[]\n",
        "target=[]\n",
        "for row in file1:\n",
        "    #Load Target\n",
        "    if row[target_idx]=='':                         #If target is blank, skip row                       \n",
        "        continue\n",
        "    else:\n",
        "        target.append(float(row[target_idx]))       #If pre-binned class, change float to int\n",
        "\n",
        "    #Load row into temp array, cast columns  \n",
        "    temp=[]\n",
        "                 \n",
        "    for j in range(feat_start,len(header)):\n",
        "        if row[j]=='':\n",
        "            temp.append(float())\n",
        "        else:\n",
        "            temp.append(float(row[j]))\n",
        "\n",
        "    #Load temp into Data array\n",
        "    data.append(temp)\n",
        "  \n",
        "#Test Print\n",
        "print(header)\n",
        "print(len(target),len(data))\n",
        "print('\\n')\n",
        "\n",
        "data_np=np.asarray(data)\n",
        "target_np=np.asarray(target)\n",
        "\n",
        "\n",
        "#############################################################################\n",
        "#\n",
        "# Preprocess data\n",
        "#\n",
        "##########################################\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#############################################################################\n",
        "#\n",
        "# Feature Selection\n",
        "#\n",
        "##########################################\n",
        "\n",
        "#Low Variance Filter\n",
        "if lv_filter==1:\n",
        "    print('--LOW VARIANCE FILTER ON--', '\\n')\n",
        "    \n",
        "    #LV Threshold\n",
        "    sel = VarianceThreshold(threshold=0.5)                                          #Removes any feature with less than 20% variance\n",
        "    fit_mod=sel.fit(data_np)\n",
        "    fitted=sel.transform(data_np)\n",
        "    sel_idx=fit_mod.get_support()\n",
        "\n",
        "    #Get lists of selected and non-selected features (names and indexes)\n",
        "    temp=[]\n",
        "    temp_idx=[]\n",
        "    temp_del=[]\n",
        "    for i in range(len(data_np[0])):\n",
        "        if sel_idx[i]==1:                                                           #Selected Features get added to temp header\n",
        "            temp.append(header[i+feat_start])\n",
        "            temp_idx.append(i)\n",
        "        else:                                                                       #Indexes of non-selected features get added to delete array\n",
        "            temp_del.append(i)\n",
        "\n",
        "    print('Selected:', temp)\n",
        "    print('Features (total, selected):', len(data_np[0]), len(temp))\n",
        "    print('\\n')\n",
        "\n",
        "    #Filter selected columns from original dataset\n",
        "    header = header[0:feat_start]\n",
        "    for field in temp:\n",
        "        header.append(field)\n",
        "    data_np = np.delete(data_np, temp_del, axis=1)                                 #Deletes non-selected features by index\n",
        "\n",
        "\n",
        "#Feature Selection\n",
        "if feat_select==1:\n",
        "    '''Three steps:\n",
        "       1) Run Feature Selection\n",
        "       2) Get lists of selected and non-selected features\n",
        "       3) Filter columns from original dataset\n",
        "       '''\n",
        "    \n",
        "    print('--FEATURE SELECTION ON--', '\\n')\n",
        "    \n",
        "    ##1) Run Feature Selection #######\n",
        "    #Wrapper Select via model\n",
        "    if fs_type==2:\n",
        "        clf = RandomForestClassifier( n_estimators=50, max_depth=None, min_samples_split=3,criterion='entropy', random_state=rand_st)                \n",
        "        sel = SelectFromModel(clf, prefit=False, threshold='mean', max_features=None)                   \n",
        "        print ('Wrapper Select: ')\n",
        "\n",
        "        fit_mod=sel.fit(data_np, target_np)    \n",
        "        sel_idx=fit_mod.get_support()\n",
        "\n",
        "    if fs_type==4:\n",
        "        clf= RandomForestClassifier( n_estimators=50, max_depth=None, min_samples_split=3,criterion='entropy', random_state=rand_st)\n",
        "        clf.fit(data_np,target_np)\n",
        "        sel_idx = []\n",
        "        print('clf.feature_importances_ = ', clf.feature_importances_)\n",
        "        for x in clf.feature_importances_:\n",
        "          if x >= np.mean(clf.feature_importances_):\n",
        "            sel_idx.append(1)\n",
        "          else:\n",
        "            sel_idx.append(0)\n",
        "\n",
        "    ##2) Get lists of selected and non-selected features (names and indexes) #######\n",
        "    temp=[]\n",
        "    temp_idx=[]\n",
        "    temp_del=[]\n",
        "    for i in range(len(data_np[0])):\n",
        "        if sel_idx[i]==1:                                                           #Selected Features get added to temp header\n",
        "            temp.append(header[i+feat_start])\n",
        "            temp_idx.append(i)\n",
        "        else:                                                                       #Indexes of non-selected features get added to delete array\n",
        "            temp_del.append(i)\n",
        "    print('Selected:', temp)\n",
        "    print('Features (total/selected):', len(data_np[0]), len(temp))\n",
        "    print('\\n')\n",
        "            \n",
        "               \n",
        "    ##3) Filter selected columns from original dataset #########\n",
        "    header = header[0:feat_start]\n",
        "    for field in temp:\n",
        "        header.append(field)\n",
        "    data_np = np.delete(data_np, temp_del, axis=1)                                 #Deletes non-selected features by index\n",
        "    \n",
        "\n",
        "#############################################################################\n",
        "#\n",
        "# Train SciKit Models\n",
        "#\n",
        "##########################################\n",
        "\n",
        "print('--ML Model Output--', '\\n')\n",
        "\n",
        "#Test/Train split\n",
        "data_train, data_test, target_train, target_test = train_test_split(data_np, target_np, test_size=0.35)\n",
        "\n",
        "####Classifiers####\n",
        "if cross_val==0:    \n",
        "    #SciKit Random Forest\n",
        "    clf = RandomForestClassifier( n_estimators=50, max_depth=None, min_samples_split=3,criterion='entropy', random_state=rand_st)  \n",
        "    clf.fit(data_train,target_train)\n",
        "\n",
        "    scores_ACC = clf.score(data_test, target_test)                                                                                                                          \n",
        "    print('Random Forest Acc:', scores_ACC)\n",
        "    scores_AUC = metrics.roc_auc_score(target_test, clf.predict_proba(data_test)[:,1])                                                                                      \n",
        "    print('Random Forest AUC:', scores_AUC)                                                                     #AUC only works with binary classes, not multiclass            \n",
        " \n",
        "####Cross-Val Classifiers####\n",
        "if cross_val==1:\n",
        "    #Setup Crossval classifier scorers\n",
        "    scorers = {'Accuracy': 'accuracy', 'roc_auc': 'roc_auc'}                                                                                                                \n",
        "    \n",
        "    #SciKit Random Forest - Cross Val\n",
        "    start_ts=time.time()\n",
        "    clf = RandomForestClassifier( n_estimators=50, max_depth=None, min_samples_split=3,criterion='entropy', random_state=rand_st)   \n",
        "    scores = cross_validate(clf, data_np, target_np, scoring=scorers, cv=5)                                                                                                 \n",
        "\n",
        "    scores_Acc = scores['test_Accuracy']                                                                                                                                    \n",
        "    print(\"Random Forest Acc: %0.2f (+/- %0.2f)\" % (scores_Acc.mean(), scores_Acc.std() * 2))                                                                                                    \n",
        "    scores_AUC= scores['test_roc_auc']                                                                     #Only works with binary classes, not multiclass                  \n",
        "    print(\"Random Forest AUC: %0.2f (+/- %0.2f)\" % (scores_AUC.mean(), scores_AUC.std() * 2))                           \n",
        "    print(\"CV Runtime:\", time.time()-start_ts)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['HeartDiseaseorAttack', 'HighBP', 'HighChol', 'CholCheck', 'BMI', 'Smoker', 'Stroke', 'Diabetes', 'PhysActivity', 'Fruits', 'Veggies', 'HvyAlcoholConsump', 'AnyHealthcare', 'NoDocbcCost', 'GenHlth', 'MentHlth', 'PhysHlth', 'DiffWalk', 'Sex', 'Age', 'Education', 'Income']\n",
            "253680 253680\n",
            "\n",
            "\n",
            "--FEATURE SELECTION ON-- \n",
            "\n",
            "clf.feature_importances_ =  [0.04089322 0.03223865 0.00436396 0.17431628 0.02240508 0.02616389\n",
            " 0.03041298 0.02506068 0.02889913 0.02376834 0.00909234 0.00769151\n",
            " 0.0135137  0.08093152 0.0600772  0.08005331 0.02753025 0.02561251\n",
            " 0.13153098 0.06333545 0.09210904]\n",
            "Selected: ['BMI', 'GenHlth', 'MentHlth', 'PhysHlth', 'Age', 'Education', 'Income']\n",
            "Features (total/selected): 21 7\n",
            "\n",
            "\n",
            "--ML Model Output-- \n",
            "\n",
            "Random Forest Acc: 0.89 (+/- 0.00)\n",
            "Random Forest AUC: 0.74 (+/- 0.01)\n",
            "CV Runtime: 103.57060194015503\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLzcRDPKO1F_"
      },
      "source": [
        "###Random Forest - w/o Feature Selection - Full Dataset\n",
        "\n",
        "\n",
        "* 10 trees & 50 trees Tested (n_estimator changes)\n",
        "* RF 10 trees - 5-fold cv ACC: 0.89 (+/- 0.00)  |   AUC: 0.71 (+/- 0.01)  |   Runtime: 9.93 seconds\n",
        "* RF 50 trees - 5-fold cv ACC: 0.90 (+/- 0.00)  |   AUC: 0.82 (+/- 0.01)  |   Runtime: 66.19 seconds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyXic4OlTxgQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "outputId": "0c67b95c-a57d-448b-e922-b19eebc21794"
      },
      "source": [
        "#SciKit DSC540 HW1\n",
        "'''created by Casey Bennett 2018, www.CaseyBennett.com'''\n",
        "\n",
        "import sys\n",
        "import csv\n",
        "import math\n",
        "import numpy as np\n",
        "from operator import itemgetter\n",
        "import time\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.externals import joblib\n",
        "from sklearn.feature_selection import RFE, VarianceThreshold, SelectFromModel\n",
        "from sklearn.feature_selection import SelectKBest, mutual_info_regression, mutual_info_classif, chi2\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import cross_validate, train_test_split\n",
        "from sklearn.preprocessing import KBinsDiscretizer, scale\n",
        "\n",
        "\n",
        "#Handle annoying warnings\n",
        "import warnings, sklearn.exceptions\n",
        "warnings.filterwarnings(\"ignore\", category=sklearn.exceptions.ConvergenceWarning)\n",
        "\n",
        "\n",
        "#############################################################################\n",
        "#\n",
        "# Global parameters\n",
        "#\n",
        "#####################\n",
        "\n",
        "target_idx=0                                        #Index of Target variable\n",
        "cross_val=1                                         #Control Switch for CV                                                                                      \n",
        "norm_target=0                                       #Normalize target switch\n",
        "norm_features=0                                     #Normalize target switch\n",
        "binning=0                                           #Control Switch for Bin Target\n",
        "bin_cnt=2                                           #If bin target, this sets number of classes\n",
        "feat_select=0                                       #Control Switch for Feature Selection\n",
        "fs_type=4                                           #Feature Selection type (1=Stepwise Backwards Removal, 2=Wrapper Select, 3=Univariate Selection)\n",
        "lv_filter=0                                         #Control switch for low variance filter on features\n",
        "feat_start=1                                        #Start column of features\n",
        "\n",
        "#Set global model parameters\n",
        "rand_st=1                                           #Set Random State variable for randomizing splits on runs\n",
        "\n",
        "\n",
        "#############################################################################\n",
        "#\n",
        "# Load Data\n",
        "#\n",
        "#####################\n",
        "\n",
        "file1= csv.reader(open('brfss2015_cleaned.csv'), delimiter=',', quotechar='\"')\n",
        "\n",
        "#Read Header Line\n",
        "header=next(file1)            \n",
        "\n",
        "#Read data\n",
        "data=[]\n",
        "target=[]\n",
        "for row in file1:\n",
        "    #Load Target\n",
        "    if row[target_idx]=='':                         #If target is blank, skip row                       \n",
        "        continue\n",
        "    else:\n",
        "        target.append(float(row[target_idx]))       #If pre-binned class, change float to int\n",
        "\n",
        "    #Load row into temp array, cast columns  \n",
        "    temp=[]\n",
        "                 \n",
        "    for j in range(feat_start,len(header)):\n",
        "        if row[j]=='':\n",
        "            temp.append(float())\n",
        "        else:\n",
        "            temp.append(float(row[j]))\n",
        "\n",
        "    #Load temp into Data array\n",
        "    data.append(temp)\n",
        "  \n",
        "#Test Print\n",
        "print(header)\n",
        "print(len(target),len(data))\n",
        "print('\\n')\n",
        "\n",
        "data_np=np.asarray(data)\n",
        "target_np=np.asarray(target)\n",
        "\n",
        "\n",
        "#############################################################################\n",
        "#\n",
        "# Preprocess data\n",
        "#\n",
        "##########################################\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#############################################################################\n",
        "#\n",
        "# Feature Selection\n",
        "#\n",
        "##########################################\n",
        "\n",
        "#Low Variance Filter\n",
        "if lv_filter==1:\n",
        "    print('--LOW VARIANCE FILTER ON--', '\\n')\n",
        "    \n",
        "    #LV Threshold\n",
        "    sel = VarianceThreshold(threshold=0.5)                                          #Removes any feature with less than 20% variance\n",
        "    fit_mod=sel.fit(data_np)\n",
        "    fitted=sel.transform(data_np)\n",
        "    sel_idx=fit_mod.get_support()\n",
        "\n",
        "    #Get lists of selected and non-selected features (names and indexes)\n",
        "    temp=[]\n",
        "    temp_idx=[]\n",
        "    temp_del=[]\n",
        "    for i in range(len(data_np[0])):\n",
        "        if sel_idx[i]==1:                                                           #Selected Features get added to temp header\n",
        "            temp.append(header[i+feat_start])\n",
        "            temp_idx.append(i)\n",
        "        else:                                                                       #Indexes of non-selected features get added to delete array\n",
        "            temp_del.append(i)\n",
        "\n",
        "    print('Selected:', temp)\n",
        "    print('Features (total, selected):', len(data_np[0]), len(temp))\n",
        "    print('\\n')\n",
        "\n",
        "    #Filter selected columns from original dataset\n",
        "    header = header[0:feat_start]\n",
        "    for field in temp:\n",
        "        header.append(field)\n",
        "    data_np = np.delete(data_np, temp_del, axis=1)                                 #Deletes non-selected features by index\n",
        "\n",
        "\n",
        "#Feature Selection\n",
        "if feat_select==1:\n",
        "    '''Three steps:\n",
        "       1) Run Feature Selection\n",
        "       2) Get lists of selected and non-selected features\n",
        "       3) Filter columns from original dataset\n",
        "       '''\n",
        "    \n",
        "    print('--FEATURE SELECTION ON--', '\\n')\n",
        "    \n",
        "    ##1) Run Feature Selection #######\n",
        "    #Wrapper Select via model\n",
        "    if fs_type==2:\n",
        "        clf = RandomForestClassifier( n_estimators=100, max_depth=None, min_samples_split=3,criterion='entropy', random_state=rand_st)                \n",
        "        sel = SelectFromModel(clf, prefit=False, threshold='mean', max_features=None)                   \n",
        "        print ('Wrapper Select: ')\n",
        "\n",
        "        fit_mod=sel.fit(data_np, target_np)    \n",
        "        sel_idx=fit_mod.get_support()\n",
        "\n",
        "    if fs_type==4:\n",
        "        clf= RandomForestClassifier( n_estimators=10, max_depth=None, min_samples_split=3,criterion='entropy', random_state=rand_st)\n",
        "        clf.fit(data_np,target_np)\n",
        "        sel_idx = []\n",
        "        print('clf.feature_importances_ = ', clf.feature_importances_)\n",
        "        for x in clf.feature_importances_:\n",
        "          if x >= np.mean(clf.feature_importances_):\n",
        "            sel_idx.append(1)\n",
        "          else:\n",
        "            sel_idx.append(0)\n",
        "\n",
        "    ##2) Get lists of selected and non-selected features (names and indexes) #######\n",
        "    temp=[]\n",
        "    temp_idx=[]\n",
        "    temp_del=[]\n",
        "    for i in range(len(data_np[0])):\n",
        "        if sel_idx[i]==1:                                                           #Selected Features get added to temp header\n",
        "            temp.append(header[i+feat_start])\n",
        "            temp_idx.append(i)\n",
        "        else:                                                                       #Indexes of non-selected features get added to delete array\n",
        "            temp_del.append(i)\n",
        "    print('Selected:', temp)\n",
        "    print('Features (total/selected):', len(data_np[0]), len(temp))\n",
        "    print('\\n')\n",
        "            \n",
        "               \n",
        "    ##3) Filter selected columns from original dataset #########\n",
        "    header = header[0:feat_start]\n",
        "    for field in temp:\n",
        "        header.append(field)\n",
        "    data_np = np.delete(data_np, temp_del, axis=1)                                 #Deletes non-selected features by index\n",
        "    \n",
        "\n",
        "#############################################################################\n",
        "#\n",
        "# Train SciKit Models\n",
        "#\n",
        "##########################################\n",
        "\n",
        "print('--ML Model Output--', '\\n')\n",
        "\n",
        "#Test/Train split\n",
        "data_train, data_test, target_train, target_test = train_test_split(data_np, target_np, test_size=0.35)\n",
        "\n",
        "####Classifiers####\n",
        "if cross_val==0:    \n",
        "    #SciKit Random Forest\n",
        "    clf = RandomForestClassifier( n_estimators=10, max_depth=None, min_samples_split=3,criterion='entropy', random_state=rand_st)  \n",
        "    clf.fit(data_train,target_train)\n",
        "\n",
        "    scores_ACC = clf.score(data_test, target_test)                                                                                                                          \n",
        "    print('Random Forest Acc:', scores_ACC)\n",
        "    scores_AUC = metrics.roc_auc_score(target_test, clf.predict_proba(data_test)[:,1])                                                                                      \n",
        "    print('Random Forest AUC:', scores_AUC)                                                                     #AUC only works with binary classes, not multiclass            \n",
        " \n",
        "####Cross-Val Classifiers####\n",
        "if cross_val==1:\n",
        "    #Setup Crossval classifier scorers\n",
        "    scorers = {'Accuracy': 'accuracy', 'roc_auc': 'roc_auc'}                                                                                                                \n",
        "    \n",
        "    #SciKit Random Forest - Cross Val\n",
        "    start_ts=time.time()\n",
        "    clf = RandomForestClassifier( n_estimators=100, max_depth=None, min_samples_split=3,criterion='entropy', random_state=rand_st)   \n",
        "    scores = cross_validate(clf, data_np, target_np, scoring=scorers, cv=5)                                                                                                 \n",
        "\n",
        "    scores_Acc = scores['test_Accuracy']                                                                                                                                    \n",
        "    print(\"Random Forest Acc: %0.2f (+/- %0.2f)\" % (scores_Acc.mean(), scores_Acc.std() * 2))                                                                                                    \n",
        "    scores_AUC= scores['test_roc_auc']                                                                     #Only works with binary classes, not multiclass                  \n",
        "    print(\"Random Forest AUC: %0.2f (+/- %0.2f)\" % (scores_AUC.mean(), scores_AUC.std() * 2))                           \n",
        "    print(\"CV Runtime:\", time.time()-start_ts)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-1cbc46e4bdbe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;31m#####################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0mfile1\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'brfss2015_cleaned.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquotechar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\"'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;31m#Read Header Line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'brfss2015_cleaned.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLPd712bjKN8"
      },
      "source": [
        "###Random Forest - w/ and w/o Feature Selection - 50-50 Balanced Dataset\n",
        "\n",
        "* 10 trees & 50 trees Tested (n_estimator changes)\n",
        "* RF 10 trees - 5-fold cv ACC: 0.75 (+/- 0.01) |   AUC: 0.82 (+/- 0.01)  |\n",
        "Runtime: 2.51 seconds\n",
        "* RF 50 trees - 5-fold cv ACC: 0.76 (+/- 0.02)  |   AUC: 0.83 (+/- 0.01)  |   Runtime: 12.40 seconds\n",
        "* RF 50 trees w/feat_select - 5-fold cv ACC: 0.72 (+/- 0.01)  |   AUC: 0.78 (+/- 0.01)  |   Runtime: 10.62 seconds\n",
        "* Selected Features: ['HighBP', 'BMI', 'GenHlth', 'MentHlth', 'PhysHlth', 'Age', 'Education', 'Income']\n",
        "\n",
        "Notes:\n",
        "* clf features: ['HighBP', 'HighChol', 'CholCheck', 'BMI', 'Smoker', 'Stroke', 'Diabetes', 'PhysActivity', 'Fruits', 'Veggies', 'HvyAlcoholConsump', 'AnyHealthcare', 'NoDocbcCost', 'GenHlth', 'MentHlth', 'PhysHlth', 'DiffWalk', 'Sex', 'Age', 'Education', 'Income']\n",
        "* clf.feature_importances_ =  [0.051, 0.038, 0.005, 0.146, 0.024, 0.025, 0.032, 0.022, 0.026, 0.022, 0.009, 0.007, 0.012, 0.093, 0.053, 0.072, 0.030, 0.029, 0.153, 0.056, 0.084]\n",
        "* Age, BMI , GenHlth, Income, PhysHlth, Education, MentHlth, and HighBP all seem to play an important role. Though Age and BMI are the most important.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FoyUJDUUHyQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2e78a59-6a78-464e-9372-c9e63749187a"
      },
      "source": [
        "#SciKit DSC540 HW1\n",
        "'''created by Casey Bennett 2018, www.CaseyBennett.com'''\n",
        "\n",
        "import sys\n",
        "import csv\n",
        "import math\n",
        "import numpy as np\n",
        "from operator import itemgetter\n",
        "import time\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.externals import joblib\n",
        "from sklearn.feature_selection import RFE, VarianceThreshold, SelectFromModel\n",
        "from sklearn.feature_selection import SelectKBest, mutual_info_regression, mutual_info_classif, chi2\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import cross_validate, train_test_split\n",
        "from sklearn.preprocessing import KBinsDiscretizer, scale\n",
        "\n",
        "\n",
        "#Handle annoying warnings\n",
        "import warnings, sklearn.exceptions\n",
        "warnings.filterwarnings(\"ignore\", category=sklearn.exceptions.ConvergenceWarning)\n",
        "\n",
        "\n",
        "#############################################################################\n",
        "#\n",
        "# Global parameters\n",
        "#\n",
        "#####################\n",
        "\n",
        "target_idx=0                                        #Index of Target variable\n",
        "cross_val=1                                         #Control Switch for CV                                                                                      \n",
        "norm_target=0                                       #Normalize target switch\n",
        "norm_features=0                                     #Normalize target switch\n",
        "binning=0                                           #Control Switch for Bin Target\n",
        "bin_cnt=2                                           #If bin target, this sets number of classes\n",
        "feat_select=1                                       #Control Switch for Feature Selection\n",
        "fs_type=4                                           #Feature Selection type (1=Stepwise Backwards Removal, 2=Wrapper Select, 3=Univariate Selection)\n",
        "lv_filter=0                                         #Control switch for low variance filter on features\n",
        "feat_start=1                                        #Start column of features\n",
        "\n",
        "#Set global model parameters\n",
        "rand_st=1                                           #Set Random State variable for randomizing splits on runs\n",
        "\n",
        "\n",
        "#############################################################################\n",
        "#\n",
        "# Load Data\n",
        "#\n",
        "#####################\n",
        "\n",
        "file1= csv.reader(open('brfss2015_5050_cleaned.csv'), delimiter=',', quotechar='\"')\n",
        "\n",
        "#Read Header Line\n",
        "header=next(file1)            \n",
        "\n",
        "#Read data\n",
        "data=[]\n",
        "target=[]\n",
        "for row in file1:\n",
        "    #Load Target\n",
        "    if row[target_idx]=='':                         #If target is blank, skip row                       \n",
        "        continue\n",
        "    else:\n",
        "        target.append(float(row[target_idx]))       #If pre-binned class, change float to int\n",
        "\n",
        "    #Load row into temp array, cast columns  \n",
        "    temp=[]\n",
        "                 \n",
        "    for j in range(feat_start,len(header)):\n",
        "        if row[j]=='':\n",
        "            temp.append(float())\n",
        "        else:\n",
        "            temp.append(float(row[j]))\n",
        "\n",
        "    #Load temp into Data array\n",
        "    data.append(temp)\n",
        "  \n",
        "#Test Print\n",
        "print(header)\n",
        "print(len(target),len(data))\n",
        "print('\\n')\n",
        "\n",
        "data_np=np.asarray(data)\n",
        "target_np=np.asarray(target)\n",
        "\n",
        "\n",
        "#############################################################################\n",
        "#\n",
        "# Preprocess data\n",
        "#\n",
        "##########################################\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#############################################################################\n",
        "#\n",
        "# Feature Selection\n",
        "#\n",
        "##########################################\n",
        "\n",
        "#Low Variance Filter\n",
        "if lv_filter==1:\n",
        "    print('--LOW VARIANCE FILTER ON--', '\\n')\n",
        "    \n",
        "    #LV Threshold\n",
        "    sel = VarianceThreshold(threshold=0.5)                                          #Removes any feature with less than 20% variance\n",
        "    fit_mod=sel.fit(data_np)\n",
        "    fitted=sel.transform(data_np)\n",
        "    sel_idx=fit_mod.get_support()\n",
        "\n",
        "    #Get lists of selected and non-selected features (names and indexes)\n",
        "    temp=[]\n",
        "    temp_idx=[]\n",
        "    temp_del=[]\n",
        "    for i in range(len(data_np[0])):\n",
        "        if sel_idx[i]==1:                                                           #Selected Features get added to temp header\n",
        "            temp.append(header[i+feat_start])\n",
        "            temp_idx.append(i)\n",
        "        else:                                                                       #Indexes of non-selected features get added to delete array\n",
        "            temp_del.append(i)\n",
        "\n",
        "    print('Selected:', temp)\n",
        "    print('Features (total, selected):', len(data_np[0]), len(temp))\n",
        "    print('\\n')\n",
        "\n",
        "    #Filter selected columns from original dataset\n",
        "    header = header[0:feat_start]\n",
        "    for field in temp:\n",
        "        header.append(field)\n",
        "    data_np = np.delete(data_np, temp_del, axis=1)                                 #Deletes non-selected features by index\n",
        "\n",
        "\n",
        "#Feature Selection\n",
        "if feat_select==1:\n",
        "    '''Three steps:\n",
        "       1) Run Feature Selection\n",
        "       2) Get lists of selected and non-selected features\n",
        "       3) Filter columns from original dataset\n",
        "       '''\n",
        "    \n",
        "    print('--FEATURE SELECTION ON--', '\\n')\n",
        "    \n",
        "    ##1) Run Feature Selection #######\n",
        "    #Wrapper Select via model\n",
        "    if fs_type==2:\n",
        "        clf = RandomForestClassifier( n_estimators=50, max_depth=None, min_samples_split=3,criterion='entropy', random_state=rand_st)                \n",
        "        sel = SelectFromModel(clf, prefit=False, threshold='mean', max_features=None)                   \n",
        "        print ('Wrapper Select: ')\n",
        "\n",
        "        fit_mod=sel.fit(data_np, target_np)    \n",
        "        sel_idx=fit_mod.get_support()\n",
        "\n",
        "    if fs_type==4:\n",
        "        clf= RandomForestClassifier( n_estimators=50, max_depth=None, min_samples_split=3,criterion='entropy', random_state=rand_st)\n",
        "        clf.fit(data_np,target_np)\n",
        "        sel_idx = []\n",
        "        print('clf.feature_importances_ = ', clf.feature_importances_)\n",
        "        for x in clf.feature_importances_:\n",
        "          if x >= np.mean(clf.feature_importances_):\n",
        "            sel_idx.append(1)\n",
        "          else:\n",
        "            sel_idx.append(0)\n",
        "\n",
        "    ##2) Get lists of selected and non-selected features (names and indexes) #######\n",
        "    temp=[]\n",
        "    temp_idx=[]\n",
        "    temp_del=[]\n",
        "    for i in range(len(data_np[0])):\n",
        "        if sel_idx[i]==1:                                                           #Selected Features get added to temp header\n",
        "            temp.append(header[i+feat_start])\n",
        "            temp_idx.append(i)\n",
        "        else:                                                                       #Indexes of non-selected features get added to delete array\n",
        "            temp_del.append(i)\n",
        "    print('Selected:', temp)\n",
        "    print('Features (total/selected):', len(data_np[0]), len(temp))\n",
        "    print('\\n')\n",
        "            \n",
        "               \n",
        "    ##3) Filter selected columns from original dataset #########\n",
        "    header = header[0:feat_start]\n",
        "    for field in temp:\n",
        "        header.append(field)\n",
        "    data_np = np.delete(data_np, temp_del, axis=1)                                 #Deletes non-selected features by index\n",
        "    \n",
        "\n",
        "#############################################################################\n",
        "#\n",
        "# Train SciKit Models\n",
        "#\n",
        "##########################################\n",
        "\n",
        "print('--ML Model Output--', '\\n')\n",
        "\n",
        "#Test/Train split\n",
        "data_train, data_test, target_train, target_test = train_test_split(data_np, target_np, test_size=0.35)\n",
        "\n",
        "####Classifiers####\n",
        "if cross_val==0:    \n",
        "    #SciKit Random Forest\n",
        "    clf = RandomForestClassifier( n_estimators=50, max_depth=None, min_samples_split=3,criterion='entropy', random_state=rand_st)  \n",
        "    clf.fit(data_train,target_train)\n",
        "\n",
        "    scores_ACC = clf.score(data_test, target_test)                                                                                                                          \n",
        "    print('Random Forest Acc:', scores_ACC)\n",
        "    scores_AUC = metrics.roc_auc_score(target_test, clf.predict_proba(data_test)[:,1])                                                                                      \n",
        "    print('Random Forest AUC:', scores_AUC)                                                                     #AUC only works with binary classes, not multiclass            \n",
        " \n",
        "####Cross-Val Classifiers####\n",
        "if cross_val==1:\n",
        "    #Setup Crossval classifier scorers\n",
        "    scorers = {'Accuracy': 'accuracy', 'roc_auc': 'roc_auc'}                                                                                                                \n",
        "    \n",
        "    #SciKit Random Forest - Cross Val\n",
        "    start_ts=time.time()\n",
        "    clf = RandomForestClassifier( n_estimators=50, max_depth=None, min_samples_split=3,criterion='entropy', random_state=rand_st)   \n",
        "    scores = cross_validate(clf, data_np, target_np, scoring=scorers, cv=5)                                                                                                 \n",
        "\n",
        "    scores_Acc = scores['test_Accuracy']                                                                                                                                    \n",
        "    print(\"Random Forest Acc: %0.2f (+/- %0.2f)\" % (scores_Acc.mean(), scores_Acc.std() * 2))                                                                                                    \n",
        "    scores_AUC= scores['test_roc_auc']                                                                     #Only works with binary classes, not multiclass                  \n",
        "    print(\"Random Forest AUC: %0.2f (+/- %0.2f)\" % (scores_AUC.mean(), scores_AUC.std() * 2))                           \n",
        "    print(\"CV Runtime:\", time.time()-start_ts)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['HeartDiseaseorAttack', 'HighBP', 'HighChol', 'CholCheck', 'BMI', 'Smoker', 'Stroke', 'Diabetes', 'PhysActivity', 'Fruits', 'Veggies', 'HvyAlcoholConsump', 'AnyHealthcare', 'NoDocbcCost', 'GenHlth', 'MentHlth', 'PhysHlth', 'DiffWalk', 'Sex', 'Age', 'Education', 'Income']\n",
            "47786 47786\n",
            "\n",
            "\n",
            "--FEATURE SELECTION ON-- \n",
            "\n",
            "clf.feature_importances_ =  [0.05178294 0.03850164 0.00528141 0.14605524 0.02442043 0.02580259\n",
            " 0.03250203 0.02273596 0.0267695  0.02214613 0.00947942 0.00747386\n",
            " 0.01253083 0.09360263 0.05312776 0.07289174 0.03054805 0.02960106\n",
            " 0.1535522  0.05696666 0.08422795]\n",
            "Selected: ['HighBP', 'BMI', 'GenHlth', 'MentHlth', 'PhysHlth', 'Age', 'Education', 'Income']\n",
            "Features (total/selected): 21 8\n",
            "\n",
            "\n",
            "--ML Model Output-- \n",
            "\n",
            "Random Forest Acc: 0.72 (+/- 0.01)\n",
            "Random Forest AUC: 0.78 (+/- 0.01)\n",
            "CV Runtime: 10.622230291366577\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTleJ-2HqBRm"
      },
      "source": [
        "###Random Forest - w/ Feature Selection - 60-40 Balanced Dataset\n",
        "RF 50 trees  \n",
        "* 5-fold cv Acc: 0.73 (+/- 0.01) | AUC: 0.78 (+/- 0.01) | Runtime: 15.27\n",
        "* Selected: ['HighBP', 'BMI', 'GenHlth', 'MentHlth', 'PhysHlth', 'Age', 'Education', 'Income']\n",
        "* Features (total/selected): 21 8\n",
        "* Same important features identified here. Age and BMI especially important\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZupbZ9mhfoF_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9309b51-b471-4f37-fb65-cd05bbedf389"
      },
      "source": [
        "#SciKit DSC540 HW1\n",
        "'''created by Casey Bennett 2018, www.CaseyBennett.com'''\n",
        "\n",
        "import sys\n",
        "import csv\n",
        "import math\n",
        "import numpy as np\n",
        "from operator import itemgetter\n",
        "import time\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.externals import joblib\n",
        "from sklearn.feature_selection import RFE, VarianceThreshold, SelectFromModel\n",
        "from sklearn.feature_selection import SelectKBest, mutual_info_regression, mutual_info_classif, chi2\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import cross_validate, train_test_split\n",
        "from sklearn.preprocessing import KBinsDiscretizer, scale\n",
        "\n",
        "\n",
        "#Handle annoying warnings\n",
        "import warnings, sklearn.exceptions\n",
        "warnings.filterwarnings(\"ignore\", category=sklearn.exceptions.ConvergenceWarning)\n",
        "\n",
        "\n",
        "#############################################################################\n",
        "#\n",
        "# Global parameters\n",
        "#\n",
        "#####################\n",
        "\n",
        "target_idx=0                                        #Index of Target variable\n",
        "cross_val=1                                         #Control Switch for CV                                                                                      \n",
        "norm_target=0                                       #Normalize target switch\n",
        "norm_features=0                                     #Normalize target switch\n",
        "binning=0                                           #Control Switch for Bin Target\n",
        "bin_cnt=2                                           #If bin target, this sets number of classes\n",
        "feat_select=1                                       #Control Switch for Feature Selection\n",
        "fs_type=4                                           #Feature Selection type (1=Stepwise Backwards Removal, 2=Wrapper Select, 3=Univariate Selection)\n",
        "lv_filter=0                                         #Control switch for low variance filter on features\n",
        "feat_start=1                                        #Start column of features\n",
        "\n",
        "#Set global model parameters\n",
        "rand_st=1                                           #Set Random State variable for randomizing splits on runs\n",
        "\n",
        "\n",
        "#############################################################################\n",
        "#\n",
        "# Load Data\n",
        "#\n",
        "#####################\n",
        "\n",
        "file1= csv.reader(open('brfss2015_6040_cleaned.csv'), delimiter=',', quotechar='\"')\n",
        "\n",
        "#Read Header Line\n",
        "header=next(file1)            \n",
        "\n",
        "#Read data\n",
        "data=[]\n",
        "target=[]\n",
        "for row in file1:\n",
        "    #Load Target\n",
        "    if row[target_idx]=='':                         #If target is blank, skip row                       \n",
        "        continue\n",
        "    else:\n",
        "        target.append(float(row[target_idx]))       #If pre-binned class, change float to int\n",
        "\n",
        "    #Load row into temp array, cast columns  \n",
        "    temp=[]\n",
        "                 \n",
        "    for j in range(feat_start,len(header)):\n",
        "        if row[j]=='':\n",
        "            temp.append(float())\n",
        "        else:\n",
        "            temp.append(float(row[j]))\n",
        "\n",
        "    #Load temp into Data array\n",
        "    data.append(temp)\n",
        "  \n",
        "#Test Print\n",
        "print(header)\n",
        "print(len(target),len(data))\n",
        "print('\\n')\n",
        "\n",
        "data_np=np.asarray(data)\n",
        "target_np=np.asarray(target)\n",
        "\n",
        "\n",
        "#############################################################################\n",
        "#\n",
        "# Preprocess data\n",
        "#\n",
        "##########################################\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#############################################################################\n",
        "#\n",
        "# Feature Selection\n",
        "#\n",
        "##########################################\n",
        "\n",
        "#Low Variance Filter\n",
        "if lv_filter==1:\n",
        "    print('--LOW VARIANCE FILTER ON--', '\\n')\n",
        "    \n",
        "    #LV Threshold\n",
        "    sel = VarianceThreshold(threshold=0.5)                                          #Removes any feature with less than 20% variance\n",
        "    fit_mod=sel.fit(data_np)\n",
        "    fitted=sel.transform(data_np)\n",
        "    sel_idx=fit_mod.get_support()\n",
        "\n",
        "    #Get lists of selected and non-selected features (names and indexes)\n",
        "    temp=[]\n",
        "    temp_idx=[]\n",
        "    temp_del=[]\n",
        "    for i in range(len(data_np[0])):\n",
        "        if sel_idx[i]==1:                                                           #Selected Features get added to temp header\n",
        "            temp.append(header[i+feat_start])\n",
        "            temp_idx.append(i)\n",
        "        else:                                                                       #Indexes of non-selected features get added to delete array\n",
        "            temp_del.append(i)\n",
        "\n",
        "    print('Selected:', temp)\n",
        "    print('Features (total, selected):', len(data_np[0]), len(temp))\n",
        "    print('\\n')\n",
        "\n",
        "    #Filter selected columns from original dataset\n",
        "    header = header[0:feat_start]\n",
        "    for field in temp:\n",
        "        header.append(field)\n",
        "    data_np = np.delete(data_np, temp_del, axis=1)                                 #Deletes non-selected features by index\n",
        "\n",
        "\n",
        "#Feature Selection\n",
        "if feat_select==1:\n",
        "    '''Three steps:\n",
        "       1) Run Feature Selection\n",
        "       2) Get lists of selected and non-selected features\n",
        "       3) Filter columns from original dataset\n",
        "       '''\n",
        "    \n",
        "    print('--FEATURE SELECTION ON--', '\\n')\n",
        "    \n",
        "    ##1) Run Feature Selection #######\n",
        "    #Wrapper Select via model\n",
        "    if fs_type==2:\n",
        "        clf = RandomForestClassifier( n_estimators=50, max_depth=None, min_samples_split=3,criterion='entropy', random_state=rand_st)                \n",
        "        sel = SelectFromModel(clf, prefit=False, threshold='mean', max_features=None)                   \n",
        "        print ('Wrapper Select: ')\n",
        "\n",
        "        fit_mod=sel.fit(data_np, target_np)    \n",
        "        sel_idx=fit_mod.get_support()\n",
        "\n",
        "    if fs_type==4:\n",
        "        clf= RandomForestClassifier( n_estimators=50, max_depth=None, min_samples_split=3,criterion='entropy', random_state=rand_st)\n",
        "        clf.fit(data_np,target_np)\n",
        "        sel_idx = []\n",
        "        print('clf.feature_importances_ = ', clf.feature_importances_)\n",
        "        for x in clf.feature_importances_:\n",
        "          if x >= np.mean(clf.feature_importances_):\n",
        "            sel_idx.append(1)\n",
        "          else:\n",
        "            sel_idx.append(0)\n",
        "\n",
        "    ##2) Get lists of selected and non-selected features (names and indexes) #######\n",
        "    temp=[]\n",
        "    temp_idx=[]\n",
        "    temp_del=[]\n",
        "    for i in range(len(data_np[0])):\n",
        "        if sel_idx[i]==1:                                                           #Selected Features get added to temp header\n",
        "            temp.append(header[i+feat_start])\n",
        "            temp_idx.append(i)\n",
        "        else:                                                                       #Indexes of non-selected features get added to delete array\n",
        "            temp_del.append(i)\n",
        "    print('Selected:', temp)\n",
        "    print('Features (total/selected):', len(data_np[0]), len(temp))\n",
        "    print('\\n')\n",
        "            \n",
        "               \n",
        "    ##3) Filter selected columns from original dataset #########\n",
        "    header = header[0:feat_start]\n",
        "    for field in temp:\n",
        "        header.append(field)\n",
        "    data_np = np.delete(data_np, temp_del, axis=1)                                 #Deletes non-selected features by index\n",
        "    \n",
        "\n",
        "#############################################################################\n",
        "#\n",
        "# Train SciKit Models\n",
        "#\n",
        "##########################################\n",
        "\n",
        "print('--ML Model Output--', '\\n')\n",
        "\n",
        "#Test/Train split\n",
        "data_train, data_test, target_train, target_test = train_test_split(data_np, target_np, test_size=0.35)\n",
        "\n",
        "####Classifiers####\n",
        "if cross_val==0:    \n",
        "    #SciKit Random Forest\n",
        "    clf = RandomForestClassifier( n_estimators=50, max_depth=None, min_samples_split=3,criterion='entropy', random_state=rand_st)  \n",
        "    clf.fit(data_train,target_train)\n",
        "\n",
        "    scores_ACC = clf.score(data_test, target_test)                                                                                                                          \n",
        "    print('Random Forest Acc:', scores_ACC)\n",
        "    scores_AUC = metrics.roc_auc_score(target_test, clf.predict_proba(data_test)[:,1])                                                                                      \n",
        "    print('Random Forest AUC:', scores_AUC)                                                                     #AUC only works with binary classes, not multiclass            \n",
        " \n",
        "####Cross-Val Classifiers####\n",
        "if cross_val==1:\n",
        "    #Setup Crossval classifier scorers\n",
        "    scorers = {'Accuracy': 'accuracy', 'roc_auc': 'roc_auc'}                                                                                                                \n",
        "    \n",
        "    #SciKit Random Forest - Cross Val\n",
        "    start_ts=time.time()\n",
        "    clf = RandomForestClassifier( n_estimators=50, max_depth=None, min_samples_split=3,criterion='entropy', random_state=rand_st)   \n",
        "    scores = cross_validate(clf, data_np, target_np, scoring=scorers, cv=5)                                                                                                 \n",
        "\n",
        "    scores_Acc = scores['test_Accuracy']                                                                                                                                    \n",
        "    print(\"Random Forest Acc: %0.2f (+/- %0.2f)\" % (scores_Acc.mean(), scores_Acc.std() * 2))                                                                                                    \n",
        "    scores_AUC= scores['test_roc_auc']                                                                     #Only works with binary classes, not multiclass                  \n",
        "    print(\"Random Forest AUC: %0.2f (+/- %0.2f)\" % (scores_AUC.mean(), scores_AUC.std() * 2))                           \n",
        "    print(\"CV Runtime:\", time.time()-start_ts)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['HeartDiseaseorAttack', 'HighBP', 'HighChol', 'CholCheck', 'BMI', 'Smoker', 'Stroke', 'Diabetes', 'PhysActivity', 'Fruits', 'Veggies', 'HvyAlcoholConsump', 'AnyHealthcare', 'NoDocbcCost', 'GenHlth', 'MentHlth', 'PhysHlth', 'DiffWalk', 'Sex', 'Age', 'Education', 'Income']\n",
            "71679 71679\n",
            "\n",
            "\n",
            "--FEATURE SELECTION ON-- \n",
            "\n",
            "clf.feature_importances_ =  [0.05030595 0.03909143 0.00465682 0.15301603 0.02378759 0.02546964\n",
            " 0.03189533 0.02322308 0.026934   0.02262808 0.00926853 0.00761745\n",
            " 0.0129452  0.09199617 0.05476121 0.07578423 0.0303378  0.02867765\n",
            " 0.14366509 0.05735905 0.08657969]\n",
            "Selected: ['HighBP', 'BMI', 'GenHlth', 'MentHlth', 'PhysHlth', 'Age', 'Education', 'Income']\n",
            "Features (total/selected): 21 8\n",
            "\n",
            "\n",
            "--ML Model Output-- \n",
            "\n",
            "Random Forest Acc: 0.73 (+/- 0.01)\n",
            "Random Forest AUC: 0.78 (+/- 0.01)\n",
            "CV Runtime: 15.27793836593628\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQbmgfdc4eB3"
      },
      "source": [
        "## AdaBoost, GradientBoost, and Neural Networks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDn5nRMjuXi_"
      },
      "source": [
        "### AdaBoost, GradientBoost, and Neural Network - w/o Feature Selection - Full Dataset\n",
        "Gradient Boosting:\n",
        "* Gradient Boosting - Acc: 0.91 (+/- 0.00)\n",
        "* Gradient Boosting - AUC: 0.85 (+/- 0.01)\n",
        "* GB - CV Runtime: 153.49 seconds\n",
        "\n",
        "Ada Boost:\n",
        "* Ada Boost - Acc: 0.91 (+/- 0.00)\n",
        "* Ada Boost - AUC: 0.84 (+/- 0.01)\n",
        "* Ada - CV Runtime: 92.66 seconds\n",
        "\n",
        "Neural Network:\n",
        "* Neural Network - Acc: 0.91 (+/- 0.00)\n",
        "* Neural Network - AUC: 0.85 (+/- 0.01)\n",
        "* NN - CV Runtime: 113.11 seconds\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxnhJzWGuuBz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7f6bea1-e6af-4ccf-c23d-312003497897"
      },
      "source": [
        "#SciKit DSC540 HW1\n",
        "'''created by Casey Bennett 2018, www.CaseyBennett.com'''\n",
        "\n",
        "import sys\n",
        "import csv\n",
        "import math\n",
        "import numpy as np\n",
        "from operator import itemgetter\n",
        "import time\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.externals import joblib\n",
        "from sklearn.feature_selection import RFE, VarianceThreshold, SelectFromModel\n",
        "from sklearn.feature_selection import SelectKBest, mutual_info_regression, mutual_info_classif, chi2\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import cross_validate, train_test_split\n",
        "from sklearn.preprocessing import KBinsDiscretizer, scale\n",
        "\n",
        "#Handle annoying warnings\n",
        "import warnings, sklearn.exceptions\n",
        "warnings.filterwarnings(\"ignore\", category=sklearn.exceptions.ConvergenceWarning)\n",
        "\n",
        "\n",
        "#############################################################################\n",
        "#\n",
        "# Global parameters\n",
        "#\n",
        "#####################\n",
        "\n",
        "target_idx=0                                        #Index of Target variable\n",
        "cross_val=1                                         #Control Switch for CV                                                                                                                                                      \n",
        "norm_target=0                                       #Normalize target switch\n",
        "norm_features=0                                     #Normalize target switch\n",
        "binning=1                                           #Control Switch for Bin Target\n",
        "bin_cnt=2                                           #If bin target, this sets number of classes\n",
        "feat_select=0                                       #Control Switch for Feature Selection                                                                                   \n",
        "fs_type=2                                           #Feature Selection type (1=Stepwise Backwards Removal, 2=Wrapper Select, 3=Univariate Selection)                        \n",
        "lv_filter=0                                         #Control switch for low variance filter on features\n",
        "feat_start=1                                        #Start column of features\n",
        "k_cnt=5                                             #Number of 'Top k' best ranked features to select, only applies for fs_types 1 and 3\n",
        "\n",
        "#Set global model parameters\n",
        "rand_st=1                                           #Set Random State variable for randomizing splits on runs\n",
        "\n",
        "\n",
        "#############################################################################\n",
        "#\n",
        "# Load Data\n",
        "#\n",
        "#####################\n",
        "\n",
        "file1= csv.reader(open('brfss2015_cleaned.csv'), delimiter=',', quotechar='\"')\n",
        "\n",
        "#Read Header Line\n",
        "header=next(file1)            \n",
        "\n",
        "#Read data\n",
        "data=[]\n",
        "target=[]\n",
        "for row in file1:\n",
        "    #Load Target\n",
        "    if row[target_idx]=='':                         #If target is blank, skip row                       \n",
        "        continue\n",
        "    else:\n",
        "        target.append(float(row[target_idx]))       #If pre-binned class, change float to int\n",
        "\n",
        "    #Load row into temp array, cast columns  \n",
        "    temp=[]\n",
        "                 \n",
        "    for j in range(feat_start,len(header)):\n",
        "        if row[j]=='':\n",
        "            temp.append(float())\n",
        "        else:\n",
        "            temp.append(float(row[j]))\n",
        "\n",
        "    #Load temp into Data array\n",
        "    data.append(temp)\n",
        "  \n",
        "#Test Print\n",
        "print(header)\n",
        "print(len(target),len(data))\n",
        "print('\\n')\n",
        "\n",
        "data_np=np.asarray(data)\n",
        "target_np=np.asarray(target)\n",
        "\n",
        "\n",
        "#############################################################################\n",
        "#\n",
        "# Preprocess data\n",
        "#\n",
        "##########################################\n",
        "\n",
        "if norm_target==1:\n",
        "    #Target normalization for continuous values\n",
        "    target_np=scale(target_np)\n",
        "\n",
        "if norm_features==1:\n",
        "    #Feature normalization for continuous values\n",
        "    data_np=scale(data_np)\n",
        "\n",
        "'''if binning==1:\n",
        "    #Discretize Target variable with KBinsDiscretizer\n",
        "    enc = KBinsDiscretizer(n_bins=[bin_cnt], encode='ordinal', strategy='quantile')                         #Strategy here is important, quantile creating equal bins, but kmeans prob being more valid \"clusters\"\n",
        "    target_np_bin = enc.fit_transform(target_np.reshape(-1,1))\n",
        "\n",
        "    #Get Bin min/max\n",
        "    temp=[[] for x in range(bin_cnt+1)]\n",
        "    for i in range(len(target_np)):\n",
        "        for j in range(bin_cnt):\n",
        "            if target_np_bin[i]==j:\n",
        "                temp[j].append(target_np[i])\n",
        "\n",
        "    for j in range(bin_cnt):\n",
        "        print('Bin', j, ':', min(temp[j]), max(temp[j]), len(temp[j]))\n",
        "    print('\\n')\n",
        "\n",
        "    #Convert Target array back to correct shape\n",
        "    target_np=np.ravel(target_np_bin)'''\n",
        "\n",
        "\n",
        "#############################################################################\n",
        "#\n",
        "# Feature Selection\n",
        "#\n",
        "##########################################\n",
        "\n",
        "#Low Variance Filter\n",
        "if lv_filter==1:\n",
        "    print('--LOW VARIANCE FILTER ON--', '\\n')\n",
        "    \n",
        "    #LV Threshold\n",
        "    sel = VarianceThreshold(threshold=0.5)                                      #Removes any feature with less than 20% variance\n",
        "    fit_mod=sel.fit(data_np)\n",
        "    fitted=sel.transform(data_np)\n",
        "    sel_idx=fit_mod.get_support()\n",
        "\n",
        "    #Get lists of selected and non-selected features (names and indexes)\n",
        "    temp=[]\n",
        "    temp_idx=[]\n",
        "    temp_del=[]\n",
        "    for i in range(len(data_np[0])):\n",
        "        if sel_idx[i]==1:                                                           #Selected Features get added to temp header\n",
        "            temp.append(header[i+feat_start])\n",
        "            temp_idx.append(i)\n",
        "        else:                                                                       #Indexes of non-selected features get added to delete array\n",
        "            temp_del.append(i)\n",
        "\n",
        "    print('Selected', temp)\n",
        "    print('Features (total, selected):', len(data_np[0]), len(temp))\n",
        "    print('\\n')\n",
        "\n",
        "    #Filter selected columns from original dataset\n",
        "    header = header[0:feat_start]\n",
        "    for field in temp:\n",
        "        header.append(field)\n",
        "    data_np = np.delete(data_np, temp_del, axis=1)                                 #Deletes non-selected features by index\n",
        "\n",
        "\n",
        "#Feature Selection\n",
        "if feat_select==1:\n",
        "    '''Three steps:\n",
        "       1) Run Feature Selection\n",
        "       2) Get lists of selected and non-selected features\n",
        "       3) Filter columns from original dataset\n",
        "       '''\n",
        "    \n",
        "    print('--FEATURE SELECTION ON--', '\\n')\n",
        "    \n",
        "    ##1) Run Feature Selection #######\n",
        "    if fs_type==1:\n",
        "        #Stepwise Recursive Backwards Feature removal\n",
        "        if binning==1:\n",
        "            clf = RandomForestClassifier(n_estimators=200, max_depth=None, min_samples_split=3, criterion='entropy', random_state=rand_st)\n",
        "            sel = RFE(clf, n_features_to_select=k_cnt, step=.1)\n",
        "            print('Stepwise Recursive Backwards - Random Forest: ')\n",
        "        if binning==0:\n",
        "            rgr = RandomForestRegressor(n_estimators=500, max_depth=None, min_samples_split=3, criterion='mse', random_state=rand_st)\n",
        "            sel = RFE(rgr, n_features_to_select=k_cnt, step=.1)\n",
        "            print('Stepwise Recursive Backwards - Random Forest: ')\n",
        "            \n",
        "        fit_mod=sel.fit(data_np, target_np)\n",
        "        print(sel.ranking_)\n",
        "        sel_idx=fit_mod.get_support()      \n",
        "\n",
        "    if fs_type==2:\n",
        "        #Wrapper Select via model\n",
        "        if binning==1:\n",
        "            clf = GradientBoostingClassifier(n_estimators=100, loss='deviance', learning_rate=0.1, max_depth=3, min_samples_split=3, random_state=rand_st)\n",
        "            sel = SelectFromModel(clf, prefit=False, threshold='mean', max_features=None)                                                           #to select only based on max_features, set to integer value and set threshold=-np.inf\n",
        "            print ('Wrapper Select: ')\n",
        "        if binning==0:\n",
        "            rgr = '''Unused in this homework'''\n",
        "            sel = SelectFromModel(rgr, prefit=False, threshold='mean', max_features=None)\n",
        "            print ('Wrapper Select: ')\n",
        "            \n",
        "        fit_mod=sel.fit(data_np, target_np)    \n",
        "        sel_idx=fit_mod.get_support()\n",
        "\n",
        "    if fs_type==3:\n",
        "        if binning==1:                                                              ######Only work if the Target is binned###########\n",
        "            #Univariate Feature Selection - Chi-squared\n",
        "            sel=SelectKBest(chi2, k=k_cnt)\n",
        "            fit_mod=sel.fit(data_np, target_np)                                         #will throw error if any negative values in features, so turn off feature normalization, or switch to mutual_info_classif\n",
        "            print ('Univariate Feature Selection - Chi2: ')\n",
        "            sel_idx=fit_mod.get_support()\n",
        "\n",
        "        if binning==0:                                                              ######Only work if the Target is continuous###########\n",
        "            #Univariate Feature Selection - Mutual Info Regression\n",
        "            sel=SelectKBest(mutual_info_regression, k=k_cnt)\n",
        "            fit_mod=sel.fit(data_np, target_np)\n",
        "            print ('Univariate Feature Selection - Mutual Info: ')\n",
        "            sel_idx=fit_mod.get_support()\n",
        "\n",
        "        #Print ranked variables out sorted\n",
        "        temp=[]\n",
        "        scores=fit_mod.scores_\n",
        "        for i in range(feat_start, len(header)):            \n",
        "            temp.append([header[i], float(scores[i-feat_start])])\n",
        "\n",
        "        print('Ranked Features')\n",
        "        temp_sort=sorted(temp, key=itemgetter(1), reverse=True)\n",
        "        for i in range(len(temp_sort)):\n",
        "            print(i, temp_sort[i][0], ':', temp_sort[i][1])\n",
        "        print('\\n')\n",
        "\n",
        "    ##2) Get lists of selected and non-selected features (names and indexes) #######\n",
        "    temp=[]\n",
        "    temp_idx=[]\n",
        "    temp_del=[]\n",
        "    for i in range(len(data_np[0])):\n",
        "        if sel_idx[i]==1:                                                           #Selected Features get added to temp header\n",
        "            temp.append(header[i+feat_start])\n",
        "            temp_idx.append(i)\n",
        "        else:                                                                       #Indexes of non-selected features get added to delete array\n",
        "            temp_del.append(i)\n",
        "    print('Selected', temp)\n",
        "    print('Features (total/selected):', len(data_np[0]), len(temp))\n",
        "    print('\\n')\n",
        "            \n",
        "                \n",
        "    ##3) Filter selected columns from original dataset #########\n",
        "    header = header[0:feat_start]\n",
        "    for field in temp:\n",
        "        header.append(field)\n",
        "    data_np = np.delete(data_np, temp_del, axis=1)                                 #Deletes non-selected features by index)\n",
        "    \n",
        "    \n",
        "\n",
        "#############################################################################\n",
        "#\n",
        "# Train SciKit Models\n",
        "#\n",
        "##########################################\n",
        "\n",
        "print('--ML Model Output--', '\\n')\n",
        "\n",
        "#Test/Train split\n",
        "data_train, data_test, target_train, target_test = train_test_split(data_np, target_np, test_size=0.35)\n",
        "\n",
        "####Classifiers####\n",
        "if binning==1 and cross_val==0:\n",
        "    #SciKit\n",
        "    '''Test/Train split unused in this homework, skip down to CV section'''\n",
        " \n",
        "\n",
        "                                                                                                                         \n",
        " \n",
        "####Cross-Val Classifiers####\n",
        "if binning==1 and cross_val==1:\n",
        "    #Setup Crossval classifier scorers\n",
        "    scorers = {'Accuracy': 'accuracy', 'roc_auc': 'roc_auc'}                                                                                                                \n",
        "    \n",
        "    #SciKit Gradient Boosting - Cross Val\n",
        "    start_ts=time.time()\n",
        "    clf=GradientBoostingClassifier(n_estimators=100, loss='deviance', learning_rate=0.1, max_depth=3, min_samples_split=3, random_state=rand_st)\n",
        "    scores= cross_validate(clf, data_np, target_np, scoring=scorers, cv=5)\n",
        "\n",
        "    scores_Acc = scores['test_Accuracy']                                                                                                                                    \n",
        "    print(\"Gradient Boosting - Random Forest Acc: %0.2f (+/- %0.2f)\" % (scores_Acc.mean(), scores_Acc.std() * 2))                                                                                                    \n",
        "    scores_AUC= scores['test_roc_auc']                                                                     #Only works with binary classes, not multiclass                  \n",
        "    print(\"Gradient Boosting - Random Forest AUC: %0.2f (+/- %0.2f)\" % (scores_AUC.mean(), scores_AUC.std() * 2))                           \n",
        "    print(\"GB - CV Runtime:\", time.time()-start_ts)\n",
        "\n",
        "\n",
        "    #SciKit Ada Boosting - Cross Val\n",
        "    start_ts=time.time()\n",
        "    clf=AdaBoostClassifier(n_estimators=100, base_estimator=None, learning_rate=0.1, random_state=rand_st)\n",
        "    scores= cross_validate(clf, data_np, target_np, scoring=scorers, cv=5)\n",
        "\n",
        "    scores_Acc = scores['test_Accuracy']                                                                                                                                    \n",
        "    print(\"Ada Boost - Random Forest Acc: %0.2f (+/- %0.2f)\" % (scores_Acc.mean(), scores_Acc.std() * 2))                                                                                                    \n",
        "    scores_AUC= scores['test_roc_auc']                                                                     #Only works with binary classes, not multiclass                  \n",
        "    print(\"Ada Boost - Random Forest AUC: %0.2f (+/- %0.2f)\" % (scores_AUC.mean(), scores_AUC.std() * 2))                           \n",
        "    print(\"Ada - CV Runtime:\", time.time()-start_ts)\n",
        "\n",
        "\n",
        "    #SciKit Neural Network - Cross Val\n",
        "    start_ts=time.time()\n",
        "    clf=MLPClassifier(activation='logistic', solver='adam', alpha=0.0001, max_iter=1000, hidden_layer_sizes=(10,), random_state=rand_st)\n",
        "    scores= cross_validate(clf, data_np, target_np, scoring=scorers, cv=5)\n",
        "\n",
        "    scores_Acc = scores['test_Accuracy']                                                                                                                                    \n",
        "    print(\"Neural Network - Acc: %0.2f (+/- %0.2f)\" % (scores_Acc.mean(), scores_Acc.std() * 2))                                                                                                    \n",
        "    scores_AUC= scores['test_roc_auc']                                                                     #Only works with binary classes, not multiclass                  \n",
        "    print(\"Neural Network - AUC: %0.2f (+/- %0.2f)\" % (scores_AUC.mean(), scores_AUC.std() * 2))                           \n",
        "    print(\"NN - CV Runtime:\", time.time()-start_ts) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['HeartDiseaseorAttack', 'HighBP', 'HighChol', 'CholCheck', 'BMI', 'Smoker', 'Stroke', 'Diabetes', 'PhysActivity', 'Fruits', 'Veggies', 'HvyAlcoholConsump', 'AnyHealthcare', 'NoDocbcCost', 'GenHlth', 'MentHlth', 'PhysHlth', 'DiffWalk', 'Sex', 'Age', 'Education', 'Income']\n",
            "253680 253680\n",
            "\n",
            "\n",
            "--ML Model Output-- \n",
            "\n",
            "Gradient Boosting - Random Forest Acc: 0.91 (+/- 0.00)\n",
            "Gradient Boosting - Random Forest AUC: 0.85 (+/- 0.01)\n",
            "GB - CV Runtime: 153.49274706840515\n",
            "Ada Boost - Random Forest Acc: 0.91 (+/- 0.00)\n",
            "Ada Boost - Random Forest AUC: 0.84 (+/- 0.01)\n",
            "Ada - CV Runtime: 92.66851735115051\n",
            "Neural Network - Acc: 0.91 (+/- 0.00)\n",
            "Neural Network - AUC: 0.85 (+/- 0.01)\n",
            "NN - CV Runtime: 113.11492609977722\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DhGgU7bp1aO"
      },
      "source": [
        "### AdaBoost, GradientBoost, and Neural Network - w/ Feature Selection - Full Dataset\n",
        "Gradient Boosting:\n",
        "* Gradient Boosting - Acc: 0.91 (+/- 0.00)\n",
        "* Gradient Boosting - AUC: 0.85 (+/- 0.01)\n",
        "* GB - CV Runtime: 54.26 seconds\n",
        "\n",
        "Ada Boost:\n",
        "* Ada Boost - Acc: 0.91 (+/- 0.00)\n",
        "* Ada Boost - AUC: 0.84 (+/- 0.01)\n",
        "* Ada - CV Runtime: 49.80 seconds\n",
        "\n",
        "Neural Network:\n",
        "* Neural Network - Acc: 0.91 (+/- 0.00)\n",
        "* Neural Network - AUC: 0.84 (+/- 0.01)\n",
        "* NN - CV Runtime: 36.23 seconds\n",
        "\n",
        "Notes:\n",
        "* Selected Features: ['HighBP', 'HighChol', 'Stroke', 'GenHlth', 'DiffWalk', 'Sex', 'Age']\n",
        "* Features (total/selected): 21 7\n",
        "* Note that the selected features are different from the ones identified in the Random Forest feature important and selection.\n",
        "* No significant change in ACC or AUC when using feature selection, just faster runtimes.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0wZbpKnq7da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "417b1ff5-f6c6-4204-82b8-46aaad9850d2"
      },
      "source": [
        "#SciKit DSC540 HW1\n",
        "'''created by Casey Bennett 2018, www.CaseyBennett.com'''\n",
        "\n",
        "import sys\n",
        "import csv\n",
        "import math\n",
        "import numpy as np\n",
        "from operator import itemgetter\n",
        "import time\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.externals import joblib\n",
        "from sklearn.feature_selection import RFE, VarianceThreshold, SelectFromModel\n",
        "from sklearn.feature_selection import SelectKBest, mutual_info_regression, mutual_info_classif, chi2\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import cross_validate, train_test_split\n",
        "from sklearn.preprocessing import KBinsDiscretizer, scale\n",
        "\n",
        "#Handle annoying warnings\n",
        "import warnings, sklearn.exceptions\n",
        "warnings.filterwarnings(\"ignore\", category=sklearn.exceptions.ConvergenceWarning)\n",
        "\n",
        "\n",
        "#############################################################################\n",
        "#\n",
        "# Global parameters\n",
        "#\n",
        "#####################\n",
        "\n",
        "target_idx=0                                        #Index of Target variable\n",
        "cross_val=1                                         #Control Switch for CV                                                                                                                                                      \n",
        "norm_target=0                                       #Normalize target switch\n",
        "norm_features=0                                     #Normalize target switch\n",
        "binning=1                                           #Control Switch for Bin Target\n",
        "bin_cnt=2                                           #If bin target, this sets number of classes\n",
        "feat_select=1                                       #Control Switch for Feature Selection                                                                                   \n",
        "fs_type=2                                           #Feature Selection type (1=Stepwise Backwards Removal, 2=Wrapper Select, 3=Univariate Selection)                        \n",
        "lv_filter=0                                         #Control switch for low variance filter on features\n",
        "feat_start=1                                        #Start column of features\n",
        "k_cnt=5                                             #Number of 'Top k' best ranked features to select, only applies for fs_types 1 and 3\n",
        "\n",
        "#Set global model parameters\n",
        "rand_st=1                                           #Set Random State variable for randomizing splits on runs\n",
        "\n",
        "\n",
        "#############################################################################\n",
        "#\n",
        "# Load Data\n",
        "#\n",
        "#####################\n",
        "\n",
        "file1= csv.reader(open('brfss2015_cleaned.csv'), delimiter=',', quotechar='\"')\n",
        "\n",
        "#Read Header Line\n",
        "header=next(file1)            \n",
        "\n",
        "#Read data\n",
        "data=[]\n",
        "target=[]\n",
        "for row in file1:\n",
        "    #Load Target\n",
        "    if row[target_idx]=='':                         #If target is blank, skip row                       \n",
        "        continue\n",
        "    else:\n",
        "        target.append(float(row[target_idx]))       #If pre-binned class, change float to int\n",
        "\n",
        "    #Load row into temp array, cast columns  \n",
        "    temp=[]\n",
        "                 \n",
        "    for j in range(feat_start,len(header)):\n",
        "        if row[j]=='':\n",
        "            temp.append(float())\n",
        "        else:\n",
        "            temp.append(float(row[j]))\n",
        "\n",
        "    #Load temp into Data array\n",
        "    data.append(temp)\n",
        "  \n",
        "#Test Print\n",
        "print(header)\n",
        "print(len(target),len(data))\n",
        "print('\\n')\n",
        "\n",
        "data_np=np.asarray(data)\n",
        "target_np=np.asarray(target)\n",
        "\n",
        "\n",
        "#############################################################################\n",
        "#\n",
        "# Preprocess data\n",
        "#\n",
        "##########################################\n",
        "\n",
        "if norm_target==1:\n",
        "    #Target normalization for continuous values\n",
        "    target_np=scale(target_np)\n",
        "\n",
        "if norm_features==1:\n",
        "    #Feature normalization for continuous values\n",
        "    data_np=scale(data_np)\n",
        "\n",
        "'''if binning==1:\n",
        "    #Discretize Target variable with KBinsDiscretizer\n",
        "    enc = KBinsDiscretizer(n_bins=[bin_cnt], encode='ordinal', strategy='quantile')                         #Strategy here is important, quantile creating equal bins, but kmeans prob being more valid \"clusters\"\n",
        "    target_np_bin = enc.fit_transform(target_np.reshape(-1,1))\n",
        "\n",
        "    #Get Bin min/max\n",
        "    temp=[[] for x in range(bin_cnt+1)]\n",
        "    for i in range(len(target_np)):\n",
        "        for j in range(bin_cnt):\n",
        "            if target_np_bin[i]==j:\n",
        "                temp[j].append(target_np[i])\n",
        "\n",
        "    for j in range(bin_cnt):\n",
        "        print('Bin', j, ':', min(temp[j]), max(temp[j]), len(temp[j]))\n",
        "    print('\\n')\n",
        "\n",
        "    #Convert Target array back to correct shape\n",
        "    target_np=np.ravel(target_np_bin)'''\n",
        "\n",
        "\n",
        "#############################################################################\n",
        "#\n",
        "# Feature Selection\n",
        "#\n",
        "##########################################\n",
        "\n",
        "#Low Variance Filter\n",
        "if lv_filter==1:\n",
        "    print('--LOW VARIANCE FILTER ON--', '\\n')\n",
        "    \n",
        "    #LV Threshold\n",
        "    sel = VarianceThreshold(threshold=0.5)                                      #Removes any feature with less than 20% variance\n",
        "    fit_mod=sel.fit(data_np)\n",
        "    fitted=sel.transform(data_np)\n",
        "    sel_idx=fit_mod.get_support()\n",
        "\n",
        "    #Get lists of selected and non-selected features (names and indexes)\n",
        "    temp=[]\n",
        "    temp_idx=[]\n",
        "    temp_del=[]\n",
        "    for i in range(len(data_np[0])):\n",
        "        if sel_idx[i]==1:                                                           #Selected Features get added to temp header\n",
        "            temp.append(header[i+feat_start])\n",
        "            temp_idx.append(i)\n",
        "        else:                                                                       #Indexes of non-selected features get added to delete array\n",
        "            temp_del.append(i)\n",
        "\n",
        "    print('Selected', temp)\n",
        "    print('Features (total, selected):', len(data_np[0]), len(temp))\n",
        "    print('\\n')\n",
        "\n",
        "    #Filter selected columns from original dataset\n",
        "    header = header[0:feat_start]\n",
        "    for field in temp:\n",
        "        header.append(field)\n",
        "    data_np = np.delete(data_np, temp_del, axis=1)                                 #Deletes non-selected features by index\n",
        "\n",
        "\n",
        "#Feature Selection\n",
        "if feat_select==1:\n",
        "    '''Three steps:\n",
        "       1) Run Feature Selection\n",
        "       2) Get lists of selected and non-selected features\n",
        "       3) Filter columns from original dataset\n",
        "       '''\n",
        "    \n",
        "    print('--FEATURE SELECTION ON--', '\\n')\n",
        "    \n",
        "    ##1) Run Feature Selection #######\n",
        "    if fs_type==1:\n",
        "        #Stepwise Recursive Backwards Feature removal\n",
        "        if binning==1:\n",
        "            clf = RandomForestClassifier(n_estimators=200, max_depth=None, min_samples_split=3, criterion='entropy', random_state=rand_st)\n",
        "            sel = RFE(clf, n_features_to_select=k_cnt, step=.1)\n",
        "            print('Stepwise Recursive Backwards - Random Forest: ')\n",
        "        if binning==0:\n",
        "            rgr = RandomForestRegressor(n_estimators=500, max_depth=None, min_samples_split=3, criterion='mse', random_state=rand_st)\n",
        "            sel = RFE(rgr, n_features_to_select=k_cnt, step=.1)\n",
        "            print('Stepwise Recursive Backwards - Random Forest: ')\n",
        "            \n",
        "        fit_mod=sel.fit(data_np, target_np)\n",
        "        print(sel.ranking_)\n",
        "        sel_idx=fit_mod.get_support()      \n",
        "\n",
        "    if fs_type==2:\n",
        "        #Wrapper Select via model\n",
        "        if binning==1:\n",
        "            clf = GradientBoostingClassifier(n_estimators=100, loss='deviance', learning_rate=0.1, max_depth=3, min_samples_split=3, random_state=rand_st)\n",
        "            sel = SelectFromModel(clf, prefit=False, threshold='mean', max_features=None)                                                           #to select only based on max_features, set to integer value and set threshold=-np.inf\n",
        "            print ('Wrapper Select: ')\n",
        "        if binning==0:\n",
        "            rgr = '''Unused in this homework'''\n",
        "            sel = SelectFromModel(rgr, prefit=False, threshold='mean', max_features=None)\n",
        "            print ('Wrapper Select: ')\n",
        "            \n",
        "        fit_mod=sel.fit(data_np, target_np)    \n",
        "        sel_idx=fit_mod.get_support()\n",
        "\n",
        "    if fs_type==3:\n",
        "        if binning==1:                                                              ######Only work if the Target is binned###########\n",
        "            #Univariate Feature Selection - Chi-squared\n",
        "            sel=SelectKBest(chi2, k=k_cnt)\n",
        "            fit_mod=sel.fit(data_np, target_np)                                         #will throw error if any negative values in features, so turn off feature normalization, or switch to mutual_info_classif\n",
        "            print ('Univariate Feature Selection - Chi2: ')\n",
        "            sel_idx=fit_mod.get_support()\n",
        "\n",
        "        if binning==0:                                                              ######Only work if the Target is continuous###########\n",
        "            #Univariate Feature Selection - Mutual Info Regression\n",
        "            sel=SelectKBest(mutual_info_regression, k=k_cnt)\n",
        "            fit_mod=sel.fit(data_np, target_np)\n",
        "            print ('Univariate Feature Selection - Mutual Info: ')\n",
        "            sel_idx=fit_mod.get_support()\n",
        "\n",
        "        #Print ranked variables out sorted\n",
        "        temp=[]\n",
        "        scores=fit_mod.scores_\n",
        "        for i in range(feat_start, len(header)):            \n",
        "            temp.append([header[i], float(scores[i-feat_start])])\n",
        "\n",
        "        print('Ranked Features')\n",
        "        temp_sort=sorted(temp, key=itemgetter(1), reverse=True)\n",
        "        for i in range(len(temp_sort)):\n",
        "            print(i, temp_sort[i][0], ':', temp_sort[i][1])\n",
        "        print('\\n')\n",
        "\n",
        "    ##2) Get lists of selected and non-selected features (names and indexes) #######\n",
        "    temp=[]\n",
        "    temp_idx=[]\n",
        "    temp_del=[]\n",
        "    for i in range(len(data_np[0])):\n",
        "        if sel_idx[i]==1:                                                           #Selected Features get added to temp header\n",
        "            temp.append(header[i+feat_start])\n",
        "            temp_idx.append(i)\n",
        "        else:                                                                       #Indexes of non-selected features get added to delete array\n",
        "            temp_del.append(i)\n",
        "    print('Selected', temp)\n",
        "    print('Features (total/selected):', len(data_np[0]), len(temp))\n",
        "    print('\\n')\n",
        "            \n",
        "                \n",
        "    ##3) Filter selected columns from original dataset #########\n",
        "    header = header[0:feat_start]\n",
        "    for field in temp:\n",
        "        header.append(field)\n",
        "    data_np = np.delete(data_np, temp_del, axis=1)                                 #Deletes non-selected features by index)\n",
        "    \n",
        "    \n",
        "\n",
        "#############################################################################\n",
        "#\n",
        "# Train SciKit Models\n",
        "#\n",
        "##########################################\n",
        "\n",
        "print('--ML Model Output--', '\\n')\n",
        "\n",
        "#Test/Train split\n",
        "data_train, data_test, target_train, target_test = train_test_split(data_np, target_np, test_size=0.35)\n",
        "\n",
        "####Classifiers####\n",
        "if binning==1 and cross_val==0:\n",
        "    #SciKit\n",
        "    '''Test/Train split unused in this homework, skip down to CV section'''\n",
        " \n",
        "\n",
        "                                                                                                                         \n",
        " \n",
        "####Cross-Val Classifiers####\n",
        "if binning==1 and cross_val==1:\n",
        "    #Setup Crossval classifier scorers\n",
        "    scorers = {'Accuracy': 'accuracy', 'roc_auc': 'roc_auc'}                                                                                                                \n",
        "    \n",
        "    #SciKit Gradient Boosting - Cross Val\n",
        "    start_ts=time.time()\n",
        "    clf=GradientBoostingClassifier(n_estimators=100, loss='deviance', learning_rate=0.1, max_depth=3, min_samples_split=3, random_state=rand_st)\n",
        "    scores= cross_validate(clf, data_np, target_np, scoring=scorers, cv=5)\n",
        "\n",
        "    scores_Acc = scores['test_Accuracy']                                                                                                                                    \n",
        "    print(\"Gradient Boosting - Random Forest Acc: %0.2f (+/- %0.2f)\" % (scores_Acc.mean(), scores_Acc.std() * 2))                                                                                                    \n",
        "    scores_AUC= scores['test_roc_auc']                                                                     #Only works with binary classes, not multiclass                  \n",
        "    print(\"Gradient Boosting - Random Forest AUC: %0.2f (+/- %0.2f)\" % (scores_AUC.mean(), scores_AUC.std() * 2))                           \n",
        "    print(\"GB - CV Runtime:\", time.time()-start_ts)\n",
        "\n",
        "\n",
        "    #SciKit Ada Boosting - Cross Val\n",
        "    start_ts=time.time()\n",
        "    clf=AdaBoostClassifier(n_estimators=100, base_estimator=None, learning_rate=0.1, random_state=rand_st)\n",
        "    scores= cross_validate(clf, data_np, target_np, scoring=scorers, cv=5)\n",
        "\n",
        "    scores_Acc = scores['test_Accuracy']                                                                                                                                    \n",
        "    print(\"Ada Boost - Random Forest Acc: %0.2f (+/- %0.2f)\" % (scores_Acc.mean(), scores_Acc.std() * 2))                                                                                                    \n",
        "    scores_AUC= scores['test_roc_auc']                                                                     #Only works with binary classes, not multiclass                  \n",
        "    print(\"Ada Boost - Random Forest AUC: %0.2f (+/- %0.2f)\" % (scores_AUC.mean(), scores_AUC.std() * 2))                           \n",
        "    print(\"Ada - CV Runtime:\", time.time()-start_ts)\n",
        "\n",
        "\n",
        "    #SciKit Neural Network - Cross Val\n",
        "    start_ts=time.time()\n",
        "    clf=MLPClassifier(activation='logistic', solver='adam', alpha=0.0001, max_iter=1000, hidden_layer_sizes=(10,), random_state=rand_st)\n",
        "    scores= cross_validate(clf, data_np, target_np, scoring=scorers, cv=5)\n",
        "\n",
        "    scores_Acc = scores['test_Accuracy']                                                                                                                                    \n",
        "    print(\"Neural Network - Acc: %0.2f (+/- %0.2f)\" % (scores_Acc.mean(), scores_Acc.std() * 2))                                                                                                    \n",
        "    scores_AUC= scores['test_roc_auc']                                                                     #Only works with binary classes, not multiclass                  \n",
        "    print(\"Neural Network - AUC: %0.2f (+/- %0.2f)\" % (scores_AUC.mean(), scores_AUC.std() * 2))                           \n",
        "    print(\"NN - CV Runtime:\", time.time()-start_ts) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['HeartDiseaseorAttack', 'HighBP', 'HighChol', 'CholCheck', 'BMI', 'Smoker', 'Stroke', 'Diabetes', 'PhysActivity', 'Fruits', 'Veggies', 'HvyAlcoholConsump', 'AnyHealthcare', 'NoDocbcCost', 'GenHlth', 'MentHlth', 'PhysHlth', 'DiffWalk', 'Sex', 'Age', 'Education', 'Income']\n",
            "253680 253680\n",
            "\n",
            "\n",
            "--FEATURE SELECTION ON-- \n",
            "\n",
            "Wrapper Select: \n",
            "Selected ['HighBP', 'HighChol', 'Stroke', 'GenHlth', 'DiffWalk', 'Sex', 'Age']\n",
            "Features (total/selected): 21 7\n",
            "\n",
            "\n",
            "--ML Model Output-- \n",
            "\n",
            "Gradient Boosting - Random Forest Acc: 0.91 (+/- 0.00)\n",
            "Gradient Boosting - Random Forest AUC: 0.85 (+/- 0.01)\n",
            "GB - CV Runtime: 54.26185202598572\n",
            "Ada Boost - Random Forest Acc: 0.91 (+/- 0.00)\n",
            "Ada Boost - Random Forest AUC: 0.84 (+/- 0.01)\n",
            "Ada - CV Runtime: 49.80426740646362\n",
            "Neural Network - Acc: 0.91 (+/- 0.00)\n",
            "Neural Network - AUC: 0.84 (+/- 0.01)\n",
            "NN - CV Runtime: 36.237913846969604\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwZvYx6Qxmch"
      },
      "source": [
        "### AdaBoost, GradientBoost, and Neural Network - w/ Feature Selection - 50-50 Dataset\n",
        "Gradient Boosting:\n",
        "* Gradient Boosting - Acc: 0.76 (+/- 0.01)\n",
        "* Gradient Boosting - AUC: 0.84 (+/- 0.01)\n",
        "* GB - CV Runtime: 8.77 seconds\n",
        "\n",
        "Ada Boost:\n",
        "* Ada Boost - Acc: 0.76 (+/- 0.01)\n",
        "* Ada Boost - AUC: 0.83 (+/- 0.01)\n",
        "* Ada - CV Runtime: 8.85 seconds\n",
        "\n",
        "Neural Network:\n",
        "* Neural Network - Acc: 0.76 (+/- 0.01)\n",
        "* Neural Network - AUC: 0.84 (+/- 0.01)\n",
        "* NN - CV Runtime: 18.77 seconds\n",
        "\n",
        "Notes:\n",
        "* Selected Features: ['HighBP', 'HighChol', 'GenHlth', 'Sex', 'Age']\n",
        "* Features (total/selected): 21 5\n",
        "* w/o feature selection was also tested, but there was no significant change in ACC or AUC, just runtime."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWnl5Lvixml6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e655c41-0c50-4ee5-bb59-faa4222334e3"
      },
      "source": [
        "#SciKit DSC540 HW1\n",
        "'''created by Casey Bennett 2018, www.CaseyBennett.com'''\n",
        "\n",
        "import sys\n",
        "import csv\n",
        "import math\n",
        "import numpy as np\n",
        "from operator import itemgetter\n",
        "import time\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.externals import joblib\n",
        "from sklearn.feature_selection import RFE, VarianceThreshold, SelectFromModel\n",
        "from sklearn.feature_selection import SelectKBest, mutual_info_regression, mutual_info_classif, chi2\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import cross_validate, train_test_split\n",
        "from sklearn.preprocessing import KBinsDiscretizer, scale\n",
        "\n",
        "#Handle annoying warnings\n",
        "import warnings, sklearn.exceptions\n",
        "warnings.filterwarnings(\"ignore\", category=sklearn.exceptions.ConvergenceWarning)\n",
        "\n",
        "\n",
        "#############################################################################\n",
        "#\n",
        "# Global parameters\n",
        "#\n",
        "#####################\n",
        "\n",
        "target_idx=0                                        #Index of Target variable\n",
        "cross_val=1                                         #Control Switch for CV                                                                                                                                                      \n",
        "norm_target=0                                       #Normalize target switch\n",
        "norm_features=0                                     #Normalize target switch\n",
        "binning=1                                           #Control Switch for Bin Target\n",
        "bin_cnt=2                                           #If bin target, this sets number of classes\n",
        "feat_select=0                                       #Control Switch for Feature Selection                                                                                   \n",
        "fs_type=2                                           #Feature Selection type (1=Stepwise Backwards Removal, 2=Wrapper Select, 3=Univariate Selection)                        \n",
        "lv_filter=0                                         #Control switch for low variance filter on features\n",
        "feat_start=1                                        #Start column of features\n",
        "k_cnt=5                                             #Number of 'Top k' best ranked features to select, only applies for fs_types 1 and 3\n",
        "\n",
        "#Set global model parameters\n",
        "rand_st=1                                           #Set Random State variable for randomizing splits on runs\n",
        "\n",
        "\n",
        "#############################################################################\n",
        "#\n",
        "# Load Data\n",
        "#\n",
        "#####################\n",
        "\n",
        "file1= csv.reader(open('brfss2015_5050_cleaned.csv'), delimiter=',', quotechar='\"')\n",
        "\n",
        "#Read Header Line\n",
        "header=next(file1)            \n",
        "\n",
        "#Read data\n",
        "data=[]\n",
        "target=[]\n",
        "for row in file1:\n",
        "    #Load Target\n",
        "    if row[target_idx]=='':                         #If target is blank, skip row                       \n",
        "        continue\n",
        "    else:\n",
        "        target.append(float(row[target_idx]))       #If pre-binned class, change float to int\n",
        "\n",
        "    #Load row into temp array, cast columns  \n",
        "    temp=[]\n",
        "                 \n",
        "    for j in range(feat_start,len(header)):\n",
        "        if row[j]=='':\n",
        "            temp.append(float())\n",
        "        else:\n",
        "            temp.append(float(row[j]))\n",
        "\n",
        "    #Load temp into Data array\n",
        "    data.append(temp)\n",
        "  \n",
        "#Test Print\n",
        "print(header)\n",
        "print(len(target),len(data))\n",
        "print('\\n')\n",
        "\n",
        "data_np=np.asarray(data)\n",
        "target_np=np.asarray(target)\n",
        "\n",
        "\n",
        "#############################################################################\n",
        "#\n",
        "# Preprocess data\n",
        "#\n",
        "##########################################\n",
        "\n",
        "if norm_target==1:\n",
        "    #Target normalization for continuous values\n",
        "    target_np=scale(target_np)\n",
        "\n",
        "if norm_features==1:\n",
        "    #Feature normalization for continuous values\n",
        "    data_np=scale(data_np)\n",
        "\n",
        "'''if binning==1:\n",
        "    #Discretize Target variable with KBinsDiscretizer\n",
        "    enc = KBinsDiscretizer(n_bins=[bin_cnt], encode='ordinal', strategy='quantile')                         #Strategy here is important, quantile creating equal bins, but kmeans prob being more valid \"clusters\"\n",
        "    target_np_bin = enc.fit_transform(target_np.reshape(-1,1))\n",
        "\n",
        "    #Get Bin min/max\n",
        "    temp=[[] for x in range(bin_cnt+1)]\n",
        "    for i in range(len(target_np)):\n",
        "        for j in range(bin_cnt):\n",
        "            if target_np_bin[i]==j:\n",
        "                temp[j].append(target_np[i])\n",
        "\n",
        "    for j in range(bin_cnt):\n",
        "        print('Bin', j, ':', min(temp[j]), max(temp[j]), len(temp[j]))\n",
        "    print('\\n')\n",
        "\n",
        "    #Convert Target array back to correct shape\n",
        "    target_np=np.ravel(target_np_bin)'''\n",
        "\n",
        "\n",
        "#############################################################################\n",
        "#\n",
        "# Feature Selection\n",
        "#\n",
        "##########################################\n",
        "\n",
        "#Low Variance Filter\n",
        "if lv_filter==1:\n",
        "    print('--LOW VARIANCE FILTER ON--', '\\n')\n",
        "    \n",
        "    #LV Threshold\n",
        "    sel = VarianceThreshold(threshold=0.5)                                      #Removes any feature with less than 20% variance\n",
        "    fit_mod=sel.fit(data_np)\n",
        "    fitted=sel.transform(data_np)\n",
        "    sel_idx=fit_mod.get_support()\n",
        "\n",
        "    #Get lists of selected and non-selected features (names and indexes)\n",
        "    temp=[]\n",
        "    temp_idx=[]\n",
        "    temp_del=[]\n",
        "    for i in range(len(data_np[0])):\n",
        "        if sel_idx[i]==1:                                                           #Selected Features get added to temp header\n",
        "            temp.append(header[i+feat_start])\n",
        "            temp_idx.append(i)\n",
        "        else:                                                                       #Indexes of non-selected features get added to delete array\n",
        "            temp_del.append(i)\n",
        "\n",
        "    print('Selected', temp)\n",
        "    print('Features (total, selected):', len(data_np[0]), len(temp))\n",
        "    print('\\n')\n",
        "\n",
        "    #Filter selected columns from original dataset\n",
        "    header = header[0:feat_start]\n",
        "    for field in temp:\n",
        "        header.append(field)\n",
        "    data_np = np.delete(data_np, temp_del, axis=1)                                 #Deletes non-selected features by index\n",
        "\n",
        "\n",
        "#Feature Selection\n",
        "if feat_select==1:\n",
        "    '''Three steps:\n",
        "       1) Run Feature Selection\n",
        "       2) Get lists of selected and non-selected features\n",
        "       3) Filter columns from original dataset\n",
        "       '''\n",
        "    \n",
        "    print('--FEATURE SELECTION ON--', '\\n')\n",
        "    \n",
        "    ##1) Run Feature Selection #######\n",
        "    if fs_type==1:\n",
        "        #Stepwise Recursive Backwards Feature removal\n",
        "        if binning==1:\n",
        "            clf = RandomForestClassifier(n_estimators=200, max_depth=None, min_samples_split=3, criterion='entropy', random_state=rand_st)\n",
        "            sel = RFE(clf, n_features_to_select=k_cnt, step=.1)\n",
        "            print('Stepwise Recursive Backwards - Random Forest: ')\n",
        "        if binning==0:\n",
        "            rgr = RandomForestRegressor(n_estimators=500, max_depth=None, min_samples_split=3, criterion='mse', random_state=rand_st)\n",
        "            sel = RFE(rgr, n_features_to_select=k_cnt, step=.1)\n",
        "            print('Stepwise Recursive Backwards - Random Forest: ')\n",
        "            \n",
        "        fit_mod=sel.fit(data_np, target_np)\n",
        "        print(sel.ranking_)\n",
        "        sel_idx=fit_mod.get_support()      \n",
        "\n",
        "    if fs_type==2:\n",
        "        #Wrapper Select via model\n",
        "        if binning==1:\n",
        "            clf = GradientBoostingClassifier(n_estimators=100, loss='deviance', learning_rate=0.1, max_depth=3, min_samples_split=3, random_state=rand_st)\n",
        "            sel = SelectFromModel(clf, prefit=False, threshold='mean', max_features=None)                                                           #to select only based on max_features, set to integer value and set threshold=-np.inf\n",
        "            print ('Wrapper Select: ')\n",
        "        if binning==0:\n",
        "            rgr = '''Unused in this homework'''\n",
        "            sel = SelectFromModel(rgr, prefit=False, threshold='mean', max_features=None)\n",
        "            print ('Wrapper Select: ')\n",
        "            \n",
        "        fit_mod=sel.fit(data_np, target_np)    \n",
        "        sel_idx=fit_mod.get_support()\n",
        "\n",
        "    if fs_type==3:\n",
        "        if binning==1:                                                              ######Only work if the Target is binned###########\n",
        "            #Univariate Feature Selection - Chi-squared\n",
        "            sel=SelectKBest(chi2, k=k_cnt)\n",
        "            fit_mod=sel.fit(data_np, target_np)                                         #will throw error if any negative values in features, so turn off feature normalization, or switch to mutual_info_classif\n",
        "            print ('Univariate Feature Selection - Chi2: ')\n",
        "            sel_idx=fit_mod.get_support()\n",
        "\n",
        "        if binning==0:                                                              ######Only work if the Target is continuous###########\n",
        "            #Univariate Feature Selection - Mutual Info Regression\n",
        "            sel=SelectKBest(mutual_info_regression, k=k_cnt)\n",
        "            fit_mod=sel.fit(data_np, target_np)\n",
        "            print ('Univariate Feature Selection - Mutual Info: ')\n",
        "            sel_idx=fit_mod.get_support()\n",
        "\n",
        "        #Print ranked variables out sorted\n",
        "        temp=[]\n",
        "        scores=fit_mod.scores_\n",
        "        for i in range(feat_start, len(header)):            \n",
        "            temp.append([header[i], float(scores[i-feat_start])])\n",
        "\n",
        "        print('Ranked Features')\n",
        "        temp_sort=sorted(temp, key=itemgetter(1), reverse=True)\n",
        "        for i in range(len(temp_sort)):\n",
        "            print(i, temp_sort[i][0], ':', temp_sort[i][1])\n",
        "        print('\\n')\n",
        "\n",
        "    ##2) Get lists of selected and non-selected features (names and indexes) #######\n",
        "    temp=[]\n",
        "    temp_idx=[]\n",
        "    temp_del=[]\n",
        "    for i in range(len(data_np[0])):\n",
        "        if sel_idx[i]==1:                                                           #Selected Features get added to temp header\n",
        "            temp.append(header[i+feat_start])\n",
        "            temp_idx.append(i)\n",
        "        else:                                                                       #Indexes of non-selected features get added to delete array\n",
        "            temp_del.append(i)\n",
        "    print('Selected', temp)\n",
        "    print('Features (total/selected):', len(data_np[0]), len(temp))\n",
        "    print('\\n')\n",
        "            \n",
        "                \n",
        "    ##3) Filter selected columns from original dataset #########\n",
        "    header = header[0:feat_start]\n",
        "    for field in temp:\n",
        "        header.append(field)\n",
        "    data_np = np.delete(data_np, temp_del, axis=1)                                 #Deletes non-selected features by index)\n",
        "    \n",
        "    \n",
        "\n",
        "#############################################################################\n",
        "#\n",
        "# Train SciKit Models\n",
        "#\n",
        "##########################################\n",
        "\n",
        "print('--ML Model Output--', '\\n')\n",
        "\n",
        "#Test/Train split\n",
        "data_train, data_test, target_train, target_test = train_test_split(data_np, target_np, test_size=0.35)\n",
        "\n",
        "####Classifiers####\n",
        "if binning==1 and cross_val==0:\n",
        "    #SciKit\n",
        "    '''Test/Train split unused in this homework, skip down to CV section'''\n",
        " \n",
        "\n",
        "                                                                                                                         \n",
        " \n",
        "####Cross-Val Classifiers####\n",
        "if binning==1 and cross_val==1:\n",
        "    #Setup Crossval classifier scorers\n",
        "    scorers = {'Accuracy': 'accuracy', 'roc_auc': 'roc_auc'}                                                                                                                \n",
        "    \n",
        "    #SciKit Gradient Boosting - Cross Val\n",
        "    start_ts=time.time()\n",
        "    clf=GradientBoostingClassifier(n_estimators=100, loss='deviance', learning_rate=0.1, max_depth=3, min_samples_split=3, random_state=rand_st)\n",
        "    scores= cross_validate(clf, data_np, target_np, scoring=scorers, cv=5)\n",
        "\n",
        "    scores_Acc = scores['test_Accuracy']                                                                                                                                    \n",
        "    print(\"Gradient Boosting - Random Forest Acc: %0.2f (+/- %0.2f)\" % (scores_Acc.mean(), scores_Acc.std() * 2))                                                                                                    \n",
        "    scores_AUC= scores['test_roc_auc']                                                                     #Only works with binary classes, not multiclass                  \n",
        "    print(\"Gradient Boosting - Random Forest AUC: %0.2f (+/- %0.2f)\" % (scores_AUC.mean(), scores_AUC.std() * 2))                           \n",
        "    print(\"GB - CV Runtime:\", time.time()-start_ts)\n",
        "\n",
        "\n",
        "    #SciKit Ada Boosting - Cross Val\n",
        "    start_ts=time.time()\n",
        "    clf=AdaBoostClassifier(n_estimators=100, base_estimator=None, learning_rate=0.1, random_state=rand_st)\n",
        "    scores= cross_validate(clf, data_np, target_np, scoring=scorers, cv=5)\n",
        "\n",
        "    scores_Acc = scores['test_Accuracy']                                                                                                                                    \n",
        "    print(\"Ada Boost - Random Forest Acc: %0.2f (+/- %0.2f)\" % (scores_Acc.mean(), scores_Acc.std() * 2))                                                                                                    \n",
        "    scores_AUC= scores['test_roc_auc']                                                                     #Only works with binary classes, not multiclass                  \n",
        "    print(\"Ada Boost - Random Forest AUC: %0.2f (+/- %0.2f)\" % (scores_AUC.mean(), scores_AUC.std() * 2))                           \n",
        "    print(\"Ada - CV Runtime:\", time.time()-start_ts)\n",
        "\n",
        "\n",
        "    #SciKit Neural Network - Cross Val\n",
        "    start_ts=time.time()\n",
        "    clf=MLPClassifier(activation='logistic', solver='adam', alpha=0.0001, max_iter=1000, hidden_layer_sizes=(10,), random_state=rand_st)\n",
        "    scores= cross_validate(clf, data_np, target_np, scoring=scorers, cv=5)\n",
        "\n",
        "    scores_Acc = scores['test_Accuracy']                                                                                                                                    \n",
        "    print(\"Neural Network - Acc: %0.2f (+/- %0.2f)\" % (scores_Acc.mean(), scores_Acc.std() * 2))                                                                                                    \n",
        "    scores_AUC= scores['test_roc_auc']                                                                     #Only works with binary classes, not multiclass                  \n",
        "    print(\"Neural Network - AUC: %0.2f (+/- %0.2f)\" % (scores_AUC.mean(), scores_AUC.std() * 2))                           \n",
        "    print(\"NN - CV Runtime:\", time.time()-start_ts) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['HeartDiseaseorAttack', 'HighBP', 'HighChol', 'CholCheck', 'BMI', 'Smoker', 'Stroke', 'Diabetes', 'PhysActivity', 'Fruits', 'Veggies', 'HvyAlcoholConsump', 'AnyHealthcare', 'NoDocbcCost', 'GenHlth', 'MentHlth', 'PhysHlth', 'DiffWalk', 'Sex', 'Age', 'Education', 'Income']\n",
            "47786 47786\n",
            "\n",
            "\n",
            "--ML Model Output-- \n",
            "\n",
            "Gradient Boosting - Random Forest Acc: 0.77 (+/- 0.01)\n",
            "Gradient Boosting - Random Forest AUC: 0.85 (+/- 0.01)\n",
            "GB - CV Runtime: 23.038897275924683\n",
            "Ada Boost - Random Forest Acc: 0.77 (+/- 0.01)\n",
            "Ada Boost - Random Forest AUC: 0.84 (+/- 0.01)\n",
            "Ada - CV Runtime: 15.661539793014526\n",
            "Neural Network - Acc: 0.77 (+/- 0.01)\n",
            "Neural Network - AUC: 0.85 (+/- 0.01)\n",
            "NN - CV Runtime: 40.660688638687134\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogba1a0zx9Df"
      },
      "source": [
        "### AdaBoost, GradientBoost, and Neural Network - w/ Feature Selection - 60-40 Dataset\n",
        "Gradient Boosting:\n",
        "* Gradient Boosting - Acc: 0.78 (+/- 0.01)\n",
        "* Gradient Boosting - AUC: 0.84 (+/- 0.01)\n",
        "* GB - CV Runtime: 13.71 seconds\n",
        "\n",
        "Ada Boost:\n",
        "* Ada Boost - Acc: 0.77 (+/- 0.01)\n",
        "* Ada Boost - AUC: 0.84 (+/- 0.01)\n",
        "* Ada - CV Runtime: 13.24 seconds\n",
        "\n",
        "Neural Network:\n",
        "* Neural Network - Acc: 0.78 (+/- 0.01)\n",
        "* Neural Network - AUC: 0.84 (+/- 0.01\n",
        "* NN - CV Runtime: 21.01 seconds\n",
        "\n",
        "Notes: \n",
        "* Selected Features['HighBP', 'HighChol', 'Stroke', 'GenHlth', 'Sex', 'Age']\n",
        "* Features (total/selected): 21 6\n",
        "* w/o feature selection was also tested, but there was no significant change in ACC or AUC, just runtime.\n",
        "* Changes to GB max_depth did not improve ACC or AUC.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-S2IZGrr7jX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8dddc0a-bb94-4556-d16b-f344aab49248"
      },
      "source": [
        "#SciKit DSC540 HW1\n",
        "'''created by Casey Bennett 2018, www.CaseyBennett.com'''\n",
        "\n",
        "import sys\n",
        "import csv\n",
        "import math\n",
        "import numpy as np\n",
        "from operator import itemgetter\n",
        "import time\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.externals import joblib\n",
        "from sklearn.feature_selection import RFE, VarianceThreshold, SelectFromModel\n",
        "from sklearn.feature_selection import SelectKBest, mutual_info_regression, mutual_info_classif, chi2\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import cross_validate, train_test_split\n",
        "from sklearn.preprocessing import KBinsDiscretizer, scale\n",
        "\n",
        "#Handle annoying warnings\n",
        "import warnings, sklearn.exceptions\n",
        "warnings.filterwarnings(\"ignore\", category=sklearn.exceptions.ConvergenceWarning)\n",
        "\n",
        "\n",
        "#############################################################################\n",
        "#\n",
        "# Global parameters\n",
        "#\n",
        "#####################\n",
        "\n",
        "target_idx=0                                        #Index of Target variable\n",
        "cross_val=1                                         #Control Switch for CV                                                                                                                                                      \n",
        "norm_target=0                                       #Normalize target switch\n",
        "norm_features=0                                     #Normalize target switch\n",
        "binning=1                                           #Control Switch for Bin Target\n",
        "bin_cnt=2                                           #If bin target, this sets number of classes\n",
        "feat_select=1                                       #Control Switch for Feature Selection                                                                                   \n",
        "fs_type=2                                           #Feature Selection type (1=Stepwise Backwards Removal, 2=Wrapper Select, 3=Univariate Selection)                        \n",
        "lv_filter=0                                         #Control switch for low variance filter on features\n",
        "feat_start=1                                        #Start column of features\n",
        "k_cnt=5                                             #Number of 'Top k' best ranked features to select, only applies for fs_types 1 and 3\n",
        "\n",
        "#Set global model parameters\n",
        "rand_st=1                                           #Set Random State variable for randomizing splits on runs\n",
        "\n",
        "\n",
        "#############################################################################\n",
        "#\n",
        "# Load Data\n",
        "#\n",
        "#####################\n",
        "\n",
        "file1= csv.reader(open('brfss2015_6040_cleaned.csv'), delimiter=',', quotechar='\"')\n",
        "\n",
        "#Read Header Line\n",
        "header=next(file1)            \n",
        "\n",
        "#Read data\n",
        "data=[]\n",
        "target=[]\n",
        "for row in file1:\n",
        "    #Load Target\n",
        "    if row[target_idx]=='':                         #If target is blank, skip row                       \n",
        "        continue\n",
        "    else:\n",
        "        target.append(float(row[target_idx]))       #If pre-binned class, change float to int\n",
        "\n",
        "    #Load row into temp array, cast columns  \n",
        "    temp=[]\n",
        "                 \n",
        "    for j in range(feat_start,len(header)):\n",
        "        if row[j]=='':\n",
        "            temp.append(float())\n",
        "        else:\n",
        "            temp.append(float(row[j]))\n",
        "\n",
        "    #Load temp into Data array\n",
        "    data.append(temp)\n",
        "  \n",
        "#Test Print\n",
        "print(header)\n",
        "print(len(target),len(data))\n",
        "print('\\n')\n",
        "\n",
        "data_np=np.asarray(data)\n",
        "target_np=np.asarray(target)\n",
        "\n",
        "\n",
        "#############################################################################\n",
        "#\n",
        "# Preprocess data\n",
        "#\n",
        "##########################################\n",
        "\n",
        "if norm_target==1:\n",
        "    #Target normalization for continuous values\n",
        "    target_np=scale(target_np)\n",
        "\n",
        "if norm_features==1:\n",
        "    #Feature normalization for continuous values\n",
        "    data_np=scale(data_np)\n",
        "\n",
        "'''if binning==1:\n",
        "    #Discretize Target variable with KBinsDiscretizer\n",
        "    enc = KBinsDiscretizer(n_bins=[bin_cnt], encode='ordinal', strategy='quantile')                         #Strategy here is important, quantile creating equal bins, but kmeans prob being more valid \"clusters\"\n",
        "    target_np_bin = enc.fit_transform(target_np.reshape(-1,1))\n",
        "\n",
        "    #Get Bin min/max\n",
        "    temp=[[] for x in range(bin_cnt+1)]\n",
        "    for i in range(len(target_np)):\n",
        "        for j in range(bin_cnt):\n",
        "            if target_np_bin[i]==j:\n",
        "                temp[j].append(target_np[i])\n",
        "\n",
        "    for j in range(bin_cnt):\n",
        "        print('Bin', j, ':', min(temp[j]), max(temp[j]), len(temp[j]))\n",
        "    print('\\n')\n",
        "\n",
        "    #Convert Target array back to correct shape\n",
        "    target_np=np.ravel(target_np_bin)'''\n",
        "\n",
        "\n",
        "#############################################################################\n",
        "#\n",
        "# Feature Selection\n",
        "#\n",
        "##########################################\n",
        "\n",
        "#Low Variance Filter\n",
        "if lv_filter==1:\n",
        "    print('--LOW VARIANCE FILTER ON--', '\\n')\n",
        "    \n",
        "    #LV Threshold\n",
        "    sel = VarianceThreshold(threshold=0.5)                                      #Removes any feature with less than 20% variance\n",
        "    fit_mod=sel.fit(data_np)\n",
        "    fitted=sel.transform(data_np)\n",
        "    sel_idx=fit_mod.get_support()\n",
        "\n",
        "    #Get lists of selected and non-selected features (names and indexes)\n",
        "    temp=[]\n",
        "    temp_idx=[]\n",
        "    temp_del=[]\n",
        "    for i in range(len(data_np[0])):\n",
        "        if sel_idx[i]==1:                                                           #Selected Features get added to temp header\n",
        "            temp.append(header[i+feat_start])\n",
        "            temp_idx.append(i)\n",
        "        else:                                                                       #Indexes of non-selected features get added to delete array\n",
        "            temp_del.append(i)\n",
        "\n",
        "    print('Selected', temp)\n",
        "    print('Features (total, selected):', len(data_np[0]), len(temp))\n",
        "    print('\\n')\n",
        "\n",
        "    #Filter selected columns from original dataset\n",
        "    header = header[0:feat_start]\n",
        "    for field in temp:\n",
        "        header.append(field)\n",
        "    data_np = np.delete(data_np, temp_del, axis=1)                                 #Deletes non-selected features by index\n",
        "\n",
        "\n",
        "#Feature Selection\n",
        "if feat_select==1:\n",
        "    '''Three steps:\n",
        "       1) Run Feature Selection\n",
        "       2) Get lists of selected and non-selected features\n",
        "       3) Filter columns from original dataset\n",
        "       '''\n",
        "    \n",
        "    print('--FEATURE SELECTION ON--', '\\n')\n",
        "    \n",
        "    ##1) Run Feature Selection #######\n",
        "    if fs_type==1:\n",
        "        #Stepwise Recursive Backwards Feature removal\n",
        "        if binning==1:\n",
        "            clf = RandomForestClassifier(n_estimators=200, max_depth=None, min_samples_split=3, criterion='entropy', random_state=rand_st)\n",
        "            sel = RFE(clf, n_features_to_select=k_cnt, step=.1)\n",
        "            print('Stepwise Recursive Backwards - Random Forest: ')\n",
        "        if binning==0:\n",
        "            rgr = RandomForestRegressor(n_estimators=500, max_depth=None, min_samples_split=3, criterion='mse', random_state=rand_st)\n",
        "            sel = RFE(rgr, n_features_to_select=k_cnt, step=.1)\n",
        "            print('Stepwise Recursive Backwards - Random Forest: ')\n",
        "            \n",
        "        fit_mod=sel.fit(data_np, target_np)\n",
        "        print(sel.ranking_)\n",
        "        sel_idx=fit_mod.get_support()      \n",
        "\n",
        "    if fs_type==2:\n",
        "        #Wrapper Select via model\n",
        "        if binning==1:\n",
        "            clf = GradientBoostingClassifier(n_estimators=100, loss='deviance', learning_rate=0.1, max_depth=3, min_samples_split=3, random_state=rand_st)\n",
        "            sel = SelectFromModel(clf, prefit=False, threshold='mean', max_features=None)                                                           #to select only based on max_features, set to integer value and set threshold=-np.inf\n",
        "            print ('Wrapper Select: ')\n",
        "        if binning==0:\n",
        "            rgr = '''Unused in this homework'''\n",
        "            sel = SelectFromModel(rgr, prefit=False, threshold='mean', max_features=None)\n",
        "            print ('Wrapper Select: ')\n",
        "            \n",
        "        fit_mod=sel.fit(data_np, target_np)    \n",
        "        sel_idx=fit_mod.get_support()\n",
        "\n",
        "    if fs_type==3:\n",
        "        if binning==1:                                                              ######Only work if the Target is binned###########\n",
        "            #Univariate Feature Selection - Chi-squared\n",
        "            sel=SelectKBest(chi2, k=k_cnt)\n",
        "            fit_mod=sel.fit(data_np, target_np)                                         #will throw error if any negative values in features, so turn off feature normalization, or switch to mutual_info_classif\n",
        "            print ('Univariate Feature Selection - Chi2: ')\n",
        "            sel_idx=fit_mod.get_support()\n",
        "\n",
        "        if binning==0:                                                              ######Only work if the Target is continuous###########\n",
        "            #Univariate Feature Selection - Mutual Info Regression\n",
        "            sel=SelectKBest(mutual_info_regression, k=k_cnt)\n",
        "            fit_mod=sel.fit(data_np, target_np)\n",
        "            print ('Univariate Feature Selection - Mutual Info: ')\n",
        "            sel_idx=fit_mod.get_support()\n",
        "\n",
        "        #Print ranked variables out sorted\n",
        "        temp=[]\n",
        "        scores=fit_mod.scores_\n",
        "        for i in range(feat_start, len(header)):            \n",
        "            temp.append([header[i], float(scores[i-feat_start])])\n",
        "\n",
        "        print('Ranked Features')\n",
        "        temp_sort=sorted(temp, key=itemgetter(1), reverse=True)\n",
        "        for i in range(len(temp_sort)):\n",
        "            print(i, temp_sort[i][0], ':', temp_sort[i][1])\n",
        "        print('\\n')\n",
        "\n",
        "    ##2) Get lists of selected and non-selected features (names and indexes) #######\n",
        "    temp=[]\n",
        "    temp_idx=[]\n",
        "    temp_del=[]\n",
        "    for i in range(len(data_np[0])):\n",
        "        if sel_idx[i]==1:                                                           #Selected Features get added to temp header\n",
        "            temp.append(header[i+feat_start])\n",
        "            temp_idx.append(i)\n",
        "        else:                                                                       #Indexes of non-selected features get added to delete array\n",
        "            temp_del.append(i)\n",
        "    print('Selected', temp)\n",
        "    print('Features (total/selected):', len(data_np[0]), len(temp))\n",
        "    print('\\n')\n",
        "            \n",
        "                \n",
        "    ##3) Filter selected columns from original dataset #########\n",
        "    header = header[0:feat_start]\n",
        "    for field in temp:\n",
        "        header.append(field)\n",
        "    data_np = np.delete(data_np, temp_del, axis=1)                                 #Deletes non-selected features by index)\n",
        "    \n",
        "    \n",
        "\n",
        "#############################################################################\n",
        "#\n",
        "# Train SciKit Models\n",
        "#\n",
        "##########################################\n",
        "\n",
        "print('--ML Model Output--', '\\n')\n",
        "\n",
        "#Test/Train split\n",
        "data_train, data_test, target_train, target_test = train_test_split(data_np, target_np, test_size=0.35)\n",
        "\n",
        "####Classifiers####\n",
        "if binning==1 and cross_val==0:\n",
        "    #SciKit\n",
        "    '''Test/Train split unused in this homework, skip down to CV section'''\n",
        " \n",
        "\n",
        "                                                                                                                         \n",
        " \n",
        "####Cross-Val Classifiers####\n",
        "if binning==1 and cross_val==1:\n",
        "    #Setup Crossval classifier scorers\n",
        "    scorers = {'Accuracy': 'accuracy', 'roc_auc': 'roc_auc'}                                                                                                                \n",
        "    \n",
        "    #SciKit Gradient Boosting - Cross Val\n",
        "    start_ts=time.time()\n",
        "    clf=GradientBoostingClassifier(n_estimators=100, loss='deviance', learning_rate=0.1, max_depth=3, min_samples_split=3, random_state=rand_st)\n",
        "    scores= cross_validate(clf, data_np, target_np, scoring=scorers, cv=5)\n",
        "\n",
        "    scores_Acc = scores['test_Accuracy']                                                                                                                                    \n",
        "    print(\"Gradient Boosting - Random Forest Acc: %0.2f (+/- %0.2f)\" % (scores_Acc.mean(), scores_Acc.std() * 2))                                                                                                    \n",
        "    scores_AUC= scores['test_roc_auc']                                                                     #Only works with binary classes, not multiclass                  \n",
        "    print(\"Gradient Boosting - Random Forest AUC: %0.2f (+/- %0.2f)\" % (scores_AUC.mean(), scores_AUC.std() * 2))                           \n",
        "    print(\"GB - CV Runtime:\", time.time()-start_ts)\n",
        "\n",
        "\n",
        "    #SciKit Ada Boosting - Cross Val\n",
        "    start_ts=time.time()\n",
        "    clf=AdaBoostClassifier(n_estimators=100, base_estimator=None, learning_rate=0.1, random_state=rand_st)\n",
        "    scores= cross_validate(clf, data_np, target_np, scoring=scorers, cv=5)\n",
        "\n",
        "    scores_Acc = scores['test_Accuracy']                                                                                                                                    \n",
        "    print(\"Ada Boost - Random Forest Acc: %0.2f (+/- %0.2f)\" % (scores_Acc.mean(), scores_Acc.std() * 2))                                                                                                    \n",
        "    scores_AUC= scores['test_roc_auc']                                                                     #Only works with binary classes, not multiclass                  \n",
        "    print(\"Ada Boost - Random Forest AUC: %0.2f (+/- %0.2f)\" % (scores_AUC.mean(), scores_AUC.std() * 2))                           \n",
        "    print(\"Ada - CV Runtime:\", time.time()-start_ts)\n",
        "\n",
        "\n",
        "    #SciKit Neural Network - Cross Val\n",
        "    start_ts=time.time()\n",
        "    clf=MLPClassifier(activation='logistic', solver='adam', alpha=0.0001, max_iter=1000, hidden_layer_sizes=(10,), random_state=rand_st)\n",
        "    scores= cross_validate(clf, data_np, target_np, scoring=scorers, cv=5)\n",
        "\n",
        "    scores_Acc = scores['test_Accuracy']                                                                                                                                    \n",
        "    print(\"Neural Network - Acc: %0.2f (+/- %0.2f)\" % (scores_Acc.mean(), scores_Acc.std() * 2))                                                                                                    \n",
        "    scores_AUC= scores['test_roc_auc']                                                                     #Only works with binary classes, not multiclass                  \n",
        "    print(\"Neural Network - AUC: %0.2f (+/- %0.2f)\" % (scores_AUC.mean(), scores_AUC.std() * 2))                           \n",
        "    print(\"NN - CV Runtime:\", time.time()-start_ts) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['HeartDiseaseorAttack', 'HighBP', 'HighChol', 'CholCheck', 'BMI', 'Smoker', 'Stroke', 'Diabetes', 'PhysActivity', 'Fruits', 'Veggies', 'HvyAlcoholConsump', 'AnyHealthcare', 'NoDocbcCost', 'GenHlth', 'MentHlth', 'PhysHlth', 'DiffWalk', 'Sex', 'Age', 'Education', 'Income']\n",
            "71679 71679\n",
            "\n",
            "\n",
            "--FEATURE SELECTION ON-- \n",
            "\n",
            "Wrapper Select: \n",
            "Selected ['HighBP', 'HighChol', 'Stroke', 'GenHlth', 'Sex', 'Age']\n",
            "Features (total/selected): 21 6\n",
            "\n",
            "\n",
            "--ML Model Output-- \n",
            "\n",
            "Gradient Boosting - Random Forest Acc: 0.78 (+/- 0.01)\n",
            "Gradient Boosting - Random Forest AUC: 0.84 (+/- 0.01)\n",
            "GB - CV Runtime: 13.7144935131073\n",
            "Ada Boost - Random Forest Acc: 0.77 (+/- 0.01)\n",
            "Ada Boost - Random Forest AUC: 0.84 (+/- 0.01)\n",
            "Ada - CV Runtime: 13.242541790008545\n",
            "Neural Network - Acc: 0.78 (+/- 0.01)\n",
            "Neural Network - AUC: 0.84 (+/- 0.01)\n",
            "NN - CV Runtime: 21.019581079483032\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpP6dxuS3OFB"
      },
      "source": [
        "## Support Vector Machines - Dataset too Large - Stuck on Execution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a13nw6p94D6a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dde4d03e-ef2d-4a74-ac5a-755c87e19c11"
      },
      "source": [
        "#SciKit DSC540 HW4\n",
        "'''created by Casey Bennett 2018, www.CaseyBennett.com'''\n",
        "\n",
        "import sys\n",
        "import csv\n",
        "import math\n",
        "import numpy as np\n",
        "from operator import itemgetter\n",
        "import time\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.externals import joblib\n",
        "from sklearn.feature_selection import RFE, VarianceThreshold, SelectFromModel\n",
        "from sklearn.feature_selection import SelectKBest, mutual_info_regression, mutual_info_classif, chi2\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import cross_validate, train_test_split\n",
        "from sklearn.preprocessing import KBinsDiscretizer, scale\n",
        "\n",
        "#Handle annoying warnings\n",
        "import warnings, sklearn.exceptions\n",
        "warnings.filterwarnings(\"ignore\", category=sklearn.exceptions.ConvergenceWarning)\n",
        "\n",
        "\n",
        "\n",
        "#############################################################################\n",
        "#\n",
        "# Global parameters\n",
        "#\n",
        "#####################\n",
        "\n",
        "target_idx=0                                        #Index of Target variable\n",
        "cross_val=1                                         #Control Switch for CV                                                                                                                                                      \n",
        "norm_target=0                                       #Normalize target switch\n",
        "norm_features=0                                     #Normalize target switch\n",
        "binning=1                                           #Control Switch for Bin Target\n",
        "bin_cnt=2                                           #If bin target, this sets number of classes\n",
        "feat_select=1                                       #Control Switch for Feature Selection                                                                                   \n",
        "fs_type=2                                           #Feature Selection type (1=Stepwise Backwards Removal, 2=Wrapper Select, 3=Univariate Selection)                        \n",
        "lv_filter=0                                         #Control switch for low variance filter on features\n",
        "feat_start=1                                        #Start column of features\n",
        "k_cnt=5                                             #Number of 'Top k' best ranked features to select, only applies for fs_types 1 and 3\n",
        "\n",
        "#Set global model parameters\n",
        "rand_st=1                                           #Set Random State variable for randomizing splits on runs\n",
        "\n",
        "\n",
        "#############################################################################\n",
        "#\n",
        "# Load Data\n",
        "#\n",
        "#####################\n",
        "\n",
        "file1= csv.reader(open('brfss2015_5050_cleaned.csv'), delimiter=',', quotechar='\"')\n",
        "\n",
        "#Read Header Line\n",
        "header=next(file1)            \n",
        "\n",
        "#Read data\n",
        "data=[]\n",
        "target=[]\n",
        "for row in file1:\n",
        "    #Load Target\n",
        "    if row[target_idx]=='':                         #If target is blank, skip row                       \n",
        "        continue\n",
        "    else:\n",
        "        target.append(float(row[target_idx]))       #If pre-binned class, change float to int\n",
        "\n",
        "    #Load row into temp array, cast columns  \n",
        "    temp=[]\n",
        "                 \n",
        "    for j in range(feat_start,len(header)):\n",
        "        if row[j]=='':\n",
        "            temp.append(float())\n",
        "        else:\n",
        "            temp.append(float(row[j]))\n",
        "\n",
        "    #Load temp into Data array\n",
        "    data.append(temp)\n",
        "  \n",
        "#Test Print\n",
        "print(header)\n",
        "print(len(target),len(data))\n",
        "print('\\n')\n",
        "\n",
        "data_np=np.asarray(data)\n",
        "target_np=np.asarray(target)\n",
        "\n",
        "\n",
        "#############################################################################\n",
        "#\n",
        "# Preprocess data\n",
        "#\n",
        "##########################################\n",
        "\n",
        "if norm_target==1:\n",
        "    #Target normalization for continuous values\n",
        "    target_np=scale(target_np)\n",
        "\n",
        "if norm_features==1:\n",
        "    #Feature normalization for continuous values\n",
        "    data_np=scale(data_np)\n",
        "\n",
        "'''if binning==1:\n",
        "    #Discretize Target variable with KBinsDiscretizer\n",
        "    enc = KBinsDiscretizer(n_bins=[bin_cnt], encode='ordinal', strategy='quantile')                         #Strategy here is important, quantile creating equal bins, but kmeans prob being more valid \"clusters\"\n",
        "    target_np_bin = enc.fit_transform(target_np.reshape(-1,1))\n",
        "\n",
        "    #Get Bin min/max\n",
        "    temp=[[] for x in range(bin_cnt+1)]\n",
        "    for i in range(len(target_np)):\n",
        "        for j in range(bin_cnt):\n",
        "            if target_np_bin[i]==j:\n",
        "                temp[j].append(target_np[i])\n",
        "\n",
        "    for j in range(bin_cnt):\n",
        "        print('Bin', j, ':', min(temp[j]), max(temp[j]), len(temp[j]))\n",
        "    print('\\n')\n",
        "\n",
        "    #Convert Target array back to correct shape\n",
        "    target_np=np.ravel(target_np_bin)'''\n",
        "\n",
        "\n",
        "#############################################################################\n",
        "#\n",
        "# Feature Selection\n",
        "#\n",
        "##########################################\n",
        "\n",
        "#Low Variance Filter\n",
        "if lv_filter==1:\n",
        "    print('--LOW VARIANCE FILTER ON--', '\\n')\n",
        "    \n",
        "    #LV Threshold\n",
        "    sel = VarianceThreshold(threshold=0.5)                                      #Removes any feature with less than 20% variance\n",
        "    fit_mod=sel.fit(data_np)\n",
        "    fitted=sel.transform(data_np)\n",
        "    sel_idx=fit_mod.get_support()\n",
        "\n",
        "    #Get lists of selected and non-selected features (names and indexes)\n",
        "    temp=[]\n",
        "    temp_idx=[]\n",
        "    temp_del=[]\n",
        "    for i in range(len(data_np[0])):\n",
        "        if sel_idx[i]==1:                                                           #Selected Features get added to temp header\n",
        "            temp.append(header[i+feat_start])\n",
        "            temp_idx.append(i)\n",
        "        else:                                                                       #Indexes of non-selected features get added to delete array\n",
        "            temp_del.append(i)\n",
        "\n",
        "    print('Selected', temp)\n",
        "    print('Features (total, selected):', len(data_np[0]), len(temp))\n",
        "    print('\\n')\n",
        "\n",
        "    #Filter selected columns from original dataset\n",
        "    header = header[0:feat_start]\n",
        "    for field in temp:\n",
        "        header.append(field)\n",
        "    data_np = np.delete(data_np, temp_del, axis=1)                                 #Deletes non-selected features by index\n",
        "\n",
        "\n",
        "#Feature Selection\n",
        "if feat_select==1:\n",
        "    '''Three steps:\n",
        "       1) Run Feature Selection\n",
        "       2) Get lists of selected and non-selected features\n",
        "       3) Filter columns from original dataset\n",
        "       '''\n",
        "    \n",
        "    print('--FEATURE SELECTION ON--', '\\n')\n",
        "    \n",
        "    ##1) Run Feature Selection #######\n",
        "    if fs_type==1:\n",
        "        #Stepwise Recursive Backwards Feature removal\n",
        "        if binning==1:\n",
        "            clf = RandomForestClassifier(n_estimators=200, max_depth=None, min_samples_split=3, criterion='entropy', random_state=rand_st)\n",
        "            sel = RFE(clf, n_features_to_select=k_cnt, step=.1)\n",
        "            print('Stepwise Recursive Backwards - Random Forest: ')\n",
        "        if binning==0:\n",
        "            rgr = RandomForestRegressor(n_estimators=500, max_depth=None, min_samples_split=3, criterion='mse', random_state=rand_st)\n",
        "            sel = RFE(rgr, n_features_to_select=k_cnt, step=.1)\n",
        "            print('Stepwise Recursive Backwards - Random Forest: ')\n",
        "            \n",
        "        fit_mod=sel.fit(data_np, target_np)\n",
        "        print(sel.ranking_)\n",
        "        sel_idx=fit_mod.get_support()      \n",
        "\n",
        "    if fs_type==2:\n",
        "        #Wrapper Select via model\n",
        "        if binning==1:\n",
        "            clf = SVC(kernel='linear', gamma='scale', C=1.0, probability=True, random_state=rand_st)\n",
        "            sel = SelectFromModel(clf, prefit=False, threshold='mean', max_features=None)                                                           #to select only based on max_features, set to integer value and set threshold=-np.inf\n",
        "            print ('Wrapper Select: ')\n",
        "        if binning==0:\n",
        "            rgr = '''Unused in this homework'''\n",
        "            sel = SelectFromModel(rgr, prefit=False, threshold='mean', max_features=None)\n",
        "            print ('Wrapper Select: ')\n",
        "            \n",
        "        fit_mod=sel.fit(data_np, target_np)    \n",
        "        sel_idx=fit_mod.get_support()\n",
        "\n",
        "    if fs_type==3:\n",
        "        if binning==1:                                                              ######Only work if the Target is binned###########\n",
        "            #Univariate Feature Selection - Chi-squared\n",
        "            sel=SelectKBest(chi2, k=k_cnt)\n",
        "            fit_mod=sel.fit(data_np, target_np)                                         #will throw error if any negative values in features, so turn off feature normalization, or switch to mutual_info_classif\n",
        "            print ('Univariate Feature Selection - Chi2: ')\n",
        "            sel_idx=fit_mod.get_support()\n",
        "\n",
        "        if binning==0:                                                              ######Only work if the Target is continuous###########\n",
        "            #Univariate Feature Selection - Mutual Info Regression\n",
        "            sel=SelectKBest(mutual_info_regression, k=k_cnt)\n",
        "            fit_mod=sel.fit(data_np, target_np)\n",
        "            print ('Univariate Feature Selection - Mutual Info: ')\n",
        "            sel_idx=fit_mod.get_support()\n",
        "\n",
        "        #Print ranked variables out sorted\n",
        "        temp=[]\n",
        "        scores=fit_mod.scores_\n",
        "        for i in range(feat_start, len(header)):            \n",
        "            temp.append([header[i], float(scores[i-feat_start])])\n",
        "\n",
        "        print('Ranked Features')\n",
        "        temp_sort=sorted(temp, key=itemgetter(1), reverse=True)\n",
        "        for i in range(len(temp_sort)):\n",
        "            print(i, temp_sort[i][0], ':', temp_sort[i][1])\n",
        "        print('\\n')\n",
        "\n",
        "    ##2) Get lists of selected and non-selected features (names and indexes) #######\n",
        "    temp=[]\n",
        "    temp_idx=[]\n",
        "    temp_del=[]\n",
        "    for i in range(len(data_np[0])):\n",
        "        if sel_idx[i]==1:                                                           #Selected Features get added to temp header\n",
        "            temp.append(header[i+feat_start])\n",
        "            temp_idx.append(i)\n",
        "        else:                                                                       #Indexes of non-selected features get added to delete array\n",
        "            temp_del.append(i)\n",
        "    print('Selected', temp)\n",
        "    print('Features (total/selected):', len(data_np[0]), len(temp))\n",
        "    print('\\n')\n",
        "            \n",
        "                \n",
        "    ##3) Filter selected columns from original dataset #########\n",
        "    header = header[0:feat_start]\n",
        "    for field in temp:\n",
        "        header.append(field)\n",
        "    data_np = np.delete(data_np, temp_del, axis=1)                                 #Deletes non-selected features by index)\n",
        "    \n",
        "    \n",
        "\n",
        "#############################################################################\n",
        "#\n",
        "# Train SciKit Models\n",
        "#\n",
        "##########################################\n",
        "\n",
        "print('--ML Model Output--', '\\n')\n",
        "\n",
        "#Test/Train split\n",
        "data_train, data_test, target_train, target_test = train_test_split(data_np, target_np, test_size=0.35)\n",
        "\n",
        "####Classifiers####\n",
        "if binning==1 and cross_val==0:\n",
        "    #SciKit\n",
        "    '''Test/Train split unused in this homework, skip down to CV section'''\n",
        " \n",
        "\n",
        "                                                                                                                         \n",
        " \n",
        "####Cross-Val Classifiers####\n",
        "if binning==1 and cross_val==1:\n",
        "    #Setup Crossval classifier scorers\n",
        "    scorers = {'Accuracy': 'accuracy', 'roc_auc': 'roc_auc'}                                                                                                                \n",
        "    \n",
        "    #SciKit RBF - SVM - Cross Val\n",
        "#    start_ts=time.time()\n",
        "#    clf=SVC(kernel='rbf', gamma='scale', C=1.0, probability=True, random_state=rand_st)\n",
        "#    scores=cross_validate(clf, data_np, target_np, scoring=scorers, cv=5)\n",
        "\n",
        "#    scores_Acc = scores['test_Accuracy']                                                                                                                                    \n",
        "#    print(\"RBF-SVM Acc: %0.2f (+/- %0.2f)\" % (scores_Acc.mean(), scores_Acc.std() * 2))                                                                                                    \n",
        "#    scores_AUC= scores['test_roc_auc']                                                                     #Only works with binary classes, not multiclass                  \n",
        "#    print(\"RBF-SVM AUC: %0.2f (+/- %0.2f)\" % (scores_AUC.mean(), scores_AUC.std() * 2))                           \n",
        "#    print(\"RBF-SVM CV Runtime:\", time.time()-start_ts)\n",
        "\n",
        "    #SciKit Linear - SVM - Cross Val\n",
        "    start_ts=time.time()\n",
        "    clf=SVC(kernel='linear', gamma='scale', C=1.0, probability=True, random_state=rand_st)\n",
        "    scores=cross_validate(clf, data_np, target_np, scoring=scorers, cv=5)\n",
        "\n",
        "    scores_Acc = scores['test_Accuracy']                                                                                                                                    \n",
        "    print(\"Linear-SVM Acc: %0.2f (+/- %0.2f)\" % (scores_Acc.mean(), scores_Acc.std() * 2))                                                                                                    \n",
        "    scores_AUC= scores['test_roc_auc']                                                                     #Only works with binary classes, not multiclass                  \n",
        "    print(\"Linear-SVM AUC: %0.2f (+/- %0.2f)\" % (scores_AUC.mean(), scores_AUC.std() * 2))                           \n",
        "    print(\"Linear-CV Runtime:\", time.time()-start_ts)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['HeartDiseaseorAttack', 'HighBP', 'HighChol', 'CholCheck', 'BMI', 'Smoker', 'Stroke', 'Diabetes', 'PhysActivity', 'Fruits', 'Veggies', 'HvyAlcoholConsump', 'AnyHealthcare', 'NoDocbcCost', 'GenHlth', 'MentHlth', 'PhysHlth', 'DiffWalk', 'Sex', 'Age', 'Education', 'Income']\n",
            "47786 47786\n",
            "\n",
            "\n",
            "--FEATURE SELECTION ON-- \n",
            "\n",
            "Wrapper Select: \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmHg-K0g87it"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}