{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S8sZ5WL2bmW8"
   },
   "source": [
    "#Final Project\n",
    "#DSC 540: Advanced Machine Learning\n",
    "**Author**: Alex Teboul\n",
    "\n",
    "**Professor**: Casey Bennett\n",
    "\n",
    "**Data Source**: https://www.kaggle.com/cdc/behavioral-risk-factor-surveillance-system#2015.csv\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c72z2O41f6wh"
   },
   "source": [
    "## About this Project\n",
    "\n",
    "**Objective:** The goal of this project was to build predicitve models for coronary heart disease using the 2015 BRFSS dataset. This project follows the processes and algorithms explored in DePaul University graduate course DSC 540: Advanced Machine Learning with professor Casey Bennett. In this Google Colab notebook, I go through the process of getting the 2015 BRFSS dataset, selecting features for exploration in my predictive models based irisk factors identified in past heart disease research, exploratory data analysis, model testing, and reporting on results. Methods explored in this notebook are: Random Forests, Gradient Boosting, AdaBoost, and Neural Networks.\n",
    "\n",
    "\n",
    "1.   **Part 1:** Getting and Cleaning the Data\n",
    "*   Get the BRFSS dataset from my local google drive\n",
    "*   Select a Relevant Subset of Features\n",
    "*   Cleaning the Data (Missing Values, Modifying Values, Make Feature Names More Readable, Save Finalized Dataset to CSV)\n",
    "2.   **Part 2:** Model Building\n",
    "\n",
    "Random Forests\n",
    "*   Random Forest - w/ Feature Selection - Full Dataset\n",
    "*   Random Forest - w/o Feature Selection - Full Dataset\n",
    "*   Random Forest - w/ and w/o Feature Selection - 50-50 Balanced Dataset\n",
    "*   Random Forest - w/ Feature Selection - 60-40 Balanced Dataset\n",
    "\n",
    "AdaBoost, GradientBoost, and Neural Networks\n",
    "*   AdaBoost, GradientBoost, and Neural Network - w/o Feature Selection - Full Dataset\n",
    "*   AdaBoost, GradientBoost, and Neural Network - w/ Feature Selection - Full Dataset\n",
    "*   AdaBoost, GradientBoost, and Neural Network - w/ Feature Selection - 50-50 Dataset\n",
    "*   AdaBoost, GradientBoost, and Neural Network - w/ Feature Selection - 60-40 Dataset\n",
    "\n",
    "Support Vector Machines: *Too Slow - Never Finishes\n",
    "*   RBF-SVM - w/ Feature Selection 50-50 Dataset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X7VcNFOPgClc"
   },
   "source": [
    "#Part 1: Getting and Cleaning the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "EcigkoPhfb7Z"
   },
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ttwQ5OG4e1yg"
   },
   "source": [
    "###Get the BRFSS dataset from my local google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "0Od7T6A_eX04",
    "outputId": "57db021a-102f-47f7-bd72-ca5f270f8b55"
   },
   "outputs": [],
   "source": [
    "#connect to my local google drive\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "3dxD5-vBe9c_"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tugcekonuklar/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3049: DtypeWarning: Columns (183,378) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#read in the dataset\n",
    "brfss_2015_dataset_source = 'brfss_for_bda_2021.csv'\n",
    "brfss_2015_dataset = pd.read_csv(brfss_2015_dataset_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "avOmAS86gj-E",
    "outputId": "4c74328f-bee8-4ad5-bce6-21a45aab1724"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12338, 414)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check that all the data loaded in\n",
    "brfss_2015_dataset.shape\n",
    "\n",
    "#Start with 444,456 records and 330 features. Each record is an individual's responses to the survey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "id": "oe_IWsqnhRjC",
    "outputId": "ed00e572-26b5-49e0-e111-b86ca083d4d2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_STATE</th>\n",
       "      <th>_GEOSTR</th>\n",
       "      <th>_DENSTR2</th>\n",
       "      <th>PRECALL</th>\n",
       "      <th>SECSCRFL</th>\n",
       "      <th>REPNUM</th>\n",
       "      <th>REPDEPTH</th>\n",
       "      <th>FMONTH</th>\n",
       "      <th>IDATE</th>\n",
       "      <th>IMONTH</th>\n",
       "      <th>IDAY</th>\n",
       "      <th>IYEAR</th>\n",
       "      <th>DISPCODE</th>\n",
       "      <th>SEQNO</th>\n",
       "      <th>_PSU</th>\n",
       "      <th>NATTMPTS</th>\n",
       "      <th>NRECSEL</th>\n",
       "      <th>NRECSTR</th>\n",
       "      <th>PVTRESD1</th>\n",
       "      <th>COLGHOUS</th>\n",
       "      <th>STATERES</th>\n",
       "      <th>CELLFON3</th>\n",
       "      <th>LADULT</th>\n",
       "      <th>NUMADULT</th>\n",
       "      <th>CADULT</th>\n",
       "      <th>CCLGHOUS</th>\n",
       "      <th>CSTATE</th>\n",
       "      <th>RSPSTATE</th>\n",
       "      <th>LANDLINE</th>\n",
       "      <th>HHADULT</th>\n",
       "      <th>GENHLTH</th>\n",
       "      <th>PHYSHLTH</th>\n",
       "      <th>MENTHLTH</th>\n",
       "      <th>POORHLTH</th>\n",
       "      <th>HLTHPLN1</th>\n",
       "      <th>PERSDOC2</th>\n",
       "      <th>MEDCOST</th>\n",
       "      <th>CHECKUP1</th>\n",
       "      <th>BPHIGH4</th>\n",
       "      <th>BPMEDS</th>\n",
       "      <th>BLOODCHO</th>\n",
       "      <th>CHOLCHK</th>\n",
       "      <th>TOLDHI2</th>\n",
       "      <th>CVDINFR4</th>\n",
       "      <th>CVDCRHD4</th>\n",
       "      <th>CVDSTRK3</th>\n",
       "      <th>ASTHMA3</th>\n",
       "      <th>ASTHNOW</th>\n",
       "      <th>CHCSCNCR</th>\n",
       "      <th>CHCOCNCR</th>\n",
       "      <th>CHCCOPD1</th>\n",
       "      <th>HAVARTH3</th>\n",
       "      <th>ADDEPEV2</th>\n",
       "      <th>CHCKIDNY</th>\n",
       "      <th>DIABETE3</th>\n",
       "      <th>DIABAGE2</th>\n",
       "      <th>SEX</th>\n",
       "      <th>AGE</th>\n",
       "      <th>HISPANC3</th>\n",
       "      <th>MRACE1</th>\n",
       "      <th>ORACE3</th>\n",
       "      <th>MARITAL</th>\n",
       "      <th>EDUCA</th>\n",
       "      <th>RENTHOM1</th>\n",
       "      <th>CTYCODE1</th>\n",
       "      <th>ZIPCODE</th>\n",
       "      <th>NUMHHOL2</th>\n",
       "      <th>NUMPHON2</th>\n",
       "      <th>CPDEMO1</th>\n",
       "      <th>VETERAN3</th>\n",
       "      <th>EMPLOY1</th>\n",
       "      <th>CHILDREN</th>\n",
       "      <th>INCOME2</th>\n",
       "      <th>INTERNET</th>\n",
       "      <th>WEIGHT2</th>\n",
       "      <th>HEIGHT3</th>\n",
       "      <th>PREGNANT</th>\n",
       "      <th>QLACTLM2</th>\n",
       "      <th>USEEQUIP</th>\n",
       "      <th>BLIND</th>\n",
       "      <th>DECIDE</th>\n",
       "      <th>DIFFWALK</th>\n",
       "      <th>DIFFDRES</th>\n",
       "      <th>DIFFALON</th>\n",
       "      <th>SMOKE100</th>\n",
       "      <th>SMOKDAY2</th>\n",
       "      <th>STOPSMK2</th>\n",
       "      <th>LASTSMK2</th>\n",
       "      <th>USENOW3</th>\n",
       "      <th>ALCDAY5</th>\n",
       "      <th>AVEDRNK2</th>\n",
       "      <th>DRNK3GE5</th>\n",
       "      <th>MAXDRNKS</th>\n",
       "      <th>FRUITJU1</th>\n",
       "      <th>FRUIT1</th>\n",
       "      <th>FVBEANS</th>\n",
       "      <th>FVGREEN</th>\n",
       "      <th>FVORANG</th>\n",
       "      <th>VEGETAB1</th>\n",
       "      <th>EXERANY2</th>\n",
       "      <th>EXRACT11</th>\n",
       "      <th>EXEROFT1</th>\n",
       "      <th>EXERHMM1</th>\n",
       "      <th>EXRACT21</th>\n",
       "      <th>EXEROFT2</th>\n",
       "      <th>EXERHMM2</th>\n",
       "      <th>STRENGTH</th>\n",
       "      <th>LMTJOIN3</th>\n",
       "      <th>ARTHDIS2</th>\n",
       "      <th>ARTHSOCL</th>\n",
       "      <th>JOINPAIN</th>\n",
       "      <th>SEATBELT</th>\n",
       "      <th>FLUSHOT6</th>\n",
       "      <th>FLSHTMY2</th>\n",
       "      <th>IMFVPLAC</th>\n",
       "      <th>PNEUVAC3</th>\n",
       "      <th>HIVTST6</th>\n",
       "      <th>HIVTSTD3</th>\n",
       "      <th>WHRTST10</th>\n",
       "      <th>PDIABTST</th>\n",
       "      <th>PREDIAB1</th>\n",
       "      <th>INSULIN</th>\n",
       "      <th>BLDSUGAR</th>\n",
       "      <th>FEETCHK2</th>\n",
       "      <th>DOCTDIAB</th>\n",
       "      <th>CHKHEMO3</th>\n",
       "      <th>FEETCHK</th>\n",
       "      <th>EYEEXAM</th>\n",
       "      <th>DIABEYE</th>\n",
       "      <th>DIABEDU</th>\n",
       "      <th>CAREGIV1</th>\n",
       "      <th>CRGVREL1</th>\n",
       "      <th>CRGVLNG1</th>\n",
       "      <th>CRGVHRS1</th>\n",
       "      <th>CRGVPRB1</th>\n",
       "      <th>CRGVPERS</th>\n",
       "      <th>CRGVHOUS</th>\n",
       "      <th>CRGVMST2</th>\n",
       "      <th>CRGVEXPT</th>\n",
       "      <th>CIMEMLOS</th>\n",
       "      <th>CDHOUSE</th>\n",
       "      <th>CDASSIST</th>\n",
       "      <th>CDHELP</th>\n",
       "      <th>CDSOCIAL</th>\n",
       "      <th>CDDISCUS</th>\n",
       "      <th>ARTTODAY</th>\n",
       "      <th>ARTHWGT</th>\n",
       "      <th>ARTHEXER</th>\n",
       "      <th>ARTHEDU</th>\n",
       "      <th>BLDSTOOL</th>\n",
       "      <th>LSTBLDS3</th>\n",
       "      <th>HADSIGM3</th>\n",
       "      <th>HADSGCO1</th>\n",
       "      <th>LASTSIG3</th>\n",
       "      <th>TYPEWORK</th>\n",
       "      <th>TYPEINDS</th>\n",
       "      <th>SXORIENT</th>\n",
       "      <th>TRNSGNDR</th>\n",
       "      <th>RCSBIRTH</th>\n",
       "      <th>RCSGENDR</th>\n",
       "      <th>RCHISLA1</th>\n",
       "      <th>RCSRACE1</th>\n",
       "      <th>RCSBRAC2</th>\n",
       "      <th>RCSRLTN2</th>\n",
       "      <th>CASTHDX2</th>\n",
       "      <th>CASTHNO2</th>\n",
       "      <th>ADHISPA</th>\n",
       "      <th>CHHISPA</th>\n",
       "      <th>QSTVER</th>\n",
       "      <th>QSTLANG</th>\n",
       "      <th>EXACTOT1</th>\n",
       "      <th>EXACTOT2</th>\n",
       "      <th>_MSACODE</th>\n",
       "      <th>MSCODE</th>\n",
       "      <th>_STSTR</th>\n",
       "      <th>_STRWT</th>\n",
       "      <th>_RAW</th>\n",
       "      <th>_WT2</th>\n",
       "      <th>_RAWRAKE</th>\n",
       "      <th>_WT2RAKE</th>\n",
       "      <th>_REGION</th>\n",
       "      <th>_IMPAGE</th>\n",
       "      <th>_IMPRACE</th>\n",
       "      <th>_IMPNPH</th>\n",
       "      <th>_IMPEDUC</th>\n",
       "      <th>_IMPMRTL</th>\n",
       "      <th>_IMPHOME</th>\n",
       "      <th>O_STATE</th>\n",
       "      <th>_CHISPNC</th>\n",
       "      <th>_CRACE1</th>\n",
       "      <th>_CPRACE</th>\n",
       "      <th>_IMPCAGE</th>\n",
       "      <th>_IMPCRAC</th>\n",
       "      <th>_IMPCSEX</th>\n",
       "      <th>_RAWCH</th>\n",
       "      <th>_WT2CH</th>\n",
       "      <th>_CLCM1V1</th>\n",
       "      <th>_CLCM2V1</th>\n",
       "      <th>_CLCM3V1</th>\n",
       "      <th>_CLCM4V1</th>\n",
       "      <th>_CLCM5V1</th>\n",
       "      <th>_CLCWTV1</th>\n",
       "      <th>_DUALUSE</th>\n",
       "      <th>_DUALCOR</th>\n",
       "      <th>_LLCPM01</th>\n",
       "      <th>_LLCPM02</th>\n",
       "      <th>_LLCPM03</th>\n",
       "      <th>_LLCPM04</th>\n",
       "      <th>_LLCPM05</th>\n",
       "      <th>_LLCPM06</th>\n",
       "      <th>_LLCPM07</th>\n",
       "      <th>_LLCPM08</th>\n",
       "      <th>_LLCPM09</th>\n",
       "      <th>_LLCPM10</th>\n",
       "      <th>_LLCPM11</th>\n",
       "      <th>_LLCPM12</th>\n",
       "      <th>_LLCPM13</th>\n",
       "      <th>_LLCPM14</th>\n",
       "      <th>_LLCPM15</th>\n",
       "      <th>_LLCPM16</th>\n",
       "      <th>_LLCPWT</th>\n",
       "      <th>_LCM01V1</th>\n",
       "      <th>_LCM02V1</th>\n",
       "      <th>_LCM03V1</th>\n",
       "      <th>_LCM04V1</th>\n",
       "      <th>_LCM05V1</th>\n",
       "      <th>_LCM06V1</th>\n",
       "      <th>_LCM07V1</th>\n",
       "      <th>_LCM08V1</th>\n",
       "      <th>_LCPWTV1</th>\n",
       "      <th>_LCM01V2</th>\n",
       "      <th>_LCM02V2</th>\n",
       "      <th>_LCM03V2</th>\n",
       "      <th>_LCM04V2</th>\n",
       "      <th>_LCM05V2</th>\n",
       "      <th>_LCM06V2</th>\n",
       "      <th>_LCM07V2</th>\n",
       "      <th>_LCM08V2</th>\n",
       "      <th>_LCM09V2</th>\n",
       "      <th>_LCM10V2</th>\n",
       "      <th>_LCM11V2</th>\n",
       "      <th>_LCM12V2</th>\n",
       "      <th>_LCPWTV2</th>\n",
       "      <th>_RFHLTH</th>\n",
       "      <th>_HCVU651</th>\n",
       "      <th>_RFHYPE5</th>\n",
       "      <th>_CHOLCHK</th>\n",
       "      <th>_RFCHOL</th>\n",
       "      <th>_MICHD</th>\n",
       "      <th>_LTASTH1</th>\n",
       "      <th>_CASTHM1</th>\n",
       "      <th>_ASTHMS1</th>\n",
       "      <th>_DRDXAR1</th>\n",
       "      <th>_MRACE1</th>\n",
       "      <th>_M_RACE</th>\n",
       "      <th>_HISPANC</th>\n",
       "      <th>_RACE</th>\n",
       "      <th>_RACEG21</th>\n",
       "      <th>_RACEGR3</th>\n",
       "      <th>_RACE_G1</th>\n",
       "      <th>_AGEG5YR</th>\n",
       "      <th>_AGE65YR</th>\n",
       "      <th>_AGE80</th>\n",
       "      <th>_AGE_G</th>\n",
       "      <th>HTIN4</th>\n",
       "      <th>HTM4</th>\n",
       "      <th>WTKG3</th>\n",
       "      <th>_BMI5</th>\n",
       "      <th>_BMI5CAT</th>\n",
       "      <th>_RFBMI5</th>\n",
       "      <th>_CHLDCNT</th>\n",
       "      <th>_EDUCAG</th>\n",
       "      <th>_INCOMG</th>\n",
       "      <th>_SMOKER3</th>\n",
       "      <th>_RFSMOK3</th>\n",
       "      <th>DRNKANY5</th>\n",
       "      <th>DROCDY3_</th>\n",
       "      <th>_RFBING5</th>\n",
       "      <th>_DRNKWEK</th>\n",
       "      <th>_RFDRHV5</th>\n",
       "      <th>FTJUDA1_</th>\n",
       "      <th>FRUTDA1_</th>\n",
       "      <th>BEANDAY_</th>\n",
       "      <th>GRENDAY_</th>\n",
       "      <th>ORNGDAY_</th>\n",
       "      <th>VEGEDA1_</th>\n",
       "      <th>_MISFRTN</th>\n",
       "      <th>_MISVEGN</th>\n",
       "      <th>_FRTRESP</th>\n",
       "      <th>_VEGRESP</th>\n",
       "      <th>_FRUTSUM</th>\n",
       "      <th>_VEGESUM</th>\n",
       "      <th>_FRTLT1</th>\n",
       "      <th>_VEGLT1</th>\n",
       "      <th>_FRT16</th>\n",
       "      <th>_VEG23</th>\n",
       "      <th>_FRUITEX</th>\n",
       "      <th>_VEGETEX</th>\n",
       "      <th>_TOTINDA</th>\n",
       "      <th>METVL11_</th>\n",
       "      <th>METVL21_</th>\n",
       "      <th>MAXVO2_</th>\n",
       "      <th>FC60_</th>\n",
       "      <th>ACTIN11_</th>\n",
       "      <th>ACTIN21_</th>\n",
       "      <th>PADUR1_</th>\n",
       "      <th>PADUR2_</th>\n",
       "      <th>PAFREQ1_</th>\n",
       "      <th>PAFREQ2_</th>\n",
       "      <th>_MINAC11</th>\n",
       "      <th>_MINAC21</th>\n",
       "      <th>STRFREQ_</th>\n",
       "      <th>PAMISS1_</th>\n",
       "      <th>PAMIN11_</th>\n",
       "      <th>PAMIN21_</th>\n",
       "      <th>PA1MIN_</th>\n",
       "      <th>PAVIG11_</th>\n",
       "      <th>PAVIG21_</th>\n",
       "      <th>PA1VIGM_</th>\n",
       "      <th>_PACAT1</th>\n",
       "      <th>_PAINDX1</th>\n",
       "      <th>_PA150R2</th>\n",
       "      <th>_PA300R2</th>\n",
       "      <th>_PA30021</th>\n",
       "      <th>_PASTRNG</th>\n",
       "      <th>_PAREC1</th>\n",
       "      <th>_PASTAE1</th>\n",
       "      <th>_LMTACT1</th>\n",
       "      <th>_LMTWRK1</th>\n",
       "      <th>_LMTSCL1</th>\n",
       "      <th>_RFSEAT2</th>\n",
       "      <th>_RFSEAT3</th>\n",
       "      <th>_FLSHOT6</th>\n",
       "      <th>_PNEUMO2</th>\n",
       "      <th>_AIDTST3</th>\n",
       "      <th>MEDICARE</th>\n",
       "      <th>HLTHCVR1</th>\n",
       "      <th>DELAYMED</th>\n",
       "      <th>NOCOV121</th>\n",
       "      <th>LSTCOVRG</th>\n",
       "      <th>DRVISITS</th>\n",
       "      <th>MEDSCOST</th>\n",
       "      <th>CARERCVD</th>\n",
       "      <th>MEDBILL1</th>\n",
       "      <th>EMPLSTYR</th>\n",
       "      <th>JOBINJMT</th>\n",
       "      <th>DAYSRTRN</th>\n",
       "      <th>WHOPAIDT</th>\n",
       "      <th>OTHRPAID</th>\n",
       "      <th>EMPAWARE</th>\n",
       "      <th>MISNERVS</th>\n",
       "      <th>MISHOPLS</th>\n",
       "      <th>MISRSTLS</th>\n",
       "      <th>MISDEPRD</th>\n",
       "      <th>MISEFFRT</th>\n",
       "      <th>MISWTLES</th>\n",
       "      <th>MISNOWRK</th>\n",
       "      <th>MISTMNT</th>\n",
       "      <th>MISTRHLP</th>\n",
       "      <th>MISPHLPF</th>\n",
       "      <th>SSBSUGR1</th>\n",
       "      <th>SSBFRUT2</th>\n",
       "      <th>HCVHEAR</th>\n",
       "      <th>HCVTEST</th>\n",
       "      <th>HCVLASTT</th>\n",
       "      <th>HCVINPTR</th>\n",
       "      <th>HCVINPTO</th>\n",
       "      <th>HCVINPTA</th>\n",
       "      <th>HCVPRIMR</th>\n",
       "      <th>HCVPRIMO</th>\n",
       "      <th>HCVPRIMA</th>\n",
       "      <th>HEALTHCL1</th>\n",
       "      <th>LIFECHG</th>\n",
       "      <th>LASTDENT1</th>\n",
       "      <th>RMVTEETH1</th>\n",
       "      <th>DIFFHEAR</th>\n",
       "      <th>FRUITVEG</th>\n",
       "      <th>NOVEGFRU</th>\n",
       "      <th>NOVFOTHR</th>\n",
       "      <th>STRSRENT</th>\n",
       "      <th>STRSMEAL</th>\n",
       "      <th>dsripreg</th>\n",
       "      <th>REGION</th>\n",
       "      <th>PPS_1</th>\n",
       "      <th>PPS_3</th>\n",
       "      <th>PPS_8</th>\n",
       "      <th>PPS_9</th>\n",
       "      <th>PPS_14</th>\n",
       "      <th>PPS_16</th>\n",
       "      <th>PPS_19</th>\n",
       "      <th>PPS_20</th>\n",
       "      <th>PPS_21</th>\n",
       "      <th>PPS_22</th>\n",
       "      <th>PPS_23</th>\n",
       "      <th>PPS_25</th>\n",
       "      <th>PPS_27</th>\n",
       "      <th>PPS_32</th>\n",
       "      <th>PPS_33</th>\n",
       "      <th>PPS_34</th>\n",
       "      <th>PPS_36</th>\n",
       "      <th>PPS_39</th>\n",
       "      <th>PPS_40</th>\n",
       "      <th>PPS_43</th>\n",
       "      <th>PPS_44</th>\n",
       "      <th>PPS_45</th>\n",
       "      <th>PPS_46</th>\n",
       "      <th>PPS_48</th>\n",
       "      <th>PPS_52</th>\n",
       "      <th>childage</th>\n",
       "      <th>cracorg1</th>\n",
       "      <th>_prace1</th>\n",
       "      <th>mracasc1</th>\n",
       "      <th>_impcty</th>\n",
       "      <th>mracorg1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New York</td>\n",
       "      <td>207</td>\n",
       "      <td>D</td>\n",
       "      <td>To be called</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40187</td>\n",
       "      <td>5</td>\n",
       "      <td>April</td>\n",
       "      <td>4092015</td>\n",
       "      <td>April</td>\n",
       "      <td>9</td>\n",
       "      <td>2015</td>\n",
       "      <td>1200</td>\n",
       "      <td>2015000012</td>\n",
       "      <td>2015000012</td>\n",
       "      <td>1</td>\n",
       "      <td>24887</td>\n",
       "      <td>1.346955e+07</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Missing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Missing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes, Male Respondent</td>\n",
       "      <td>Missing</td>\n",
       "      <td>No</td>\n",
       "      <td>New York</td>\n",
       "      <td>No</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Very good</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Within past 2 years (1 year but less than 2 ye...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Within the past 5 years (2 years but less than...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Male</td>\n",
       "      <td>Age 25 - 34</td>\n",
       "      <td>Data do not meet the criteria for statistical ...</td>\n",
       "      <td>Data do not meet the criteria for statistical ...</td>\n",
       "      <td>D</td>\n",
       "      <td>Never married</td>\n",
       "      <td>College 4 years or more (College graduate)</td>\n",
       "      <td>Rent</td>\n",
       "      <td>D</td>\n",
       "      <td>Data do not meet the criteria for statistical ...</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Employed for wages</td>\n",
       "      <td>None</td>\n",
       "      <td>$75,000 or more</td>\n",
       "      <td>Yes</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not at all</td>\n",
       "      <td>Days per week</td>\n",
       "      <td>Number of drinks</td>\n",
       "      <td>Number of Times</td>\n",
       "      <td>Number of drinks</td>\n",
       "      <td>Times per week</td>\n",
       "      <td>Times per week</td>\n",
       "      <td>Times per month</td>\n",
       "      <td>Times per month</td>\n",
       "      <td>Times per month</td>\n",
       "      <td>Times per week</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Running</td>\n",
       "      <td>Times per week</td>\n",
       "      <td>Hours and Minutes</td>\n",
       "      <td>Bicycling machine exercise</td>\n",
       "      <td>Times per month</td>\n",
       "      <td>Hours and Minutes</td>\n",
       "      <td>Times per week</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Nearly always</td>\n",
       "      <td>No</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Don't know/Not sure</td>\n",
       "      <td>Clinic</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Data do not meet the criteria for statistical ...</td>\n",
       "      <td>Data do not meet the criteria for statistical ...</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>D</td>\n",
       "      <td>Data do not meet the criteria for statistical ...</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Data do not meet the criteria for statistical ...</td>\n",
       "      <td>Data do not meet the criteria for statistical ...</td>\n",
       "      <td>D</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>Core only cellphone (collected out of state)</td>\n",
       "      <td>English</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data do not meet the criteria for statistical ...</td>\n",
       "      <td>D</td>\n",
       "      <td>362079</td>\n",
       "      <td>541.228186</td>\n",
       "      <td>NaN</td>\n",
       "      <td>541.228186</td>\n",
       "      <td>1.0</td>\n",
       "      <td>541.228186</td>\n",
       "      <td>7</td>\n",
       "      <td>Age 25 to 34</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>College 4 years or more (College graduate)</td>\n",
       "      <td>Never married</td>\n",
       "      <td>Rent</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>Missing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No Dual Phone Use</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>42</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>33</td>\n",
       "      <td>11</td>\n",
       "      <td>2117.541967</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Good or Better Health</td>\n",
       "      <td>Have health care coverage</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Had cholesterol checked in past 5 years</td>\n",
       "      <td>No</td>\n",
       "      <td>Did not report having MI or CHD</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Never</td>\n",
       "      <td>Not diagnosed with arthritis</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>Age 30 to 34</td>\n",
       "      <td>Age 18 to 64</td>\n",
       "      <td>Imputed Age 30 to 34</td>\n",
       "      <td>Age 25 to 34</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>1 or greater</td>\n",
       "      <td>Normal Weight</td>\n",
       "      <td>No</td>\n",
       "      <td>No children in household</td>\n",
       "      <td>Graduated from College or Technical School</td>\n",
       "      <td>$50,000 or more</td>\n",
       "      <td>Never smoked</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Drink-Occasions per day</td>\n",
       "      <td>Yes</td>\n",
       "      <td>600</td>\n",
       "      <td>1</td>\n",
       "      <td>29.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>No missing fruit responses</td>\n",
       "      <td>No missing vegetable responses</td>\n",
       "      <td>Included - Not Missing Fruit Responses</td>\n",
       "      <td>Included - Not Missing Vegetable Responses</td>\n",
       "      <td>58.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>Consumed fruit less than one time per day</td>\n",
       "      <td>Consumed vegetables one or more times per day</td>\n",
       "      <td>Included - Values are in accepted range</td>\n",
       "      <td>Included - Values are in accepted range</td>\n",
       "      <td>No missing values and in accepted range</td>\n",
       "      <td>No missing values and in accepted range</td>\n",
       "      <td>Had physical activity or exercise</td>\n",
       "      <td>60.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>4130</td>\n",
       "      <td>708</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>467.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Insufficiently Active</td>\n",
       "      <td>Did Not Meet Aerobic Recommendations</td>\n",
       "      <td>1-149 minutes  (or vigorous equivalent minutes...</td>\n",
       "      <td>1-300 minutes  (or vigorous equivalent minutes...</td>\n",
       "      <td>0-300 minutes  (or vigorous equivalent minutes...</td>\n",
       "      <td>Did not meet muscle strengthening recommendations</td>\n",
       "      <td>Did not meet Either Guideline</td>\n",
       "      <td>Did Not Meet Both Guidelines</td>\n",
       "      <td>Not told they have arthritis</td>\n",
       "      <td>Not told they have arthritis</td>\n",
       "      <td>Not told they have arthritis</td>\n",
       "      <td>Always or Almost Always Wear Seat Belt</td>\n",
       "      <td>Don't Always Wear Seat Belt</td>\n",
       "      <td>Age Less Than 65</td>\n",
       "      <td>Age Less Than 65</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>New York City</td>\n",
       "      <td>New York City (NYC)</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>D</td>\n",
       "      <td>Data do not meet the criteria for statistical ...</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>Data do not meet the criteria for statistical ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>New York</td>\n",
       "      <td>207</td>\n",
       "      <td>D</td>\n",
       "      <td>To be called</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60025</td>\n",
       "      <td>21</td>\n",
       "      <td>June</td>\n",
       "      <td>6232015</td>\n",
       "      <td>June</td>\n",
       "      <td>23</td>\n",
       "      <td>2015</td>\n",
       "      <td>1200</td>\n",
       "      <td>2015000013</td>\n",
       "      <td>2015000013</td>\n",
       "      <td>4</td>\n",
       "      <td>24887</td>\n",
       "      <td>1.346955e+07</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Missing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Missing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes, Female Respondent</td>\n",
       "      <td>Missing</td>\n",
       "      <td>No</td>\n",
       "      <td>New York</td>\n",
       "      <td>No</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Good</td>\n",
       "      <td>None</td>\n",
       "      <td>Number of days</td>\n",
       "      <td>None</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes, only one</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Within past year (anytime less than 12 months ...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Within the past year (anytime less than 12 mon...</td>\n",
       "      <td>No</td>\n",
       "      <td>Don't know/Not sure</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Female</td>\n",
       "      <td>Age 45 - 54</td>\n",
       "      <td>Data do not meet the criteria for statistical ...</td>\n",
       "      <td>Data do not meet the criteria for statistical ...</td>\n",
       "      <td>D</td>\n",
       "      <td>Separated</td>\n",
       "      <td>College 1 year to 3 years (Some college or tec...</td>\n",
       "      <td>Other arrangement</td>\n",
       "      <td>D</td>\n",
       "      <td>Data do not meet the criteria for statistical ...</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>No</td>\n",
       "      <td>Employed for wages</td>\n",
       "      <td>Number of children</td>\n",
       "      <td>Don't know/Not sure</td>\n",
       "      <td>Yes</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not at all</td>\n",
       "      <td>No drinks in past 30 days</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Times per month</td>\n",
       "      <td>Times per month</td>\n",
       "      <td>Times per month</td>\n",
       "      <td>Times per month</td>\n",
       "      <td>Times per month</td>\n",
       "      <td>Times per month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Running</td>\n",
       "      <td>Times per month</td>\n",
       "      <td>Don't know/Not sure</td>\n",
       "      <td>Walking</td>\n",
       "      <td>Times per month</td>\n",
       "      <td>Don't know/Not sure</td>\n",
       "      <td>Times per month</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Always</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Month / Year</td>\n",
       "      <td>A hospital (Example: inpatient)</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Don't know/Not sure</td>\n",
       "      <td>Clinic</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Data do not meet the criteria for statistical ...</td>\n",
       "      <td>Data do not meet the criteria for statistical ...</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>D</td>\n",
       "      <td>Data do not meet the criteria for statistical ...</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Data do not meet the criteria for statistical ...</td>\n",
       "      <td>Data do not meet the criteria for statistical ...</td>\n",
       "      <td>D</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>Core only cellphone (collected out of state)</td>\n",
       "      <td>English</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data do not meet the criteria for statistical ...</td>\n",
       "      <td>D</td>\n",
       "      <td>362079</td>\n",
       "      <td>541.228186</td>\n",
       "      <td>NaN</td>\n",
       "      <td>541.228186</td>\n",
       "      <td>1.0</td>\n",
       "      <td>541.228186</td>\n",
       "      <td>7</td>\n",
       "      <td>Age 45 to 54</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>College 1 year to 3 years (Some college or tec...</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Other arrangement</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>Missing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No Dual Phone Use</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>44</td>\n",
       "      <td>14</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>35</td>\n",
       "      <td>12</td>\n",
       "      <td>2230.075513</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Good or Better Health</td>\n",
       "      <td>Have health care coverage</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Had cholesterol checked in past 5 years</td>\n",
       "      <td>No</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Never</td>\n",
       "      <td>Not diagnosed with arthritis</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>Age 45 to 49</td>\n",
       "      <td>Age 18 to 64</td>\n",
       "      <td>Imputed Age 45 to 49</td>\n",
       "      <td>Age 45 to 54</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>1 or greater</td>\n",
       "      <td>Obese</td>\n",
       "      <td>Yes</td>\n",
       "      <td>One child in household</td>\n",
       "      <td>Attended College or Technical School</td>\n",
       "      <td>Don't know/Not sure/Missing</td>\n",
       "      <td>Never smoked</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No Drink-Occasions per day</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>No missing fruit responses</td>\n",
       "      <td>No missing vegetable responses</td>\n",
       "      <td>Included - Not Missing Fruit Responses</td>\n",
       "      <td>Included - Not Missing Vegetable Responses</td>\n",
       "      <td>96.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>Consumed fruit less than one time per day</td>\n",
       "      <td>Consumed vegetables one or more times per day</td>\n",
       "      <td>Included - Values are in accepted range</td>\n",
       "      <td>Included - Values are in accepted range</td>\n",
       "      <td>No missing values and in accepted range</td>\n",
       "      <td>No missing values and in accepted range</td>\n",
       "      <td>Had physical activity or exercise</td>\n",
       "      <td>60.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>3061</td>\n",
       "      <td>525</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5833.0</td>\n",
       "      <td>5833.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2333.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Don't know/Not Sure/Refused/Missing</td>\n",
       "      <td>Don't know/Not Sure/Refused/Missing</td>\n",
       "      <td>Don't know/Not Sure/Refused/Missing</td>\n",
       "      <td>Don't know/Not Sure/Refused/Missing</td>\n",
       "      <td>Don't know/Not Sure/Refused/Missing</td>\n",
       "      <td>Meet muscle strengthening recommendations</td>\n",
       "      <td>Don't know/Not Sure/Refused/Missing</td>\n",
       "      <td>Don't know/Not Sure/Refused/Missing</td>\n",
       "      <td>Not told they have arthritis</td>\n",
       "      <td>Not told they have arthritis</td>\n",
       "      <td>Not told they have arthritis</td>\n",
       "      <td>Always or Almost Always Wear Seat Belt</td>\n",
       "      <td>Always Wear Seat Belt</td>\n",
       "      <td>Age Less Than 65</td>\n",
       "      <td>Age Less Than 65</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>New York City</td>\n",
       "      <td>New York City (NYC)</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>D</td>\n",
       "      <td>Data do not meet the criteria for statistical ...</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>Data do not meet the criteria for statistical ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New York</td>\n",
       "      <td>203</td>\n",
       "      <td>D</td>\n",
       "      <td>To be called</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120050</td>\n",
       "      <td>3</td>\n",
       "      <td>December</td>\n",
       "      <td>12282015</td>\n",
       "      <td>December</td>\n",
       "      <td>28</td>\n",
       "      <td>2015</td>\n",
       "      <td>1200</td>\n",
       "      <td>2015000014</td>\n",
       "      <td>2015000014</td>\n",
       "      <td>3</td>\n",
       "      <td>3593</td>\n",
       "      <td>1.568383e+06</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Missing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Missing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes, Female Respondent</td>\n",
       "      <td>Missing</td>\n",
       "      <td>No</td>\n",
       "      <td>New York</td>\n",
       "      <td>No</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Very good</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes, only one</td>\n",
       "      <td>No</td>\n",
       "      <td>Within past year (anytime less than 12 months ...</td>\n",
       "      <td>No</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Within the past year (anytime less than 12 mon...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Female</td>\n",
       "      <td>Age 25 - 34</td>\n",
       "      <td>Data do not meet the criteria for statistical ...</td>\n",
       "      <td>Data do not meet the criteria for statistical ...</td>\n",
       "      <td>D</td>\n",
       "      <td>Never married</td>\n",
       "      <td>College 4 years or more (College graduate)</td>\n",
       "      <td>Rent</td>\n",
       "      <td>D</td>\n",
       "      <td>Data do not meet the criteria for statistical ...</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>No</td>\n",
       "      <td>Employed for wages</td>\n",
       "      <td>None</td>\n",
       "      <td>Don't know/Not sure</td>\n",
       "      <td>Yes</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not at all</td>\n",
       "      <td>Days in past 30 days</td>\n",
       "      <td>Number of drinks</td>\n",
       "      <td>None</td>\n",
       "      <td>Number of drinks</td>\n",
       "      <td>Never</td>\n",
       "      <td>Times per week</td>\n",
       "      <td>Never</td>\n",
       "      <td>Times per week</td>\n",
       "      <td>Times per week</td>\n",
       "      <td>Times per week</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Running</td>\n",
       "      <td>Times per month</td>\n",
       "      <td>Hours and Minutes</td>\n",
       "      <td>Calisthenics</td>\n",
       "      <td>Times per month</td>\n",
       "      <td>Hours and Minutes</td>\n",
       "      <td>Never</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Always</td>\n",
       "      <td>No</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Code month and year</td>\n",
       "      <td>Private doctor or HMO</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Data do not meet the criteria for statistical ...</td>\n",
       "      <td>Data do not meet the criteria for statistical ...</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>D</td>\n",
       "      <td>Data do not meet the criteria for statistical ...</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Data do not meet the criteria for statistical ...</td>\n",
       "      <td>Data do not meet the criteria for statistical ...</td>\n",
       "      <td>D</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>Core only cellphone (collected out of state)</td>\n",
       "      <td>English</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data do not meet the criteria for statistical ...</td>\n",
       "      <td>D</td>\n",
       "      <td>362039</td>\n",
       "      <td>436.510631</td>\n",
       "      <td>NaN</td>\n",
       "      <td>436.510631</td>\n",
       "      <td>1.0</td>\n",
       "      <td>436.510631</td>\n",
       "      <td>3</td>\n",
       "      <td>Age 25 to 34</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>College 4 years or more (College graduate)</td>\n",
       "      <td>Never married</td>\n",
       "      <td>Rent</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>Missing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No Dual Phone Use</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>25</td>\n",
       "      <td>8</td>\n",
       "      <td>1205.094503</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Good or Better Health</td>\n",
       "      <td>Have health care coverage</td>\n",
       "      <td>No</td>\n",
       "      <td>Had cholesterol checked in past 5 years</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Did not report having MI or CHD</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Never</td>\n",
       "      <td>Not diagnosed with arthritis</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>Age 30 to 34</td>\n",
       "      <td>Age 18 to 64</td>\n",
       "      <td>Imputed Age 30 to 34</td>\n",
       "      <td>Age 25 to 34</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>1 or greater</td>\n",
       "      <td>Overweight</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No children in household</td>\n",
       "      <td>Graduated from College or Technical School</td>\n",
       "      <td>Don't know/Not sure/Missing</td>\n",
       "      <td>Never smoked</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Drink-Occasions per day</td>\n",
       "      <td>No</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>No missing fruit responses</td>\n",
       "      <td>No missing vegetable responses</td>\n",
       "      <td>Included - Not Missing Fruit Responses</td>\n",
       "      <td>Included - Not Missing Vegetable Responses</td>\n",
       "      <td>43.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>Consumed fruit less than one time per day</td>\n",
       "      <td>Consumed vegetables one or more times per day</td>\n",
       "      <td>Included - Values are in accepted range</td>\n",
       "      <td>Included - Values are in accepted range</td>\n",
       "      <td>No missing values and in accepted range</td>\n",
       "      <td>No missing values and in accepted range</td>\n",
       "      <td>Had physical activity or exercise</td>\n",
       "      <td>60.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>3690</td>\n",
       "      <td>633</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>467.0</td>\n",
       "      <td>467.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Insufficiently Active</td>\n",
       "      <td>Did Not Meet Aerobic Recommendations</td>\n",
       "      <td>1-149 minutes  (or vigorous equivalent minutes...</td>\n",
       "      <td>1-300 minutes  (or vigorous equivalent minutes...</td>\n",
       "      <td>0-300 minutes  (or vigorous equivalent minutes...</td>\n",
       "      <td>Did not meet muscle strengthening recommendations</td>\n",
       "      <td>Did not meet Either Guideline</td>\n",
       "      <td>Did Not Meet Both Guidelines</td>\n",
       "      <td>Not told they have arthritis</td>\n",
       "      <td>Not told they have arthritis</td>\n",
       "      <td>Not told they have arthritis</td>\n",
       "      <td>Always or Almost Always Wear Seat Belt</td>\n",
       "      <td>Always Wear Seat Belt</td>\n",
       "      <td>Age Less Than 65</td>\n",
       "      <td>Age Less Than 65</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Finger Lakes</td>\n",
       "      <td>NYS exclusive of NYC</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>D</td>\n",
       "      <td>Data do not meet the criteria for statistical ...</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>Data do not meet the criteria for statistical ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>New York</td>\n",
       "      <td>206</td>\n",
       "      <td>D</td>\n",
       "      <td>To be called</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30066</td>\n",
       "      <td>28</td>\n",
       "      <td>March</td>\n",
       "      <td>3182015</td>\n",
       "      <td>March</td>\n",
       "      <td>18</td>\n",
       "      <td>2015</td>\n",
       "      <td>1200</td>\n",
       "      <td>2015000015</td>\n",
       "      <td>2015000015</td>\n",
       "      <td>3</td>\n",
       "      <td>4465</td>\n",
       "      <td>8.766998e+05</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Missing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Missing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes, Male Respondent</td>\n",
       "      <td>Missing</td>\n",
       "      <td>No</td>\n",
       "      <td>New York</td>\n",
       "      <td>No</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Within past year (anytime less than 12 months ...</td>\n",
       "      <td>No</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Don't know/Not Sure</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Male</td>\n",
       "      <td>Age 18 - 24</td>\n",
       "      <td>Data do not meet the criteria for statistical ...</td>\n",
       "      <td>Data do not meet the criteria for statistical ...</td>\n",
       "      <td>D</td>\n",
       "      <td>Never married</td>\n",
       "      <td>Grade 12 or GED (High school graduate)</td>\n",
       "      <td>Rent</td>\n",
       "      <td>D</td>\n",
       "      <td>Data do not meet the criteria for statistical ...</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>No</td>\n",
       "      <td>Employed for wages</td>\n",
       "      <td>Number of children</td>\n",
       "      <td>Don't know/Not sure</td>\n",
       "      <td>Yes</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not at all</td>\n",
       "      <td>No drinks in past 30 days</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Never</td>\n",
       "      <td>Times per month</td>\n",
       "      <td>Don't know/Not sure</td>\n",
       "      <td>Don't know/Not sure</td>\n",
       "      <td>Don't know/Not sure</td>\n",
       "      <td>Don't know/Not sure</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Walking</td>\n",
       "      <td>Don't know/Not sure</td>\n",
       "      <td>Hours and Minutes</td>\n",
       "      <td>No other activity</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Never</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Always</td>\n",
       "      <td>No</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Don't know/Not Sure</td>\n",
       "      <td>No</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Data do not meet the criteria for statistical ...</td>\n",
       "      <td>Data do not meet the criteria for statistical ...</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>D</td>\n",
       "      <td>Data do not meet the criteria for statistical ...</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Data do not meet the criteria for statistical ...</td>\n",
       "      <td>Data do not meet the criteria for statistical ...</td>\n",
       "      <td>D</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>Core only cellphone (collected out of state)</td>\n",
       "      <td>English</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data do not meet the criteria for statistical ...</td>\n",
       "      <td>D</td>\n",
       "      <td>362069</td>\n",
       "      <td>196.349347</td>\n",
       "      <td>NaN</td>\n",
       "      <td>196.349347</td>\n",
       "      <td>1.0</td>\n",
       "      <td>196.349347</td>\n",
       "      <td>6</td>\n",
       "      <td>Age 18 to 24</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Grade 12 or GED (High school graduate)</td>\n",
       "      <td>Never married</td>\n",
       "      <td>Rent</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>Missing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No Dual Phone Use</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>34</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>58</td>\n",
       "      <td>19</td>\n",
       "      <td>1776.406100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Good or Better Health</td>\n",
       "      <td>Do not have health care coverage</td>\n",
       "      <td>No</td>\n",
       "      <td>Don't know/Not Sure Or Refused/Missing</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Did not report having MI or CHD</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Never</td>\n",
       "      <td>Not diagnosed with arthritis</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>Age 18 to 24</td>\n",
       "      <td>Age 18 to 64</td>\n",
       "      <td>Imputed Age 18 to 24</td>\n",
       "      <td>Age 18 to 24</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>1 or greater</td>\n",
       "      <td>Overweight</td>\n",
       "      <td>Yes</td>\n",
       "      <td>One child in household</td>\n",
       "      <td>Graduated High School</td>\n",
       "      <td>Don't know/Not sure/Missing</td>\n",
       "      <td>Never smoked</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No Drink-Occasions per day</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No missing fruit responses</td>\n",
       "      <td>Has 1, 2, 3, or 4 missing vegetable responses</td>\n",
       "      <td>Included - Not Missing Fruit Responses</td>\n",
       "      <td>Not Included - Missing Vegetable Responses</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Consumed fruit less than one time per day</td>\n",
       "      <td>Don´t know, refused or missing values</td>\n",
       "      <td>Included - Values are in accepted range</td>\n",
       "      <td>Included - Values are in accepted range</td>\n",
       "      <td>No missing values and in accepted range</td>\n",
       "      <td>Missing Vegetable responses</td>\n",
       "      <td>Had physical activity or exercise</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5010</td>\n",
       "      <td>859</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Don't know/Not Sure/Refused/Missing</td>\n",
       "      <td>Don't know/Not Sure/Refused/Missing</td>\n",
       "      <td>Don't know/Not Sure/Refused/Missing</td>\n",
       "      <td>Don't know/Not Sure/Refused/Missing</td>\n",
       "      <td>Don't know/Not Sure/Refused/Missing</td>\n",
       "      <td>Did not meet muscle strengthening recommendations</td>\n",
       "      <td>Don't know/Not Sure/Refused/Missing</td>\n",
       "      <td>Don't know/Not Sure/Refused/Missing</td>\n",
       "      <td>Not told they have arthritis</td>\n",
       "      <td>Not told they have arthritis</td>\n",
       "      <td>Not told they have arthritis</td>\n",
       "      <td>Always or Almost Always Wear Seat Belt</td>\n",
       "      <td>Always Wear Seat Belt</td>\n",
       "      <td>Age Less Than 65</td>\n",
       "      <td>Age Less Than 65</td>\n",
       "      <td>No</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>North Country</td>\n",
       "      <td>NYS exclusive of NYC</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>D</td>\n",
       "      <td>Data do not meet the criteria for statistical ...</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>Data do not meet the criteria for statistical ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New York</td>\n",
       "      <td>203</td>\n",
       "      <td>D</td>\n",
       "      <td>To be called</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110026</td>\n",
       "      <td>23</td>\n",
       "      <td>November</td>\n",
       "      <td>11292015</td>\n",
       "      <td>November</td>\n",
       "      <td>29</td>\n",
       "      <td>2015</td>\n",
       "      <td>1200</td>\n",
       "      <td>2015000016</td>\n",
       "      <td>2015000016</td>\n",
       "      <td>8</td>\n",
       "      <td>3593</td>\n",
       "      <td>1.568383e+06</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Missing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Missing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes, Female Respondent</td>\n",
       "      <td>Missing</td>\n",
       "      <td>No</td>\n",
       "      <td>New York</td>\n",
       "      <td>No</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Number of days</td>\n",
       "      <td>Number of days</td>\n",
       "      <td>Number of days</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes, only one</td>\n",
       "      <td>No</td>\n",
       "      <td>Within past year (anytime less than 12 months ...</td>\n",
       "      <td>No</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>No</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Female</td>\n",
       "      <td>Age 25 - 34</td>\n",
       "      <td>Data do not meet the criteria for statistical ...</td>\n",
       "      <td>Data do not meet the criteria for statistical ...</td>\n",
       "      <td>D</td>\n",
       "      <td>Never married</td>\n",
       "      <td>College 4 years or more (College graduate)</td>\n",
       "      <td>Rent</td>\n",
       "      <td>D</td>\n",
       "      <td>Data do not meet the criteria for statistical ...</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>No</td>\n",
       "      <td>Employed for wages</td>\n",
       "      <td>None</td>\n",
       "      <td>Less than $50,000 ($35,000 to less than $50,000)</td>\n",
       "      <td>Yes</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not at all</td>\n",
       "      <td>Days per week</td>\n",
       "      <td>Number of drinks</td>\n",
       "      <td>Number of Times</td>\n",
       "      <td>Number of drinks</td>\n",
       "      <td>Never</td>\n",
       "      <td>Times per day</td>\n",
       "      <td>Times per day</td>\n",
       "      <td>Times per day</td>\n",
       "      <td>Times per week</td>\n",
       "      <td>Times per day</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Running</td>\n",
       "      <td>Times per week</td>\n",
       "      <td>Hours and Minutes</td>\n",
       "      <td>Elliptical/EFX machine exercise</td>\n",
       "      <td>Times per week</td>\n",
       "      <td>Hours and Minutes</td>\n",
       "      <td>Times per week</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Always</td>\n",
       "      <td>No</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Unknown month and known year</td>\n",
       "      <td>Private doctor or HMO</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Data do not meet the criteria for statistical ...</td>\n",
       "      <td>Data do not meet the criteria for statistical ...</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>D</td>\n",
       "      <td>Data do not meet the criteria for statistical ...</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Data do not meet the criteria for statistical ...</td>\n",
       "      <td>Data do not meet the criteria for statistical ...</td>\n",
       "      <td>D</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>Core only cellphone (collected out of state)</td>\n",
       "      <td>English</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data do not meet the criteria for statistical ...</td>\n",
       "      <td>D</td>\n",
       "      <td>362039</td>\n",
       "      <td>436.510631</td>\n",
       "      <td>NaN</td>\n",
       "      <td>436.510631</td>\n",
       "      <td>1.0</td>\n",
       "      <td>436.510631</td>\n",
       "      <td>3</td>\n",
       "      <td>Age 25 to 34</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>College 4 years or more (College graduate)</td>\n",
       "      <td>Never married</td>\n",
       "      <td>Rent</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>Missing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No Dual Phone Use</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>25</td>\n",
       "      <td>8</td>\n",
       "      <td>1273.934863</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Good or Better Health</td>\n",
       "      <td>Have health care coverage</td>\n",
       "      <td>No</td>\n",
       "      <td>Have never had cholesterol checked</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Did not report having MI or CHD</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Never</td>\n",
       "      <td>Not diagnosed with arthritis</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>Age 25 to 29</td>\n",
       "      <td>Age 18 to 64</td>\n",
       "      <td>Imputed Age 25 to 29</td>\n",
       "      <td>Age 25 to 34</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>1 or greater</td>\n",
       "      <td>Normal Weight</td>\n",
       "      <td>No</td>\n",
       "      <td>No children in household</td>\n",
       "      <td>Graduated from College or Technical School</td>\n",
       "      <td>$35,000 to less than $50,000</td>\n",
       "      <td>Never smoked</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Drink-Occasions per day</td>\n",
       "      <td>Yes</td>\n",
       "      <td>400</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>No missing fruit responses</td>\n",
       "      <td>No missing vegetable responses</td>\n",
       "      <td>Included - Not Missing Fruit Responses</td>\n",
       "      <td>Included - Not Missing Vegetable Responses</td>\n",
       "      <td>300.0</td>\n",
       "      <td>471.0</td>\n",
       "      <td>Consumed fruit one or more times per day</td>\n",
       "      <td>Consumed vegetables one or more times per day</td>\n",
       "      <td>Included - Values are in accepted range</td>\n",
       "      <td>Included - Values are in accepted range</td>\n",
       "      <td>No missing values and in accepted range</td>\n",
       "      <td>No missing values and in accepted range</td>\n",
       "      <td>Had physical activity or exercise</td>\n",
       "      <td>60.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>3764</td>\n",
       "      <td>645</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Active</td>\n",
       "      <td>Meet Aerobic Recommendations</td>\n",
       "      <td>150+ minutes (or vigorous equivalent minutes) ...</td>\n",
       "      <td>1-300 minutes  (or vigorous equivalent minutes...</td>\n",
       "      <td>0-300 minutes  (or vigorous equivalent minutes...</td>\n",
       "      <td>Meet muscle strengthening recommendations</td>\n",
       "      <td>Met Both Guidelines</td>\n",
       "      <td>Met Both Guidelines</td>\n",
       "      <td>Not told they have arthritis</td>\n",
       "      <td>Not told they have arthritis</td>\n",
       "      <td>Not told they have arthritis</td>\n",
       "      <td>Always or Almost Always Wear Seat Belt</td>\n",
       "      <td>Always Wear Seat Belt</td>\n",
       "      <td>Age Less Than 65</td>\n",
       "      <td>Age Less Than 65</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Finger Lakes</td>\n",
       "      <td>NYS exclusive of NYC</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>D</td>\n",
       "      <td>Data do not meet the criteria for statistical ...</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>Data do not meet the criteria for statistical ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     _STATE  _GEOSTR _DENSTR2       PRECALL  SECSCRFL  REPNUM  REPDEPTH  \\\n",
       "0  New York      207        D  To be called       NaN   40187         5   \n",
       "1  New York      207        D  To be called       NaN   60025        21   \n",
       "2  New York      203        D  To be called       NaN  120050         3   \n",
       "3  New York      206        D  To be called       NaN   30066        28   \n",
       "4  New York      203        D  To be called       NaN  110026        23   \n",
       "\n",
       "     FMONTH     IDATE    IMONTH  IDAY  IYEAR  DISPCODE       SEQNO  \\\n",
       "0     April   4092015     April     9   2015      1200  2015000012   \n",
       "1      June   6232015      June    23   2015      1200  2015000013   \n",
       "2  December  12282015  December    28   2015      1200  2015000014   \n",
       "3     March   3182015     March    18   2015      1200  2015000015   \n",
       "4  November  11292015  November    29   2015      1200  2015000016   \n",
       "\n",
       "         _PSU  NATTMPTS  NRECSEL       NRECSTR PVTRESD1 COLGHOUS  STATERES  \\\n",
       "0  2015000012         1    24887  1.346955e+07  Missing  Missing       NaN   \n",
       "1  2015000013         4    24887  1.346955e+07  Missing  Missing       NaN   \n",
       "2  2015000014         3     3593  1.568383e+06  Missing  Missing       NaN   \n",
       "3  2015000015         3     4465  8.766998e+05  Missing  Missing       NaN   \n",
       "4  2015000016         8     3593  1.568383e+06  Missing  Missing       NaN   \n",
       "\n",
       "  CELLFON3   LADULT  NUMADULT                  CADULT CCLGHOUS CSTATE  \\\n",
       "0  Missing  Missing       NaN    Yes, Male Respondent  Missing     No   \n",
       "1  Missing  Missing       NaN  Yes, Female Respondent  Missing     No   \n",
       "2  Missing  Missing       NaN  Yes, Female Respondent  Missing     No   \n",
       "3  Missing  Missing       NaN    Yes, Male Respondent  Missing     No   \n",
       "4  Missing  Missing       NaN  Yes, Female Respondent  Missing     No   \n",
       "\n",
       "   RSPSTATE LANDLINE  HHADULT    GENHLTH        PHYSHLTH        MENTHLTH  \\\n",
       "0  New York       No      2.0  Very good            None            None   \n",
       "1  New York       No      2.0       Good            None  Number of days   \n",
       "2  New York       No      1.0  Very good            None            None   \n",
       "3  New York       No      3.0  Excellent            None            None   \n",
       "4  New York       No      1.0  Excellent  Number of days  Number of days   \n",
       "\n",
       "               POORHLTH HLTHPLN1       PERSDOC2 MEDCOST  \\\n",
       "0  Not asked or Missing      Yes             No      No   \n",
       "1                  None      Yes  Yes, only one     Yes   \n",
       "2  Not asked or Missing      Yes  Yes, only one      No   \n",
       "3  Not asked or Missing       No             No      No   \n",
       "4        Number of days      Yes  Yes, only one      No   \n",
       "\n",
       "                                            CHECKUP1 BPHIGH4  \\\n",
       "0  Within past 2 years (1 year but less than 2 ye...     Yes   \n",
       "1  Within past year (anytime less than 12 months ...     Yes   \n",
       "2  Within past year (anytime less than 12 months ...      No   \n",
       "3  Within past year (anytime less than 12 months ...      No   \n",
       "4  Within past year (anytime less than 12 months ...      No   \n",
       "\n",
       "                 BPMEDS             BLOODCHO  \\\n",
       "0                    No                  Yes   \n",
       "1                   Yes                  Yes   \n",
       "2  Not asked or Missing                  Yes   \n",
       "3  Not asked or Missing  Don't know/Not Sure   \n",
       "4  Not asked or Missing                   No   \n",
       "\n",
       "                                             CHOLCHK               TOLDHI2  \\\n",
       "0  Within the past 5 years (2 years but less than...                    No   \n",
       "1  Within the past year (anytime less than 12 mon...                    No   \n",
       "2  Within the past year (anytime less than 12 mon...                   Yes   \n",
       "3                               Not asked or Missing  Not asked or Missing   \n",
       "4                               Not asked or Missing  Not asked or Missing   \n",
       "\n",
       "              CVDINFR4 CVDCRHD4 CVDSTRK3 ASTHMA3               ASTHNOW  \\\n",
       "0                   No       No       No      No  Not asked or Missing   \n",
       "1  Don't know/Not sure       No      Yes      No  Not asked or Missing   \n",
       "2                   No       No       No      No  Not asked or Missing   \n",
       "3                   No       No       No      No  Not asked or Missing   \n",
       "4                   No       No       No      No  Not asked or Missing   \n",
       "\n",
       "  CHCSCNCR CHCOCNCR CHCCOPD1 HAVARTH3 ADDEPEV2 CHCKIDNY DIABETE3  \\\n",
       "0       No       No       No       No       No       No       No   \n",
       "1       No       No       No       No       No       No       No   \n",
       "2       No       No       No       No       No       No       No   \n",
       "3       No       No       No       No       No       No       No   \n",
       "4       No       No       No       No      Yes       No       No   \n",
       "\n",
       "               DIABAGE2     SEX          AGE  \\\n",
       "0  Not asked or Missing    Male  Age 25 - 34   \n",
       "1  Not asked or Missing  Female  Age 45 - 54   \n",
       "2  Not asked or Missing  Female  Age 25 - 34   \n",
       "3  Not asked or Missing    Male  Age 18 - 24   \n",
       "4  Not asked or Missing  Female  Age 25 - 34   \n",
       "\n",
       "                                            HISPANC3  \\\n",
       "0  Data do not meet the criteria for statistical ...   \n",
       "1  Data do not meet the criteria for statistical ...   \n",
       "2  Data do not meet the criteria for statistical ...   \n",
       "3  Data do not meet the criteria for statistical ...   \n",
       "4  Data do not meet the criteria for statistical ...   \n",
       "\n",
       "                                              MRACE1 ORACE3        MARITAL  \\\n",
       "0  Data do not meet the criteria for statistical ...      D  Never married   \n",
       "1  Data do not meet the criteria for statistical ...      D      Separated   \n",
       "2  Data do not meet the criteria for statistical ...      D  Never married   \n",
       "3  Data do not meet the criteria for statistical ...      D  Never married   \n",
       "4  Data do not meet the criteria for statistical ...      D  Never married   \n",
       "\n",
       "                                               EDUCA           RENTHOM1  \\\n",
       "0         College 4 years or more (College graduate)               Rent   \n",
       "1  College 1 year to 3 years (Some college or tec...  Other arrangement   \n",
       "2         College 4 years or more (College graduate)               Rent   \n",
       "3             Grade 12 or GED (High school graduate)               Rent   \n",
       "4         College 4 years or more (College graduate)               Rent   \n",
       "\n",
       "  CTYCODE1                                            ZIPCODE  \\\n",
       "0        D  Data do not meet the criteria for statistical ...   \n",
       "1        D  Data do not meet the criteria for statistical ...   \n",
       "2        D  Data do not meet the criteria for statistical ...   \n",
       "3        D  Data do not meet the criteria for statistical ...   \n",
       "4        D  Data do not meet the criteria for statistical ...   \n",
       "\n",
       "               NUMHHOL2              NUMPHON2               CPDEMO1 VETERAN3  \\\n",
       "0  Not asked or Missing  Not asked or Missing  Not asked or Missing      Yes   \n",
       "1  Not asked or Missing  Not asked or Missing  Not asked or Missing       No   \n",
       "2  Not asked or Missing  Not asked or Missing  Not asked or Missing       No   \n",
       "3  Not asked or Missing  Not asked or Missing  Not asked or Missing       No   \n",
       "4  Not asked or Missing  Not asked or Missing  Not asked or Missing       No   \n",
       "\n",
       "              EMPLOY1            CHILDREN  \\\n",
       "0  Employed for wages                None   \n",
       "1  Employed for wages  Number of children   \n",
       "2  Employed for wages                None   \n",
       "3  Employed for wages  Number of children   \n",
       "4  Employed for wages                None   \n",
       "\n",
       "                                            INCOME2 INTERNET WEIGHT2 HEIGHT3  \\\n",
       "0                                   $75,000 or more      Yes       D       D   \n",
       "1                               Don't know/Not sure      Yes       D       D   \n",
       "2                               Don't know/Not sure      Yes       D       D   \n",
       "3                               Don't know/Not sure      Yes       D       D   \n",
       "4  Less than $50,000 ($35,000 to less than $50,000)      Yes       D       D   \n",
       "\n",
       "               PREGNANT QLACTLM2 USEEQUIP BLIND DECIDE DIFFWALK DIFFDRES  \\\n",
       "0  Not asked or Missing       No       No    No     No       No       No   \n",
       "1  Not asked or Missing       No       No    No     No       No       No   \n",
       "2                    No       No       No    No     No       No       No   \n",
       "3  Not asked or Missing       No       No    No     No       No       No   \n",
       "4                    No       No       No    No     No       No       No   \n",
       "\n",
       "  DIFFALON SMOKE100              SMOKDAY2              STOPSMK2  \\\n",
       "0       No       No  Not asked or Missing  Not asked or Missing   \n",
       "1       No       No  Not asked or Missing  Not asked or Missing   \n",
       "2       No       No  Not asked or Missing  Not asked or Missing   \n",
       "3       No       No  Not asked or Missing  Not asked or Missing   \n",
       "4       No       No  Not asked or Missing  Not asked or Missing   \n",
       "\n",
       "               LASTSMK2     USENOW3                    ALCDAY5  \\\n",
       "0  Not asked or Missing  Not at all              Days per week   \n",
       "1  Not asked or Missing  Not at all  No drinks in past 30 days   \n",
       "2  Not asked or Missing  Not at all       Days in past 30 days   \n",
       "3  Not asked or Missing  Not at all  No drinks in past 30 days   \n",
       "4  Not asked or Missing  Not at all              Days per week   \n",
       "\n",
       "               AVEDRNK2              DRNK3GE5              MAXDRNKS  \\\n",
       "0      Number of drinks       Number of Times      Number of drinks   \n",
       "1  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "2      Number of drinks                  None      Number of drinks   \n",
       "3  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "4      Number of drinks       Number of Times      Number of drinks   \n",
       "\n",
       "          FRUITJU1           FRUIT1              FVBEANS              FVGREEN  \\\n",
       "0   Times per week   Times per week      Times per month      Times per month   \n",
       "1  Times per month  Times per month      Times per month      Times per month   \n",
       "2            Never   Times per week                Never       Times per week   \n",
       "3            Never  Times per month  Don't know/Not sure  Don't know/Not sure   \n",
       "4            Never    Times per day        Times per day        Times per day   \n",
       "\n",
       "               FVORANG             VEGETAB1 EXERANY2 EXRACT11  \\\n",
       "0      Times per month       Times per week      Yes  Running   \n",
       "1      Times per month      Times per month      Yes  Running   \n",
       "2       Times per week       Times per week      Yes  Running   \n",
       "3  Don't know/Not sure  Don't know/Not sure      Yes  Walking   \n",
       "4       Times per week        Times per day      Yes  Running   \n",
       "\n",
       "              EXEROFT1             EXERHMM1                         EXRACT21  \\\n",
       "0       Times per week    Hours and Minutes       Bicycling machine exercise   \n",
       "1      Times per month  Don't know/Not sure                          Walking   \n",
       "2      Times per month    Hours and Minutes                     Calisthenics   \n",
       "3  Don't know/Not sure    Hours and Minutes                No other activity   \n",
       "4       Times per week    Hours and Minutes  Elliptical/EFX machine exercise   \n",
       "\n",
       "               EXEROFT2              EXERHMM2         STRENGTH  \\\n",
       "0       Times per month     Hours and Minutes   Times per week   \n",
       "1       Times per month   Don't know/Not sure  Times per month   \n",
       "2       Times per month     Hours and Minutes            Never   \n",
       "3  Not asked or Missing  Not asked or Missing            Never   \n",
       "4        Times per week     Hours and Minutes   Times per week   \n",
       "\n",
       "               LMTJOIN3 ARTHDIS2 ARTHSOCL JOINPAIN       SEATBELT FLUSHOT6  \\\n",
       "0  Not asked or Missing  Missing  Missing  Missing  Nearly always       No   \n",
       "1  Not asked or Missing  Missing  Missing  Missing         Always      Yes   \n",
       "2  Not asked or Missing  Missing  Missing  Missing         Always       No   \n",
       "3  Not asked or Missing  Missing  Missing  Missing         Always       No   \n",
       "4  Not asked or Missing  Missing  Missing  Missing         Always       No   \n",
       "\n",
       "               FLSHTMY2                         IMFVPLAC             PNEUVAC3  \\\n",
       "0  Not asked or Missing             Not asked or Missing                   No   \n",
       "1          Month / Year  A hospital (Example: inpatient)                  Yes   \n",
       "2  Not asked or Missing             Not asked or Missing                  Yes   \n",
       "3  Not asked or Missing             Not asked or Missing  Don't know/Not Sure   \n",
       "4  Not asked or Missing             Not asked or Missing                  Yes   \n",
       "\n",
       "  HIVTST6                      HIVTSTD3               WHRTST10  \\\n",
       "0     Yes           Don't know/Not sure                 Clinic   \n",
       "1     Yes           Don't know/Not sure                 Clinic   \n",
       "2     Yes           Code month and year  Private doctor or HMO   \n",
       "3      No          Not asked or Missing   Not asked or Missing   \n",
       "4     Yes  Unknown month and known year  Private doctor or HMO   \n",
       "\n",
       "               PDIABTST              PREDIAB1               INSULIN  \\\n",
       "0  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "1  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "2  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "3  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "4  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "\n",
       "               BLDSUGAR              FEETCHK2              DOCTDIAB  \\\n",
       "0  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "1  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "2  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "3  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "4  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "\n",
       "               CHKHEMO3               FEETCHK               EYEEXAM  \\\n",
       "0  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "1  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "2  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "3  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "4  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "\n",
       "                DIABEYE               DIABEDU              CAREGIV1  \\\n",
       "0  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "1  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "2  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "3  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "4  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "\n",
       "               CRGVREL1              CRGVLNG1              CRGVHRS1  \\\n",
       "0  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "1  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "2  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "3  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "4  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "\n",
       "               CRGVPRB1              CRGVPERS              CRGVHOUS  \\\n",
       "0  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "1  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "2  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "3  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "4  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "\n",
       "               CRGVMST2              CRGVEXPT              CIMEMLOS  \\\n",
       "0  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "1  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "2  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "3  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "4  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "\n",
       "                CDHOUSE              CDASSIST                CDHELP  \\\n",
       "0  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "1  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "2  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "3  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "4  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "\n",
       "               CDSOCIAL              CDDISCUS              ARTTODAY  \\\n",
       "0  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "1  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "2  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "3  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "4  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "\n",
       "                ARTHWGT              ARTHEXER               ARTHEDU  \\\n",
       "0  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "1  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "2  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "3  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "4  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "\n",
       "               BLDSTOOL              LSTBLDS3              HADSIGM3  \\\n",
       "0  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "1  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "2  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "3  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "4  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "\n",
       "               HADSGCO1              LASTSIG3  \\\n",
       "0  Not asked or Missing  Not asked or Missing   \n",
       "1  Not asked or Missing  Not asked or Missing   \n",
       "2  Not asked or Missing  Not asked or Missing   \n",
       "3  Not asked or Missing  Not asked or Missing   \n",
       "4  Not asked or Missing  Not asked or Missing   \n",
       "\n",
       "                                            TYPEWORK  \\\n",
       "0  Data do not meet the criteria for statistical ...   \n",
       "1  Data do not meet the criteria for statistical ...   \n",
       "2  Data do not meet the criteria for statistical ...   \n",
       "3  Data do not meet the criteria for statistical ...   \n",
       "4  Data do not meet the criteria for statistical ...   \n",
       "\n",
       "                                            TYPEINDS              SXORIENT  \\\n",
       "0  Data do not meet the criteria for statistical ...  Not asked or Missing   \n",
       "1  Data do not meet the criteria for statistical ...  Not asked or Missing   \n",
       "2  Data do not meet the criteria for statistical ...  Not asked or Missing   \n",
       "3  Data do not meet the criteria for statistical ...  Not asked or Missing   \n",
       "4  Data do not meet the criteria for statistical ...  Not asked or Missing   \n",
       "\n",
       "  TRNSGNDR                                           RCSBIRTH  \\\n",
       "0        D  Data do not meet the criteria for statistical ...   \n",
       "1        D  Data do not meet the criteria for statistical ...   \n",
       "2        D  Data do not meet the criteria for statistical ...   \n",
       "3        D  Data do not meet the criteria for statistical ...   \n",
       "4        D  Data do not meet the criteria for statistical ...   \n",
       "\n",
       "               RCSGENDR                                           RCHISLA1  \\\n",
       "0  Not asked or Missing  Data do not meet the criteria for statistical ...   \n",
       "1  Not asked or Missing  Data do not meet the criteria for statistical ...   \n",
       "2  Not asked or Missing  Data do not meet the criteria for statistical ...   \n",
       "3  Not asked or Missing  Data do not meet the criteria for statistical ...   \n",
       "4  Not asked or Missing  Data do not meet the criteria for statistical ...   \n",
       "\n",
       "                                            RCSRACE1 RCSBRAC2  \\\n",
       "0  Data do not meet the criteria for statistical ...        D   \n",
       "1  Data do not meet the criteria for statistical ...        D   \n",
       "2  Data do not meet the criteria for statistical ...        D   \n",
       "3  Data do not meet the criteria for statistical ...        D   \n",
       "4  Data do not meet the criteria for statistical ...        D   \n",
       "\n",
       "               RCSRLTN2              CASTHDX2              CASTHNO2 ADHISPA  \\\n",
       "0  Not asked or Missing  Not asked or Missing  Not asked or Missing       D   \n",
       "1  Not asked or Missing  Not asked or Missing  Not asked or Missing       D   \n",
       "2  Not asked or Missing  Not asked or Missing  Not asked or Missing       D   \n",
       "3  Not asked or Missing  Not asked or Missing  Not asked or Missing       D   \n",
       "4  Not asked or Missing  Not asked or Missing  Not asked or Missing       D   \n",
       "\n",
       "  CHHISPA                                        QSTVER  QSTLANG EXACTOT1  \\\n",
       "0       D  Core only cellphone (collected out of state)  English      NaN   \n",
       "1       D  Core only cellphone (collected out of state)  English      NaN   \n",
       "2       D  Core only cellphone (collected out of state)  English      NaN   \n",
       "3       D  Core only cellphone (collected out of state)  English      NaN   \n",
       "4       D  Core only cellphone (collected out of state)  English      NaN   \n",
       "\n",
       "  EXACTOT2                                           _MSACODE MSCODE  _STSTR  \\\n",
       "0      NaN  Data do not meet the criteria for statistical ...      D  362079   \n",
       "1      NaN  Data do not meet the criteria for statistical ...      D  362079   \n",
       "2      NaN  Data do not meet the criteria for statistical ...      D  362039   \n",
       "3      NaN  Data do not meet the criteria for statistical ...      D  362069   \n",
       "4      NaN  Data do not meet the criteria for statistical ...      D  362039   \n",
       "\n",
       "       _STRWT  _RAW        _WT2  _RAWRAKE    _WT2RAKE  _REGION       _IMPAGE  \\\n",
       "0  541.228186   NaN  541.228186       1.0  541.228186        7  Age 25 to 34   \n",
       "1  541.228186   NaN  541.228186       1.0  541.228186        7  Age 45 to 54   \n",
       "2  436.510631   NaN  436.510631       1.0  436.510631        3  Age 25 to 34   \n",
       "3  196.349347   NaN  196.349347       1.0  196.349347        6  Age 18 to 24   \n",
       "4  436.510631   NaN  436.510631       1.0  436.510631        3  Age 25 to 34   \n",
       "\n",
       "  _IMPRACE _IMPNPH                                           _IMPEDUC  \\\n",
       "0        D     NaN         College 4 years or more (College graduate)   \n",
       "1        D     NaN  College 1 year to 3 years (Some college or tec...   \n",
       "2        D     NaN         College 4 years or more (College graduate)   \n",
       "3        D     NaN             Grade 12 or GED (High school graduate)   \n",
       "4        D     NaN         College 4 years or more (College graduate)   \n",
       "\n",
       "        _IMPMRTL           _IMPHOME  O_STATE _CHISPNC _CRACE1 _CPRACE  \\\n",
       "0  Never married               Rent  Alabama        D       D       D   \n",
       "1      Separated  Other arrangement  Alabama        D       D       D   \n",
       "2  Never married               Rent  Alabama        D       D       D   \n",
       "3  Never married               Rent   Alaska        D       D       D   \n",
       "4  Never married               Rent   Alaska        D       D       D   \n",
       "\n",
       "  _IMPCAGE _IMPCRAC _IMPCSEX  _RAWCH  _WT2CH  _CLCM1V1  _CLCM2V1  _CLCM3V1  \\\n",
       "0        D        D  Missing     NaN     NaN       NaN       NaN       NaN   \n",
       "1        D        D  Missing     NaN     NaN       NaN       NaN       NaN   \n",
       "2        D        D  Missing     NaN     NaN       NaN       NaN       NaN   \n",
       "3        D        D  Missing     NaN     NaN       NaN       NaN       NaN   \n",
       "4        D        D  Missing     NaN     NaN       NaN       NaN       NaN   \n",
       "\n",
       "   _CLCM4V1  _CLCM5V1  _CLCWTV1           _DUALUSE  _DUALCOR  _LLCPM01  \\\n",
       "0       NaN       NaN       NaN  No Dual Phone Use       NaN         2   \n",
       "1       NaN       NaN       NaN  No Dual Phone Use       NaN        11   \n",
       "2       NaN       NaN       NaN  No Dual Phone Use       NaN         9   \n",
       "3       NaN       NaN       NaN  No Dual Phone Use       NaN         1   \n",
       "4       NaN       NaN       NaN  No Dual Phone Use       NaN         9   \n",
       "\n",
       "   _LLCPM02  _LLCPM03  _LLCPM04  _LLCPM05  _LLCPM06  _LLCPM07  _LLCPM08  \\\n",
       "0         1         4         2         2         1         1         1   \n",
       "1         2         3         3         2         6         5         1   \n",
       "2         2         4         2         2         6         3         1   \n",
       "3         1         2         2         2         1         1         1   \n",
       "4         3         4         2         2         8         3         1   \n",
       "\n",
       "   _LLCPM09  _LLCPM10  _LLCPM11  _LLCPM12  _LLCPM13  _LLCPM14  _LLCPM15  \\\n",
       "0         7        42        13        18         6        16        33   \n",
       "1         7        44        14        19         6        17        35   \n",
       "2         3        19         6         6         4        11        25   \n",
       "3         6        34        11        16        10        30        58   \n",
       "4         3        19         6         7         4        11        25   \n",
       "\n",
       "   _LLCPM16      _LLCPWT  _LCM01V1  _LCM02V1  _LCM03V1  _LCM04V1  _LCM05V1  \\\n",
       "0        11  2117.541967       NaN       NaN       NaN       NaN       NaN   \n",
       "1        12  2230.075513       NaN       NaN       NaN       NaN       NaN   \n",
       "2         8  1205.094503       NaN       NaN       NaN       NaN       NaN   \n",
       "3        19  1776.406100       NaN       NaN       NaN       NaN       NaN   \n",
       "4         8  1273.934863       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "   _LCM06V1  _LCM07V1  _LCM08V1  _LCPWTV1  _LCM01V2  _LCM02V2  _LCM03V2  \\\n",
       "0       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "1       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "2       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "3       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "4       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "   _LCM04V2  _LCM05V2  _LCM06V2  _LCM07V2  _LCM08V2  _LCM09V2  _LCM10V2  \\\n",
       "0       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "1       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "2       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "3       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "4       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "   _LCM11V2  _LCM12V2  _LCPWTV2                _RFHLTH  \\\n",
       "0       NaN       NaN       NaN  Good or Better Health   \n",
       "1       NaN       NaN       NaN  Good or Better Health   \n",
       "2       NaN       NaN       NaN  Good or Better Health   \n",
       "3       NaN       NaN       NaN  Good or Better Health   \n",
       "4       NaN       NaN       NaN  Good or Better Health   \n",
       "\n",
       "                           _HCVU651 _RFHYPE5  \\\n",
       "0         Have health care coverage      Yes   \n",
       "1         Have health care coverage      Yes   \n",
       "2         Have health care coverage       No   \n",
       "3  Do not have health care coverage       No   \n",
       "4         Have health care coverage       No   \n",
       "\n",
       "                                  _CHOLCHK  _RFCHOL  \\\n",
       "0  Had cholesterol checked in past 5 years       No   \n",
       "1  Had cholesterol checked in past 5 years       No   \n",
       "2  Had cholesterol checked in past 5 years      Yes   \n",
       "3   Don't know/Not Sure Or Refused/Missing  Missing   \n",
       "4       Have never had cholesterol checked  Missing   \n",
       "\n",
       "                            _MICHD _LTASTH1 _CASTHM1 _ASTHMS1  \\\n",
       "0  Did not report having MI or CHD       No       No    Never   \n",
       "1             Not asked or Missing       No       No    Never   \n",
       "2  Did not report having MI or CHD       No       No    Never   \n",
       "3  Did not report having MI or CHD       No       No    Never   \n",
       "4  Did not report having MI or CHD       No       No    Never   \n",
       "\n",
       "                       _DRDXAR1 _MRACE1 _M_RACE _HISPANC _RACE _RACEG21  \\\n",
       "0  Not diagnosed with arthritis       D       D        D     D        D   \n",
       "1  Not diagnosed with arthritis       D       D        D     D        D   \n",
       "2  Not diagnosed with arthritis       D       D        D     D        D   \n",
       "3  Not diagnosed with arthritis       D       D        D     D        D   \n",
       "4  Not diagnosed with arthritis       D       D        D     D        D   \n",
       "\n",
       "  _RACEGR3 _RACE_G1      _AGEG5YR      _AGE65YR                _AGE80  \\\n",
       "0        D        D  Age 30 to 34  Age 18 to 64  Imputed Age 30 to 34   \n",
       "1        D        D  Age 45 to 49  Age 18 to 64  Imputed Age 45 to 49   \n",
       "2        D        D  Age 30 to 34  Age 18 to 64  Imputed Age 30 to 34   \n",
       "3        D        D  Age 18 to 24  Age 18 to 64  Imputed Age 18 to 24   \n",
       "4        D        D  Age 25 to 29  Age 18 to 64  Imputed Age 25 to 29   \n",
       "\n",
       "         _AGE_G HTIN4 HTM4 WTKG3         _BMI5       _BMI5CAT _RFBMI5  \\\n",
       "0  Age 25 to 34     D    D     D  1 or greater  Normal Weight      No   \n",
       "1  Age 45 to 54     D    D     D  1 or greater          Obese     Yes   \n",
       "2  Age 25 to 34     D    D     D  1 or greater     Overweight     Yes   \n",
       "3  Age 18 to 24     D    D     D  1 or greater     Overweight     Yes   \n",
       "4  Age 25 to 34     D    D     D  1 or greater  Normal Weight      No   \n",
       "\n",
       "                   _CHLDCNT                                     _EDUCAG  \\\n",
       "0  No children in household  Graduated from College or Technical School   \n",
       "1    One child in household        Attended College or Technical School   \n",
       "2  No children in household  Graduated from College or Technical School   \n",
       "3    One child in household                       Graduated High School   \n",
       "4  No children in household  Graduated from College or Technical School   \n",
       "\n",
       "                        _INCOMG      _SMOKER3 _RFSMOK3 DRNKANY5  \\\n",
       "0               $50,000 or more  Never smoked       No      Yes   \n",
       "1   Don't know/Not sure/Missing  Never smoked       No       No   \n",
       "2   Don't know/Not sure/Missing  Never smoked       No      Yes   \n",
       "3   Don't know/Not sure/Missing  Never smoked       No       No   \n",
       "4  $35,000 to less than $50,000  Never smoked       No      Yes   \n",
       "\n",
       "                     DROCDY3_ _RFBING5  _DRNKWEK  _RFDRHV5  FTJUDA1_  \\\n",
       "0     Drink-Occasions per day      Yes       600         1      29.0   \n",
       "1  No Drink-Occasions per day       No         0         1      13.0   \n",
       "2     Drink-Occasions per day       No        70         1       0.0   \n",
       "3  No Drink-Occasions per day       No         0         1       0.0   \n",
       "4     Drink-Occasions per day      Yes       400         1       0.0   \n",
       "\n",
       "   FRUTDA1_  BEANDAY_  GRENDAY_  ORNGDAY_  VEGEDA1_  \\\n",
       "0      29.0       3.0      33.0      10.0      71.0   \n",
       "1      83.0      67.0      50.0      33.0      50.0   \n",
       "2      43.0       0.0      43.0      29.0      43.0   \n",
       "3      50.0       NaN       NaN       NaN       NaN   \n",
       "4     300.0     100.0     200.0      71.0     100.0   \n",
       "\n",
       "                     _MISFRTN                                       _MISVEGN  \\\n",
       "0  No missing fruit responses                 No missing vegetable responses   \n",
       "1  No missing fruit responses                 No missing vegetable responses   \n",
       "2  No missing fruit responses                 No missing vegetable responses   \n",
       "3  No missing fruit responses  Has 1, 2, 3, or 4 missing vegetable responses   \n",
       "4  No missing fruit responses                 No missing vegetable responses   \n",
       "\n",
       "                                 _FRTRESP  \\\n",
       "0  Included - Not Missing Fruit Responses   \n",
       "1  Included - Not Missing Fruit Responses   \n",
       "2  Included - Not Missing Fruit Responses   \n",
       "3  Included - Not Missing Fruit Responses   \n",
       "4  Included - Not Missing Fruit Responses   \n",
       "\n",
       "                                     _VEGRESP  _FRUTSUM  _VEGESUM  \\\n",
       "0  Included - Not Missing Vegetable Responses      58.0     117.0   \n",
       "1  Included - Not Missing Vegetable Responses      96.0     200.0   \n",
       "2  Included - Not Missing Vegetable Responses      43.0     115.0   \n",
       "3  Not Included - Missing Vegetable Responses      50.0       NaN   \n",
       "4  Included - Not Missing Vegetable Responses     300.0     471.0   \n",
       "\n",
       "                                     _FRTLT1  \\\n",
       "0  Consumed fruit less than one time per day   \n",
       "1  Consumed fruit less than one time per day   \n",
       "2  Consumed fruit less than one time per day   \n",
       "3  Consumed fruit less than one time per day   \n",
       "4   Consumed fruit one or more times per day   \n",
       "\n",
       "                                         _VEGLT1  \\\n",
       "0  Consumed vegetables one or more times per day   \n",
       "1  Consumed vegetables one or more times per day   \n",
       "2  Consumed vegetables one or more times per day   \n",
       "3          Don´t know, refused or missing values   \n",
       "4  Consumed vegetables one or more times per day   \n",
       "\n",
       "                                    _FRT16  \\\n",
       "0  Included - Values are in accepted range   \n",
       "1  Included - Values are in accepted range   \n",
       "2  Included - Values are in accepted range   \n",
       "3  Included - Values are in accepted range   \n",
       "4  Included - Values are in accepted range   \n",
       "\n",
       "                                    _VEG23  \\\n",
       "0  Included - Values are in accepted range   \n",
       "1  Included - Values are in accepted range   \n",
       "2  Included - Values are in accepted range   \n",
       "3  Included - Values are in accepted range   \n",
       "4  Included - Values are in accepted range   \n",
       "\n",
       "                                  _FRUITEX  \\\n",
       "0  No missing values and in accepted range   \n",
       "1  No missing values and in accepted range   \n",
       "2  No missing values and in accepted range   \n",
       "3  No missing values and in accepted range   \n",
       "4  No missing values and in accepted range   \n",
       "\n",
       "                                  _VEGETEX                           _TOTINDA  \\\n",
       "0  No missing values and in accepted range  Had physical activity or exercise   \n",
       "1  No missing values and in accepted range  Had physical activity or exercise   \n",
       "2  No missing values and in accepted range  Had physical activity or exercise   \n",
       "3              Missing Vegetable responses  Had physical activity or exercise   \n",
       "4  No missing values and in accepted range  Had physical activity or exercise   \n",
       "\n",
       "   METVL11_  METVL21_  MAXVO2_  FC60_  ACTIN11_  ACTIN21_  PADUR1_  PADUR2_  \\\n",
       "0      60.0      68.0     4130    708       1.0       1.0     30.0     45.0   \n",
       "1      60.0      35.0     3061    525       2.0       1.0      NaN      NaN   \n",
       "2      60.0      38.0     3690    633       1.0       1.0     90.0     15.0   \n",
       "3      35.0       0.0     5010    859       1.0       0.0     60.0      NaN   \n",
       "4      60.0      50.0     3764    645       1.0       1.0     30.0     40.0   \n",
       "\n",
       "   PAFREQ1_  PAFREQ2_  _MINAC11  _MINAC21  STRFREQ_  PAMISS1_  PAMIN11_  \\\n",
       "0    1000.0     467.0      30.0      21.0    1000.0         0      30.0   \n",
       "1    5833.0    5833.0       NaN       NaN    2333.0         1       NaN   \n",
       "2     467.0     467.0      42.0       7.0       0.0         0      42.0   \n",
       "3       NaN       NaN       NaN       0.0       0.0         1       NaN   \n",
       "4    5000.0    2000.0     150.0      80.0    2000.0         0     150.0   \n",
       "\n",
       "   PAMIN21_  PA1MIN_  PAVIG11_  PAVIG21_  PA1VIGM_  \\\n",
       "0      21.0     51.0       0.0       0.0       0.0   \n",
       "1       NaN      NaN       NaN       0.0       0.0   \n",
       "2       7.0     49.0       0.0       0.0       0.0   \n",
       "3       0.0      0.0       0.0       0.0       0.0   \n",
       "4      80.0    230.0       0.0       0.0       0.0   \n",
       "\n",
       "                               _PACAT1                              _PAINDX1  \\\n",
       "0                Insufficiently Active  Did Not Meet Aerobic Recommendations   \n",
       "1  Don't know/Not Sure/Refused/Missing   Don't know/Not Sure/Refused/Missing   \n",
       "2                Insufficiently Active  Did Not Meet Aerobic Recommendations   \n",
       "3  Don't know/Not Sure/Refused/Missing   Don't know/Not Sure/Refused/Missing   \n",
       "4                               Active          Meet Aerobic Recommendations   \n",
       "\n",
       "                                            _PA150R2  \\\n",
       "0  1-149 minutes  (or vigorous equivalent minutes...   \n",
       "1                Don't know/Not Sure/Refused/Missing   \n",
       "2  1-149 minutes  (or vigorous equivalent minutes...   \n",
       "3                Don't know/Not Sure/Refused/Missing   \n",
       "4  150+ minutes (or vigorous equivalent minutes) ...   \n",
       "\n",
       "                                            _PA300R2  \\\n",
       "0  1-300 minutes  (or vigorous equivalent minutes...   \n",
       "1                Don't know/Not Sure/Refused/Missing   \n",
       "2  1-300 minutes  (or vigorous equivalent minutes...   \n",
       "3                Don't know/Not Sure/Refused/Missing   \n",
       "4  1-300 minutes  (or vigorous equivalent minutes...   \n",
       "\n",
       "                                            _PA30021  \\\n",
       "0  0-300 minutes  (or vigorous equivalent minutes...   \n",
       "1                Don't know/Not Sure/Refused/Missing   \n",
       "2  0-300 minutes  (or vigorous equivalent minutes...   \n",
       "3                Don't know/Not Sure/Refused/Missing   \n",
       "4  0-300 minutes  (or vigorous equivalent minutes...   \n",
       "\n",
       "                                            _PASTRNG  \\\n",
       "0  Did not meet muscle strengthening recommendations   \n",
       "1          Meet muscle strengthening recommendations   \n",
       "2  Did not meet muscle strengthening recommendations   \n",
       "3  Did not meet muscle strengthening recommendations   \n",
       "4          Meet muscle strengthening recommendations   \n",
       "\n",
       "                               _PAREC1                             _PASTAE1  \\\n",
       "0        Did not meet Either Guideline         Did Not Meet Both Guidelines   \n",
       "1  Don't know/Not Sure/Refused/Missing  Don't know/Not Sure/Refused/Missing   \n",
       "2        Did not meet Either Guideline         Did Not Meet Both Guidelines   \n",
       "3  Don't know/Not Sure/Refused/Missing  Don't know/Not Sure/Refused/Missing   \n",
       "4                  Met Both Guidelines                  Met Both Guidelines   \n",
       "\n",
       "                       _LMTACT1                      _LMTWRK1  \\\n",
       "0  Not told they have arthritis  Not told they have arthritis   \n",
       "1  Not told they have arthritis  Not told they have arthritis   \n",
       "2  Not told they have arthritis  Not told they have arthritis   \n",
       "3  Not told they have arthritis  Not told they have arthritis   \n",
       "4  Not told they have arthritis  Not told they have arthritis   \n",
       "\n",
       "                       _LMTSCL1                                _RFSEAT2  \\\n",
       "0  Not told they have arthritis  Always or Almost Always Wear Seat Belt   \n",
       "1  Not told they have arthritis  Always or Almost Always Wear Seat Belt   \n",
       "2  Not told they have arthritis  Always or Almost Always Wear Seat Belt   \n",
       "3  Not told they have arthritis  Always or Almost Always Wear Seat Belt   \n",
       "4  Not told they have arthritis  Always or Almost Always Wear Seat Belt   \n",
       "\n",
       "                      _RFSEAT3          _FLSHOT6          _PNEUMO2 _AIDTST3  \\\n",
       "0  Don't Always Wear Seat Belt  Age Less Than 65  Age Less Than 65      Yes   \n",
       "1        Always Wear Seat Belt  Age Less Than 65  Age Less Than 65      Yes   \n",
       "2        Always Wear Seat Belt  Age Less Than 65  Age Less Than 65      Yes   \n",
       "3        Always Wear Seat Belt  Age Less Than 65  Age Less Than 65       No   \n",
       "4        Always Wear Seat Belt  Age Less Than 65  Age Less Than 65      Yes   \n",
       "\n",
       "               MEDICARE              HLTHCVR1              DELAYMED  \\\n",
       "0  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "1  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "2  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "3  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "4  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "\n",
       "               NOCOV121              LSTCOVRG              DRVISITS  \\\n",
       "0  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "1  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "2  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "3  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "4  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "\n",
       "               MEDSCOST              CARERCVD              MEDBILL1  \\\n",
       "0  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "1  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "2  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "3  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "4  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "\n",
       "               EMPLSTYR              JOBINJMT              DAYSRTRN  \\\n",
       "0  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "1  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "2  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "3  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "4  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "\n",
       "               WHOPAIDT              OTHRPAID              EMPAWARE  \\\n",
       "0  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "1  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "2  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "3  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "4  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "\n",
       "               MISNERVS              MISHOPLS              MISRSTLS  \\\n",
       "0  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "1  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "2  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "3  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "4  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "\n",
       "               MISDEPRD              MISEFFRT              MISWTLES  \\\n",
       "0  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "1  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "2  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "3  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "4  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "\n",
       "               MISNOWRK               MISTMNT              MISTRHLP  \\\n",
       "0  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "1  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "2  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "3  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "4  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "\n",
       "               MISPHLPF              SSBSUGR1              SSBFRUT2  \\\n",
       "0  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "1  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "2  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "3  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "4  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "\n",
       "                HCVHEAR               HCVTEST              HCVLASTT  \\\n",
       "0  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "1  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "2  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "3  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "4  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "\n",
       "               HCVINPTR              HCVINPTO              HCVINPTA  \\\n",
       "0  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "1  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "2  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "3  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "4  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "\n",
       "               HCVPRIMR              HCVPRIMO              HCVPRIMA  \\\n",
       "0  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "1  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "2  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "3  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "4  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "\n",
       "              HEALTHCL1               LIFECHG             LASTDENT1  \\\n",
       "0  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "1  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "2  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "3  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "4  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "\n",
       "              RMVTEETH1              DIFFHEAR              FRUITVEG  \\\n",
       "0  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "1  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "2  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "3  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "4  Not asked or Missing  Not asked or Missing  Not asked or Missing   \n",
       "\n",
       "               NOVEGFRU NOVFOTHR              STRSRENT              STRSMEAL  \\\n",
       "0  Not asked or Missing      NaN  Not asked or Missing  Not asked or Missing   \n",
       "1  Not asked or Missing      NaN  Not asked or Missing  Not asked or Missing   \n",
       "2  Not asked or Missing      NaN  Not asked or Missing  Not asked or Missing   \n",
       "3  Not asked or Missing      NaN  Not asked or Missing  Not asked or Missing   \n",
       "4  Not asked or Missing      NaN  Not asked or Missing  Not asked or Missing   \n",
       "\n",
       "        dsripreg                REGION PPS_1 PPS_3 PPS_8 PPS_9 PPS_14 PPS_16  \\\n",
       "0  New York City   New York City (NYC)    No    No    No    No     No     No   \n",
       "1  New York City   New York City (NYC)    No    No    No    No     No     No   \n",
       "2   Finger Lakes  NYS exclusive of NYC    No    No    No   Yes     No     No   \n",
       "3  North Country  NYS exclusive of NYC    No    No    No    No     No     No   \n",
       "4   Finger Lakes  NYS exclusive of NYC    No    No    No   Yes     No     No   \n",
       "\n",
       "  PPS_19 PPS_20 PPS_21 PPS_22 PPS_23 PPS_25 PPS_27 PPS_32 PPS_33 PPS_34  \\\n",
       "0     No     No     No     No     No    Yes     No     No     No    Yes   \n",
       "1     No     No     No     No     No    Yes     No     No     No    Yes   \n",
       "2     No     No     No     No     No     No     No     No     No     No   \n",
       "3     No     No     No     No    Yes     No     No     No     No     No   \n",
       "4     No     No     No     No     No     No     No     No     No     No   \n",
       "\n",
       "  PPS_36 PPS_39 PPS_40 PPS_43 PPS_44 PPS_45 PPS_46 PPS_48 PPS_52 childage  \\\n",
       "0     No    Yes     No     No     No     No     No     No    Yes        D   \n",
       "1     No    Yes     No     No     No     No     No     No    Yes        D   \n",
       "2     No     No     No     No     No     No     No     No     No        D   \n",
       "3     No     No     No     No     No     No     No     No     No        D   \n",
       "4     No     No     No     No     No     No     No     No     No        D   \n",
       "\n",
       "                                            cracorg1 _prace1 mracasc1 _impcty  \\\n",
       "0  Data do not meet the criteria for statistical ...       D        D       D   \n",
       "1  Data do not meet the criteria for statistical ...       D        D       D   \n",
       "2  Data do not meet the criteria for statistical ...       D        D       D   \n",
       "3  Data do not meet the criteria for statistical ...       D        D       D   \n",
       "4  Data do not meet the criteria for statistical ...       D        D       D   \n",
       "\n",
       "                                            mracorg1  \n",
       "0  Data do not meet the criteria for statistical ...  \n",
       "1  Data do not meet the criteria for statistical ...  \n",
       "2  Data do not meet the criteria for statistical ...  \n",
       "3  Data do not meet the criteria for statistical ...  \n",
       "4  Data do not meet the criteria for statistical ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check that the data loaded in is in the correct format\n",
    "pd.set_option('display.max_columns', 500)\n",
    "brfss_2015_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qay9KFf4gg0K"
   },
   "source": [
    "### Select Relevant Subset of Features\n",
    "\n",
    "The dataset originally has 330 features (columns), but based on heart disease research regarding factors influencing heart disease, only select features are included in this analysis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jxXwUYlBitL3"
   },
   "source": [
    "#### Important Risk Factors\n",
    "Research in the field has identified the following as **important risk factors** for heart disease (not in strict order of importance):\n",
    "\n",
    "*   blood pressure (high)\n",
    "*   cholesterol (high)\n",
    "*   smoking\n",
    "*   diabetes\n",
    "*   obesity\n",
    "*   age\n",
    "*   sex\n",
    "*   race\n",
    "*   diet\n",
    "*   exercise\n",
    "*   alcohol consumption\n",
    "*   BMI\n",
    "*   Household Income\n",
    "*   Marital Status\n",
    "*   Sleep\n",
    "*   Time since last checkup\n",
    "*   Education\n",
    "*   Health care coverage\n",
    "*   Mental Health\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FxTFj35AiyjD"
   },
   "source": [
    "#### Selected Subset of Features from BRFSS 2015\n",
    "Given these risk factors, I tried to select features (columns/questions) in the BRFSS related to these risk factors. To help understand what the columns mean, I consult the BRFSS 2015 Codebook to see the questions and information about the questions. I try to match the variable names in the codebook to the variable names in the dataset I downloaded from Kaggle. I also reference some of the same features chosen for a research paper by Zidian Xie et al for *Building Risk Prediction Models for Type 2 Diabetes Using Machine Learning Techniques* using the 2014 BRFSS. Diabetes and Heart Disease outcomes are strongly correlated, with the primary cause of death for diabetics being heart disease complications. Given this information, it is a useful starting point.\n",
    "\n",
    "**BRFSS 2015 Codebook:** https://www.cdc.gov/brfss/annual_data/2015/pdf/codebook15_llcp.pdf\n",
    "\n",
    "**Relevant Research Paper using BRFSS for Diabetes ML:** https://www.cdc.gov/pcd/issues/2019/19_0109.htm\n",
    "\n",
    "\n",
    "The **selected features** from the BRFSS 2015 dataset are:\n",
    "\n",
    "**Response Variable / Dependent Variable:**\n",
    "*   Respondents that have ever reported having coronary heart disease (CHD) or myocardial infarction (MI) --> _MICHD\n",
    "\n",
    "\n",
    "**Independent Variables:**\n",
    "\n",
    "**High Blood Pressure**\n",
    "*   Adults who have been told they have high blood pressure by a doctor, nurse, or other health professional --> _RFHYPE5\n",
    "\n",
    "**High Cholesterol**\n",
    "*   Have you EVER been told by a doctor, nurse or other health professional that your blood cholesterol is high? --> TOLDHI2\n",
    "*   Cholesterol check within past five years --> _CHOLCHK\n",
    "\n",
    "**BMI**\n",
    "*   Body Mass Index (BMI) --> _BMI5\n",
    "\n",
    "**Smoking**\n",
    "*   Have you smoked at least 100 cigarettes in your entire life? [Note: 5 packs = 100 cigarettes] --> SMOKE100\n",
    "\n",
    "**Other Chronic Health Conditions**\n",
    "*   (Ever told) you had a stroke. --> CVDSTRK3\n",
    "*   (Ever told) you have diabetes (If \"Yes\" and respondent is female, ask \"Was this only when you were pregnant?\". If Respondent says pre-diabetes or borderline diabetes, use response code 4.) --> DIABETE3\n",
    "\n",
    "**Physical Activity**\n",
    "*   Adults who reported doing physical activity or exercise during the past 30 days other than their regular job --> _TOTINDA\n",
    "\n",
    "**Diet**\n",
    "*   Consume Fruit 1 or more times per day --> _FRTLT1\n",
    "*   Consume Vegetables 1 or more times per day --> _VEGLT1\n",
    "\n",
    "**Alcohol Consumption**\n",
    "*   Heavy drinkers (adult men having more than 14 drinks per week and adult women having more than 7 drinks per week) --> _RFDRHV5\n",
    "\n",
    "**Health Care**\n",
    "*   Do you have any kind of health care coverage, including health insurance, prepaid plans such as HMOs, or government plans such as Medicare, or Indian Health Service?  --> HLTHPLN1\n",
    "*   Was there a time in the past 12 months when you needed to see a doctor but could not because of cost? --> MEDCOST\n",
    "\n",
    "**Health General and Mental Health**\n",
    "*   Would you say that in general your health is: --> GENHLTH\n",
    "*   Now thinking about your mental health, which includes stress, depression, and problems with emotions, for how many days during the past 30 days was your mental health not good? --> MENTHLTH\n",
    "*   Now thinking about your physical health, which includes physical illness and injury, for how many days during the past 30 days was your physical health not good? --> PHYSHLTH\n",
    "*   Do you have serious difficulty walking or climbing stairs? --> DIFFWALK\n",
    "\n",
    "**Demographics**\n",
    "*   Indicate sex of respondent. --> SEX\n",
    "*   Fourteen-level age category --> _AGEG5YR\n",
    "*   What is the highest grade or year of school you completed? --> EDUCA\n",
    "*   Is your annual household income from all sources: (If respondent refuses at any income level, code \"Refused.\") --> INCOME2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EGQb0kEQHjpG"
   },
   "source": [
    "####Get Subset of Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "4BmPHgdSgT2w"
   },
   "outputs": [],
   "source": [
    "# select specific columns\n",
    "brfss_df_selected = brfss_2015_dataset[['_MICHD', \n",
    "                                         '_RFHYPE5',  \n",
    "                                         'TOLDHI2', '_CHOLCHK', \n",
    "                                         '_BMI5','_BMI5CAT', \n",
    "                                         'SMOKE100', \n",
    "                                         'CVDSTRK3', 'DIABETE3', \n",
    "                                         '_TOTINDA', \n",
    "                                         '_FRTLT1', '_VEGLT1', \n",
    "                                         '_RFDRHV5', \n",
    "                                         'HLTHPLN1', 'MEDCOST', \n",
    "                                         'GENHLTH', 'MENTHLTH', 'PHYSHLTH', 'DIFFWALK', \n",
    "                                         'SEX', '_AGEG5YR', 'EDUCA', 'INCOME2' ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "5ZGWjQoIree7",
    "outputId": "1f99c514-4263-429e-c527-1b9af7e3d0c3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12338, 23)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brfss_df_selected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "id": "XGvPoELQjzUH",
    "outputId": "6750579c-4ace-49c2-c7f9-ea080335cdbe"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_MICHD</th>\n",
       "      <th>_RFHYPE5</th>\n",
       "      <th>TOLDHI2</th>\n",
       "      <th>_CHOLCHK</th>\n",
       "      <th>_BMI5</th>\n",
       "      <th>_BMI5CAT</th>\n",
       "      <th>SMOKE100</th>\n",
       "      <th>CVDSTRK3</th>\n",
       "      <th>DIABETE3</th>\n",
       "      <th>_TOTINDA</th>\n",
       "      <th>_FRTLT1</th>\n",
       "      <th>_VEGLT1</th>\n",
       "      <th>_RFDRHV5</th>\n",
       "      <th>HLTHPLN1</th>\n",
       "      <th>MEDCOST</th>\n",
       "      <th>GENHLTH</th>\n",
       "      <th>MENTHLTH</th>\n",
       "      <th>PHYSHLTH</th>\n",
       "      <th>DIFFWALK</th>\n",
       "      <th>SEX</th>\n",
       "      <th>_AGEG5YR</th>\n",
       "      <th>EDUCA</th>\n",
       "      <th>INCOME2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Did not report having MI or CHD</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Had cholesterol checked in past 5 years</td>\n",
       "      <td>1 or greater</td>\n",
       "      <td>Normal Weight</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Had physical activity or exercise</td>\n",
       "      <td>Consumed fruit less than one time per day</td>\n",
       "      <td>Consumed vegetables one or more times per day</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Very good</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>Age 30 to 34</td>\n",
       "      <td>College 4 years or more (College graduate)</td>\n",
       "      <td>$75,000 or more</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Had cholesterol checked in past 5 years</td>\n",
       "      <td>1 or greater</td>\n",
       "      <td>Obese</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Had physical activity or exercise</td>\n",
       "      <td>Consumed fruit less than one time per day</td>\n",
       "      <td>Consumed vegetables one or more times per day</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Good</td>\n",
       "      <td>Number of days</td>\n",
       "      <td>None</td>\n",
       "      <td>No</td>\n",
       "      <td>Female</td>\n",
       "      <td>Age 45 to 49</td>\n",
       "      <td>College 1 year to 3 years (Some college or tec...</td>\n",
       "      <td>Don't know/Not sure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Did not report having MI or CHD</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Had cholesterol checked in past 5 years</td>\n",
       "      <td>1 or greater</td>\n",
       "      <td>Overweight</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Had physical activity or exercise</td>\n",
       "      <td>Consumed fruit less than one time per day</td>\n",
       "      <td>Consumed vegetables one or more times per day</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Very good</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>No</td>\n",
       "      <td>Female</td>\n",
       "      <td>Age 30 to 34</td>\n",
       "      <td>College 4 years or more (College graduate)</td>\n",
       "      <td>Don't know/Not sure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Did not report having MI or CHD</td>\n",
       "      <td>No</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Don't know/Not Sure Or Refused/Missing</td>\n",
       "      <td>1 or greater</td>\n",
       "      <td>Overweight</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Had physical activity or exercise</td>\n",
       "      <td>Consumed fruit less than one time per day</td>\n",
       "      <td>Don´t know, refused or missing values</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>Age 18 to 24</td>\n",
       "      <td>Grade 12 or GED (High school graduate)</td>\n",
       "      <td>Don't know/Not sure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Did not report having MI or CHD</td>\n",
       "      <td>No</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Have never had cholesterol checked</td>\n",
       "      <td>1 or greater</td>\n",
       "      <td>Normal Weight</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Had physical activity or exercise</td>\n",
       "      <td>Consumed fruit one or more times per day</td>\n",
       "      <td>Consumed vegetables one or more times per day</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Number of days</td>\n",
       "      <td>Number of days</td>\n",
       "      <td>No</td>\n",
       "      <td>Female</td>\n",
       "      <td>Age 25 to 29</td>\n",
       "      <td>College 4 years or more (College graduate)</td>\n",
       "      <td>Less than $50,000 ($35,000 to less than $50,000)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            _MICHD _RFHYPE5               TOLDHI2  \\\n",
       "0  Did not report having MI or CHD      Yes                    No   \n",
       "1             Not asked or Missing      Yes                    No   \n",
       "2  Did not report having MI or CHD       No                   Yes   \n",
       "3  Did not report having MI or CHD       No  Not asked or Missing   \n",
       "4  Did not report having MI or CHD       No  Not asked or Missing   \n",
       "\n",
       "                                  _CHOLCHK         _BMI5       _BMI5CAT  \\\n",
       "0  Had cholesterol checked in past 5 years  1 or greater  Normal Weight   \n",
       "1  Had cholesterol checked in past 5 years  1 or greater          Obese   \n",
       "2  Had cholesterol checked in past 5 years  1 or greater     Overweight   \n",
       "3   Don't know/Not Sure Or Refused/Missing  1 or greater     Overweight   \n",
       "4       Have never had cholesterol checked  1 or greater  Normal Weight   \n",
       "\n",
       "  SMOKE100 CVDSTRK3 DIABETE3                           _TOTINDA  \\\n",
       "0       No       No       No  Had physical activity or exercise   \n",
       "1       No      Yes       No  Had physical activity or exercise   \n",
       "2       No       No       No  Had physical activity or exercise   \n",
       "3       No       No       No  Had physical activity or exercise   \n",
       "4       No       No       No  Had physical activity or exercise   \n",
       "\n",
       "                                     _FRTLT1  \\\n",
       "0  Consumed fruit less than one time per day   \n",
       "1  Consumed fruit less than one time per day   \n",
       "2  Consumed fruit less than one time per day   \n",
       "3  Consumed fruit less than one time per day   \n",
       "4   Consumed fruit one or more times per day   \n",
       "\n",
       "                                         _VEGLT1  _RFDRHV5 HLTHPLN1 MEDCOST  \\\n",
       "0  Consumed vegetables one or more times per day         1      Yes      No   \n",
       "1  Consumed vegetables one or more times per day         1      Yes     Yes   \n",
       "2  Consumed vegetables one or more times per day         1      Yes      No   \n",
       "3          Don´t know, refused or missing values         1       No      No   \n",
       "4  Consumed vegetables one or more times per day         1      Yes      No   \n",
       "\n",
       "     GENHLTH        MENTHLTH        PHYSHLTH DIFFWALK     SEX      _AGEG5YR  \\\n",
       "0  Very good            None            None       No    Male  Age 30 to 34   \n",
       "1       Good  Number of days            None       No  Female  Age 45 to 49   \n",
       "2  Very good            None            None       No  Female  Age 30 to 34   \n",
       "3  Excellent            None            None       No    Male  Age 18 to 24   \n",
       "4  Excellent  Number of days  Number of days       No  Female  Age 25 to 29   \n",
       "\n",
       "                                               EDUCA  \\\n",
       "0         College 4 years or more (College graduate)   \n",
       "1  College 1 year to 3 years (Some college or tec...   \n",
       "2         College 4 years or more (College graduate)   \n",
       "3             Grade 12 or GED (High school graduate)   \n",
       "4         College 4 years or more (College graduate)   \n",
       "\n",
       "                                            INCOME2  \n",
       "0                                   $75,000 or more  \n",
       "1                               Don't know/Not sure  \n",
       "2                               Don't know/Not sure  \n",
       "3                               Don't know/Not sure  \n",
       "4  Less than $50,000 ($35,000 to less than $50,000)  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brfss_df_selected.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iRPUB2I1zdjl"
   },
   "source": [
    "### Cleaning the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "unlVkPjf0zh7"
   },
   "source": [
    "####Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "ROIt4LK6kRln",
    "outputId": "41153e6e-eeac-4068-cefe-339f29f49d2f"
   },
   "outputs": [],
   "source": [
    "brfss_df_selected.to_csv('export_report_v1.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "brfss_df_diabet_selected = brfss_2015_dataset[['GENHLTH', \n",
    "                                         '_AGEG5YR',  \n",
    "                                         '_BMI5CAT', 'CHECKUP1', \n",
    "                                         'INCOME2', \n",
    "                                         'EMPLOY1', \n",
    "                                         'SEX', 'MARITAL', \n",
    "                                         '_EDUCAG', \n",
    "                                         'CVDCRHD4', 'HLTHCVR1', \n",
    "                                         'MENTHLTH', \n",
    "                                         'CHCKIDNY', 'USEEQUIP', \n",
    "                                         '_TOTINDA', 'ADDEPEV2', 'RENTHOM1', 'EXERANY2', \n",
    "                                         'BLIND', 'DECIDE', 'HLTHPLN1', 'DIABETE3','_SMOKER3' ]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GENHLTH</th>\n",
       "      <th>_AGEG5YR</th>\n",
       "      <th>_BMI5CAT</th>\n",
       "      <th>CHECKUP1</th>\n",
       "      <th>INCOME2</th>\n",
       "      <th>EMPLOY1</th>\n",
       "      <th>SEX</th>\n",
       "      <th>MARITAL</th>\n",
       "      <th>_EDUCAG</th>\n",
       "      <th>CVDCRHD4</th>\n",
       "      <th>HLTHCVR1</th>\n",
       "      <th>MENTHLTH</th>\n",
       "      <th>CHCKIDNY</th>\n",
       "      <th>USEEQUIP</th>\n",
       "      <th>_TOTINDA</th>\n",
       "      <th>ADDEPEV2</th>\n",
       "      <th>RENTHOM1</th>\n",
       "      <th>EXERANY2</th>\n",
       "      <th>BLIND</th>\n",
       "      <th>DECIDE</th>\n",
       "      <th>HLTHPLN1</th>\n",
       "      <th>DIABETE3</th>\n",
       "      <th>_SMOKER3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Very good</td>\n",
       "      <td>Age 30 to 34</td>\n",
       "      <td>Normal Weight</td>\n",
       "      <td>Within past 2 years (1 year but less than 2 ye...</td>\n",
       "      <td>$75,000 or more</td>\n",
       "      <td>Employed for wages</td>\n",
       "      <td>Male</td>\n",
       "      <td>Never married</td>\n",
       "      <td>Graduated from College or Technical School</td>\n",
       "      <td>No</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>None</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Had physical activity or exercise</td>\n",
       "      <td>No</td>\n",
       "      <td>Rent</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Never smoked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good</td>\n",
       "      <td>Age 45 to 49</td>\n",
       "      <td>Obese</td>\n",
       "      <td>Within past year (anytime less than 12 months ...</td>\n",
       "      <td>Don't know/Not sure</td>\n",
       "      <td>Employed for wages</td>\n",
       "      <td>Female</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Attended College or Technical School</td>\n",
       "      <td>No</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Number of days</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Had physical activity or exercise</td>\n",
       "      <td>No</td>\n",
       "      <td>Other arrangement</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Never smoked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Very good</td>\n",
       "      <td>Age 30 to 34</td>\n",
       "      <td>Overweight</td>\n",
       "      <td>Within past year (anytime less than 12 months ...</td>\n",
       "      <td>Don't know/Not sure</td>\n",
       "      <td>Employed for wages</td>\n",
       "      <td>Female</td>\n",
       "      <td>Never married</td>\n",
       "      <td>Graduated from College or Technical School</td>\n",
       "      <td>No</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>None</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Had physical activity or exercise</td>\n",
       "      <td>No</td>\n",
       "      <td>Rent</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Never smoked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Excellent</td>\n",
       "      <td>Age 18 to 24</td>\n",
       "      <td>Overweight</td>\n",
       "      <td>Within past year (anytime less than 12 months ...</td>\n",
       "      <td>Don't know/Not sure</td>\n",
       "      <td>Employed for wages</td>\n",
       "      <td>Male</td>\n",
       "      <td>Never married</td>\n",
       "      <td>Graduated High School</td>\n",
       "      <td>No</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>None</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Had physical activity or exercise</td>\n",
       "      <td>No</td>\n",
       "      <td>Rent</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Never smoked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Excellent</td>\n",
       "      <td>Age 25 to 29</td>\n",
       "      <td>Normal Weight</td>\n",
       "      <td>Within past year (anytime less than 12 months ...</td>\n",
       "      <td>Less than $50,000 ($35,000 to less than $50,000)</td>\n",
       "      <td>Employed for wages</td>\n",
       "      <td>Female</td>\n",
       "      <td>Never married</td>\n",
       "      <td>Graduated from College or Technical School</td>\n",
       "      <td>No</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Number of days</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Had physical activity or exercise</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Rent</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Never smoked</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     GENHLTH      _AGEG5YR       _BMI5CAT  \\\n",
       "0  Very good  Age 30 to 34  Normal Weight   \n",
       "1       Good  Age 45 to 49          Obese   \n",
       "2  Very good  Age 30 to 34     Overweight   \n",
       "3  Excellent  Age 18 to 24     Overweight   \n",
       "4  Excellent  Age 25 to 29  Normal Weight   \n",
       "\n",
       "                                            CHECKUP1  \\\n",
       "0  Within past 2 years (1 year but less than 2 ye...   \n",
       "1  Within past year (anytime less than 12 months ...   \n",
       "2  Within past year (anytime less than 12 months ...   \n",
       "3  Within past year (anytime less than 12 months ...   \n",
       "4  Within past year (anytime less than 12 months ...   \n",
       "\n",
       "                                            INCOME2             EMPLOY1  \\\n",
       "0                                   $75,000 or more  Employed for wages   \n",
       "1                               Don't know/Not sure  Employed for wages   \n",
       "2                               Don't know/Not sure  Employed for wages   \n",
       "3                               Don't know/Not sure  Employed for wages   \n",
       "4  Less than $50,000 ($35,000 to less than $50,000)  Employed for wages   \n",
       "\n",
       "      SEX        MARITAL                                     _EDUCAG CVDCRHD4  \\\n",
       "0    Male  Never married  Graduated from College or Technical School       No   \n",
       "1  Female      Separated        Attended College or Technical School       No   \n",
       "2  Female  Never married  Graduated from College or Technical School       No   \n",
       "3    Male  Never married                       Graduated High School       No   \n",
       "4  Female  Never married  Graduated from College or Technical School       No   \n",
       "\n",
       "               HLTHCVR1        MENTHLTH CHCKIDNY USEEQUIP  \\\n",
       "0  Not asked or Missing            None       No       No   \n",
       "1  Not asked or Missing  Number of days       No       No   \n",
       "2  Not asked or Missing            None       No       No   \n",
       "3  Not asked or Missing            None       No       No   \n",
       "4  Not asked or Missing  Number of days       No       No   \n",
       "\n",
       "                            _TOTINDA ADDEPEV2           RENTHOM1 EXERANY2  \\\n",
       "0  Had physical activity or exercise       No               Rent      Yes   \n",
       "1  Had physical activity or exercise       No  Other arrangement      Yes   \n",
       "2  Had physical activity or exercise       No               Rent      Yes   \n",
       "3  Had physical activity or exercise       No               Rent      Yes   \n",
       "4  Had physical activity or exercise      Yes               Rent      Yes   \n",
       "\n",
       "  BLIND DECIDE HLTHPLN1 DIABETE3      _SMOKER3  \n",
       "0    No     No      Yes       No  Never smoked  \n",
       "1    No     No      Yes       No  Never smoked  \n",
       "2    No     No      Yes       No  Never smoked  \n",
       "3    No     No       No       No  Never smoked  \n",
       "4    No     No      Yes       No  Never smoked  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brfss_df_diabet_selected.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "brfss_df_diabet_selected.to_csv('export_report_v2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STOP HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12338, 23)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Drop Missing Values - knocks 100,000 rows out right away\n",
    "brfss_df_selected = brfss_df_selected.dropna()\n",
    "brfss_df_selected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "id": "I0KxsYALyYWN",
    "outputId": "01dc72ca-8470-4c01-b35b-9c0646fea43e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_MICHD</th>\n",
       "      <th>_RFHYPE5</th>\n",
       "      <th>TOLDHI2</th>\n",
       "      <th>_CHOLCHK</th>\n",
       "      <th>_BMI5</th>\n",
       "      <th>_BMI5CAT</th>\n",
       "      <th>SMOKE100</th>\n",
       "      <th>CVDSTRK3</th>\n",
       "      <th>DIABETE3</th>\n",
       "      <th>_TOTINDA</th>\n",
       "      <th>_FRTLT1</th>\n",
       "      <th>_VEGLT1</th>\n",
       "      <th>_RFDRHV5</th>\n",
       "      <th>HLTHPLN1</th>\n",
       "      <th>MEDCOST</th>\n",
       "      <th>GENHLTH</th>\n",
       "      <th>MENTHLTH</th>\n",
       "      <th>PHYSHLTH</th>\n",
       "      <th>DIFFWALK</th>\n",
       "      <th>SEX</th>\n",
       "      <th>_AGEG5YR</th>\n",
       "      <th>EDUCA</th>\n",
       "      <th>INCOME2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Did not report having MI or CHD</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Had cholesterol checked in past 5 years</td>\n",
       "      <td>1 or greater</td>\n",
       "      <td>Normal Weight</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Had physical activity or exercise</td>\n",
       "      <td>Consumed fruit less than one time per day</td>\n",
       "      <td>Consumed vegetables one or more times per day</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Very good</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>Age 30 to 34</td>\n",
       "      <td>College 4 years or more (College graduate)</td>\n",
       "      <td>$75,000 or more</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Had cholesterol checked in past 5 years</td>\n",
       "      <td>1 or greater</td>\n",
       "      <td>Obese</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Had physical activity or exercise</td>\n",
       "      <td>Consumed fruit less than one time per day</td>\n",
       "      <td>Consumed vegetables one or more times per day</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Good</td>\n",
       "      <td>Number of days</td>\n",
       "      <td>None</td>\n",
       "      <td>No</td>\n",
       "      <td>Female</td>\n",
       "      <td>Age 45 to 49</td>\n",
       "      <td>College 1 year to 3 years (Some college or tec...</td>\n",
       "      <td>Don't know/Not sure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Did not report having MI or CHD</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Had cholesterol checked in past 5 years</td>\n",
       "      <td>1 or greater</td>\n",
       "      <td>Overweight</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Had physical activity or exercise</td>\n",
       "      <td>Consumed fruit less than one time per day</td>\n",
       "      <td>Consumed vegetables one or more times per day</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Very good</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>No</td>\n",
       "      <td>Female</td>\n",
       "      <td>Age 30 to 34</td>\n",
       "      <td>College 4 years or more (College graduate)</td>\n",
       "      <td>Don't know/Not sure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Did not report having MI or CHD</td>\n",
       "      <td>No</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Don't know/Not Sure Or Refused/Missing</td>\n",
       "      <td>1 or greater</td>\n",
       "      <td>Overweight</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Had physical activity or exercise</td>\n",
       "      <td>Consumed fruit less than one time per day</td>\n",
       "      <td>Don´t know, refused or missing values</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>Age 18 to 24</td>\n",
       "      <td>Grade 12 or GED (High school graduate)</td>\n",
       "      <td>Don't know/Not sure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Did not report having MI or CHD</td>\n",
       "      <td>No</td>\n",
       "      <td>Not asked or Missing</td>\n",
       "      <td>Have never had cholesterol checked</td>\n",
       "      <td>1 or greater</td>\n",
       "      <td>Normal Weight</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Had physical activity or exercise</td>\n",
       "      <td>Consumed fruit one or more times per day</td>\n",
       "      <td>Consumed vegetables one or more times per day</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Number of days</td>\n",
       "      <td>Number of days</td>\n",
       "      <td>No</td>\n",
       "      <td>Female</td>\n",
       "      <td>Age 25 to 29</td>\n",
       "      <td>College 4 years or more (College graduate)</td>\n",
       "      <td>Less than $50,000 ($35,000 to less than $50,000)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            _MICHD _RFHYPE5               TOLDHI2  \\\n",
       "0  Did not report having MI or CHD      Yes                    No   \n",
       "1             Not asked or Missing      Yes                    No   \n",
       "2  Did not report having MI or CHD       No                   Yes   \n",
       "3  Did not report having MI or CHD       No  Not asked or Missing   \n",
       "4  Did not report having MI or CHD       No  Not asked or Missing   \n",
       "\n",
       "                                  _CHOLCHK         _BMI5       _BMI5CAT  \\\n",
       "0  Had cholesterol checked in past 5 years  1 or greater  Normal Weight   \n",
       "1  Had cholesterol checked in past 5 years  1 or greater          Obese   \n",
       "2  Had cholesterol checked in past 5 years  1 or greater     Overweight   \n",
       "3   Don't know/Not Sure Or Refused/Missing  1 or greater     Overweight   \n",
       "4       Have never had cholesterol checked  1 or greater  Normal Weight   \n",
       "\n",
       "  SMOKE100 CVDSTRK3 DIABETE3                           _TOTINDA  \\\n",
       "0       No       No       No  Had physical activity or exercise   \n",
       "1       No      Yes       No  Had physical activity or exercise   \n",
       "2       No       No       No  Had physical activity or exercise   \n",
       "3       No       No       No  Had physical activity or exercise   \n",
       "4       No       No       No  Had physical activity or exercise   \n",
       "\n",
       "                                     _FRTLT1  \\\n",
       "0  Consumed fruit less than one time per day   \n",
       "1  Consumed fruit less than one time per day   \n",
       "2  Consumed fruit less than one time per day   \n",
       "3  Consumed fruit less than one time per day   \n",
       "4   Consumed fruit one or more times per day   \n",
       "\n",
       "                                         _VEGLT1  _RFDRHV5 HLTHPLN1 MEDCOST  \\\n",
       "0  Consumed vegetables one or more times per day         1      Yes      No   \n",
       "1  Consumed vegetables one or more times per day         1      Yes     Yes   \n",
       "2  Consumed vegetables one or more times per day         1      Yes      No   \n",
       "3          Don´t know, refused or missing values         1       No      No   \n",
       "4  Consumed vegetables one or more times per day         1      Yes      No   \n",
       "\n",
       "     GENHLTH        MENTHLTH        PHYSHLTH DIFFWALK     SEX      _AGEG5YR  \\\n",
       "0  Very good            None            None       No    Male  Age 30 to 34   \n",
       "1       Good  Number of days            None       No  Female  Age 45 to 49   \n",
       "2  Very good            None            None       No  Female  Age 30 to 34   \n",
       "3  Excellent            None            None       No    Male  Age 18 to 24   \n",
       "4  Excellent  Number of days  Number of days       No  Female  Age 25 to 29   \n",
       "\n",
       "                                               EDUCA  \\\n",
       "0         College 4 years or more (College graduate)   \n",
       "1  College 1 year to 3 years (Some college or tec...   \n",
       "2         College 4 years or more (College graduate)   \n",
       "3             Grade 12 or GED (High school graduate)   \n",
       "4         College 4 years or more (College graduate)   \n",
       "\n",
       "                                            INCOME2  \n",
       "0                                   $75,000 or more  \n",
       "1                               Don't know/Not sure  \n",
       "2                               Don't know/Not sure  \n",
       "3                               Don't know/Not sure  \n",
       "4  Less than $50,000 ($35,000 to less than $50,000)  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brfss_df_selected.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JcTDYuv206kn"
   },
   "source": [
    "####Modifying Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "blBecp410Vyw",
    "outputId": "3a014475-81da-4dee-822b-cda1fb200e6b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# _MICHD\n",
    "#Change 2 to 0 because this means did not have MI or CHD\n",
    "brfss_df_selected['_MICHD'] = brfss_df_selected['_MICHD'].replace(['Did not report having MI or CHD','Reported having MI or CHD'], [0,1])\n",
    "brfss_df_selected = brfss_df_selected[brfss_df_selected._MICHD != 'Not asked or Missing']\n",
    "brfss_df_selected._MICHD.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "67919_rQ1JHU",
    "outputId": "778916bb-8b99-4d17-edbf-aacd40cb880b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, \"Don't know/Not Sure/Refused/Missing\"], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1 _RFHYPE5\n",
    "#Change 1 to 0 so it represetnts No high blood pressure and 2 to 1 so it represents high blood pressure\n",
    "brfss_df_selected['_RFHYPE5'] = brfss_df_selected['_RFHYPE5'].replace({'No':0, 'Yes':1})\n",
    "brfss_df_selected = brfss_df_selected[brfss_df_selected._RFHYPE5 != 9]\n",
    "brfss_df_selected._RFHYPE5.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "wZoLGBfq2uOV",
    "outputId": "7434520e-e5bd-4914-af18-bb4e39de35c2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2 TOLDHI2\n",
    "# Change 2 to 0 because it is No\n",
    "# Remove all 7 (dont knows)\n",
    "# Remove all 9 (refused)\n",
    "brfss_df_selected['TOLDHI2'] = brfss_df_selected['TOLDHI2'].replace([\"No\",\"Yes\"],[0,1])\n",
    "brfss_df_selected = brfss_df_selected[brfss_df_selected.TOLDHI2 != \"Don't know/Not Sure\"]\n",
    "brfss_df_selected = brfss_df_selected[brfss_df_selected.TOLDHI2 != 'Not asked or Missing']\n",
    "brfss_df_selected = brfss_df_selected[brfss_df_selected.TOLDHI2 != 'Refused']\n",
    "brfss_df_selected.TOLDHI2.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "6VZOv2BaLZU0",
    "outputId": "a9a30ce0-aded-4209-f465-0cc4602c2052"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, \"Don't know/Not Sure Or Refused/Missing\"], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3 _CHOLCHK\n",
    "# Change 3 to 0 and 2 to 0 for Not checked cholesterol in past 5 years\n",
    "# Remove 9\n",
    "brfss_df_selected['_CHOLCHK'] = brfss_df_selected['_CHOLCHK'].replace([\"Did not have cholesterol checked in past 5 years\",\"Have never had cholesterol checked\",\"Had cholesterol checked in past 5 years\"],[0,0,1])\n",
    "brfss_df_selected = brfss_df_selected[brfss_df_selected._CHOLCHK != \"Don’t know/Not Sure Or Refused/Missing\"]\n",
    "brfss_df_selected._CHOLCHK.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 138
    },
    "id": "j5R-hbiIMhcP",
    "outputId": "19c8b163-dafa-4c43-f48c-d8ae01f7fb32"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Replacement lists must match in length. Expecting 4 got 3 ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-fae1b8c2a43d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#4 _BMI5 (no changes, just note that these are BMI * 100. So for example a BMI of 4018 is really 40.18)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbrfss_df_selected\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_BMI5CAT'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbrfss_df_selected\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_BMI5CAT'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Underweight\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Normal Weight\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Overweight\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Obese\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mbrfss_df_selected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbrfss_df_selected\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbrfss_df_selected\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_BMI5CAT\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"Don’t know/Refused/Missing\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#brfss_df_selected['_BMI5CAT'] = brfss_df_selected['_BMI5CAT'].div(100).round(0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#brfss_df_selected._BMI5CAT.unique()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mreplace\u001b[0;34m(self, to_replace, value, inplace, limit, regex, method)\u001b[0m\n\u001b[1;32m   4513\u001b[0m             \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4514\u001b[0m             \u001b[0mregex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4515\u001b[0;31m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4516\u001b[0m         )\n\u001b[1;32m   4517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mreplace\u001b[0;34m(self, to_replace, value, inplace, limit, regex, method)\u001b[0m\n\u001b[1;32m   6891\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_replace\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6892\u001b[0m                     raise ValueError(\n\u001b[0;32m-> 6893\u001b[0;31m                         \u001b[0;34mf\"Replacement lists must match in length. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6894\u001b[0m                         \u001b[0;34mf\"Expecting {len(to_replace)} got {len(value)} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6895\u001b[0m                     )\n",
      "\u001b[0;31mValueError\u001b[0m: Replacement lists must match in length. Expecting 4 got 3 "
     ]
    }
   ],
   "source": [
    "#4 _BMI5 (no changes, just note that these are BMI * 100. So for example a BMI of 4018 is really 40.18)\n",
    "brfss_df_selected['_BMI5CAT'] = brfss_df_selected['_BMI5CAT'].replace([\"Underweight\",\"Normal Weight\",\"Overweight\",\"Obese\"],[1,2,3])\n",
    "brfss_df_selected = brfss_df_selected[brfss_df_selected._BMI5CAT != \"Don’t know/Refused/Missing\"]\n",
    "#brfss_df_selected['_BMI5CAT'] = brfss_df_selected['_BMI5CAT'].div(100).round(0)\n",
    "#brfss_df_selected._BMI5CAT.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "hinFMXZTNDnk",
    "outputId": "19f544b5-2269-4184-a33d-9fe48f1451cf"
   },
   "outputs": [],
   "source": [
    "#### Burdasin\n",
    "\n",
    "#5 SMOKE100\n",
    "# Change 2 to 0 because it is No\n",
    "# Remove all 7 (dont knows)\n",
    "# Remove all 9 (refused)\n",
    "brfss_df_selected['SMOKE100'] = brfss_df_selected['SMOKE100'].replace({2:0})\n",
    "brfss_df_selected = brfss_df_selected[brfss_df_selected.SMOKE100 != 7]\n",
    "brfss_df_selected = brfss_df_selected[brfss_df_selected.SMOKE100 != 9]\n",
    "brfss_df_selected.SMOKE100.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "9Q5kMiDnNw76",
    "outputId": "45c93e43-469f-4587-abf9-72dddbffe1fa"
   },
   "outputs": [],
   "source": [
    "#6 CVDSTRK3\n",
    "# Change 2 to 0 because it is No\n",
    "# Remove all 7 (dont knows)\n",
    "# Remove all 9 (refused)\n",
    "brfss_df_selected['CVDSTRK3'] = brfss_df_selected['CVDSTRK3'].replace({2:0})\n",
    "brfss_df_selected = brfss_df_selected[brfss_df_selected.CVDSTRK3 != 7]\n",
    "brfss_df_selected = brfss_df_selected[brfss_df_selected.CVDSTRK3 != 9]\n",
    "brfss_df_selected.CVDSTRK3.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "sPztu3fpOH_8",
    "outputId": "4a6d1ccb-747f-4702-d1be-b2886ce1ce30"
   },
   "outputs": [],
   "source": [
    "#7 DIABETE3\n",
    "# going to make this ordinal. 0 is for no diabetes or only during pregnancy, 1 is for pre-diabetes or borderline diabetes, 2 is for yes diabetes\n",
    "# Remove all 7 (dont knows)\n",
    "# Remove all 9 (refused)\n",
    "brfss_df_selected['DIABETE3'] = brfss_df_selected['DIABETE3'].replace({2:0, 3:0, 1:2, 4:1})\n",
    "brfss_df_selected = brfss_df_selected[brfss_df_selected.DIABETE3 != 7]\n",
    "brfss_df_selected = brfss_df_selected[brfss_df_selected.DIABETE3 != 9]\n",
    "brfss_df_selected.DIABETE3.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "aIJqBL3EPiow",
    "outputId": "413a1e5d-9c79-4bb0-daf3-f1a55ff321a3"
   },
   "outputs": [],
   "source": [
    "#8 _TOTINDA\n",
    "# 1 for physical activity\n",
    "# change 2 to 0 for no physical activity\n",
    "# Remove all 9 (don't know/refused)\n",
    "brfss_df_selected['_TOTINDA'] = brfss_df_selected['_TOTINDA'].replace({2:0})\n",
    "brfss_df_selected = brfss_df_selected[brfss_df_selected._TOTINDA != 9]\n",
    "brfss_df_selected._TOTINDA.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "8EYucZDKQSeo",
    "outputId": "7aa76535-7891-4cb2-e4d3-4378d852ba41"
   },
   "outputs": [],
   "source": [
    "#9 _FRTLT1\n",
    "# Change 2 to 0. this means no fruit consumed per day. 1 will mean consumed 1 or more pieces of fruit per day \n",
    "# remove all dont knows and missing 9\n",
    "brfss_df_selected['_FRTLT1'] = brfss_df_selected['_FRTLT1'].replace({2:0})\n",
    "brfss_df_selected = brfss_df_selected[brfss_df_selected._FRTLT1 != 9]\n",
    "brfss_df_selected._FRTLT1.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "MpCGcx_NRAhJ",
    "outputId": "fb8ff83c-9210-4e05-fdcb-7d6d9a0c6d97"
   },
   "outputs": [],
   "source": [
    "#10 _VEGLT1\n",
    "# Change 2 to 0. this means no vegetables consumed per day. 1 will mean consumed 1 or more pieces of vegetable per day \n",
    "# remove all dont knows and missing 9\n",
    "brfss_df_selected['_VEGLT1'] = brfss_df_selected['_VEGLT1'].replace({2:0})\n",
    "brfss_df_selected = brfss_df_selected[brfss_df_selected._VEGLT1 != 9]\n",
    "brfss_df_selected._VEGLT1.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "jEkYqHoDRm4a",
    "outputId": "00d55330-b06d-4f22-8ef4-c9c0d0c72c91"
   },
   "outputs": [],
   "source": [
    "#11 _RFDRHV5\n",
    "# Change 1 to 0 (1 was no for heavy drinking). change all 2 to 1 (2 was yes for heavy drinking)\n",
    "# remove all dont knows and missing 9\n",
    "brfss_df_selected['_RFDRHV5'] = brfss_df_selected['_RFDRHV5'].replace({1:0, 2:1})\n",
    "brfss_df_selected = brfss_df_selected[brfss_df_selected._RFDRHV5 != 9]\n",
    "brfss_df_selected._RFDRHV5.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "dNO16De8SBEt",
    "outputId": "b124b5a5-a503-48c0-fc97-91890e9b5472"
   },
   "outputs": [],
   "source": [
    "#12 HLTHPLN1\n",
    "# 1 is yes, change 2 to 0 because it is No health care access\n",
    "# remove 7 and 9 for don't know or refused\n",
    "brfss_df_selected['HLTHPLN1'] = brfss_df_selected['HLTHPLN1'].replace({2:0})\n",
    "brfss_df_selected = brfss_df_selected[brfss_df_selected.HLTHPLN1 != 7]\n",
    "brfss_df_selected = brfss_df_selected[brfss_df_selected.HLTHPLN1 != 9]\n",
    "brfss_df_selected.HLTHPLN1.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "NgFtHLP8dgdx",
    "outputId": "f798dc89-fbcb-4396-c3dc-65b1561049dc"
   },
   "outputs": [],
   "source": [
    "#13 MEDCOST\n",
    "# Change 2 to 0 for no, 1 is already yes\n",
    "# remove 7 for don/t know and 9 for refused\n",
    "brfss_df_selected['MEDCOST'] = brfss_df_selected['MEDCOST'].replace({2:0})\n",
    "brfss_df_selected = brfss_df_selected[brfss_df_selected.MEDCOST != 7]\n",
    "brfss_df_selected = brfss_df_selected[brfss_df_selected.MEDCOST != 9]\n",
    "brfss_df_selected.MEDCOST.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "deh43iCyeKPW",
    "outputId": "b3a52e98-9ed1-458c-c84d-b4c413f4ad62"
   },
   "outputs": [],
   "source": [
    "#14 GENHLTH\n",
    "# This is an ordinal variable that I want to keep (1 is Excellent -> 5 is Poor)\n",
    "# Remove 7 and 9 for don't know and refused\n",
    "brfss_df_selected = brfss_df_selected[brfss_df_selected.GENHLTH != 7]\n",
    "brfss_df_selected = brfss_df_selected[brfss_df_selected.GENHLTH != 9]\n",
    "brfss_df_selected.GENHLTH.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "id": "Buk40s5ae1Fq",
    "outputId": "0fc2eec4-5b52-43b1-d877-46c0b3f45e16"
   },
   "outputs": [],
   "source": [
    "#15 MENTHLTH\n",
    "# already in days so keep that, scale will be 0-30\n",
    "# change 88 to 0 because it means none (no bad mental health days)\n",
    "# remove 77 and 99 for don't know not sure and refused\n",
    "brfss_df_selected['MENTHLTH'] = brfss_df_selected['MENTHLTH'].replace({88:0})\n",
    "brfss_df_selected = brfss_df_selected[brfss_df_selected.MENTHLTH != 77]\n",
    "brfss_df_selected = brfss_df_selected[brfss_df_selected.MENTHLTH != 99]\n",
    "brfss_df_selected.MENTHLTH.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "id": "Aj52MPd3oy9w",
    "outputId": "15b4415a-7961-4b64-ae03-c3f32689b8de"
   },
   "outputs": [],
   "source": [
    "#16 PHYSHLTH\n",
    "# already in days so keep that, scale will be 0-30\n",
    "# change 88 to 0 because it means none (no bad mental health days)\n",
    "# remove 77 and 99 for don't know not sure and refused\n",
    "brfss_df_selected['PHYSHLTH'] = brfss_df_selected['PHYSHLTH'].replace({88:0})\n",
    "brfss_df_selected = brfss_df_selected[brfss_df_selected.PHYSHLTH != 77]\n",
    "brfss_df_selected = brfss_df_selected[brfss_df_selected.PHYSHLTH != 99]\n",
    "brfss_df_selected.PHYSHLTH.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "TFNUbnyfpUMp",
    "outputId": "b879e78c-fe3a-413d-cf36-38521443bb58"
   },
   "outputs": [],
   "source": [
    "#17 DIFFWALK\n",
    "# change 2 to 0 for no. 1 is already yes\n",
    "# remove 7 and 9 for don't know not sure and refused\n",
    "brfss_df_selected['DIFFWALK'] = brfss_df_selected['DIFFWALK'].replace({2:0})\n",
    "brfss_df_selected = brfss_df_selected[brfss_df_selected.DIFFWALK != 7]\n",
    "brfss_df_selected = brfss_df_selected[brfss_df_selected.DIFFWALK != 9]\n",
    "brfss_df_selected.DIFFWALK.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "SMhII7O0pq2C",
    "outputId": "06b14bb9-1d4a-4135-e9fc-107ae8f0ea83"
   },
   "outputs": [],
   "source": [
    "#18 SEX\n",
    "# in other words - is respondent male (somewhat arbitrarily chose this change because men are at higher risk for heart disease)\n",
    "# change 2 to 0 (female as 0). Male is 1\n",
    "brfss_df_selected['SEX'] = brfss_df_selected['SEX'].replace({2:0})\n",
    "brfss_df_selected.SEX.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "Up4csI8ZqXJe",
    "outputId": "403ac391-3f01-4547-eb98-6c77efd45159"
   },
   "outputs": [],
   "source": [
    "#19 _AGEG5YR\n",
    "# already ordinal. 1 is 18-24 all the way up to 13 wis 80 and older. 5 year increments.\n",
    "# remove 14 because it is don't know or missing\n",
    "brfss_df_selected = brfss_df_selected[brfss_df_selected._AGEG5YR != 14]\n",
    "brfss_df_selected._AGEG5YR.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "xa6x8-JjrNYG",
    "outputId": "052adaf3-80f5-45e0-87ea-094a4e0413cd"
   },
   "outputs": [],
   "source": [
    "#20 EDUCA\n",
    "# This is already an ordinal variable with 1 being never attended school or kindergarten only up to 6 being college 4 years or more\n",
    "# Scale here is 1-6\n",
    "# Remove 9 for refused:\n",
    "brfss_df_selected = brfss_df_selected[brfss_df_selected.EDUCA != 9]\n",
    "brfss_df_selected.EDUCA.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "imr2psFzv0jA",
    "outputId": "2bbb1b86-1c76-4154-e545-aba11262191c"
   },
   "outputs": [],
   "source": [
    "#21 INCOME2\n",
    "# Variable is already ordinal with 1 being less than $10,000 all the way up to 8 being $75,000 or more\n",
    "# Remove 77 and 99 for don't know and refused\n",
    "brfss_df_selected = brfss_df_selected[brfss_df_selected.INCOME2 != 77]\n",
    "brfss_df_selected = brfss_df_selected[brfss_df_selected.INCOME2 != 99]\n",
    "brfss_df_selected.INCOME2.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "YC7WB5jb3DDj",
    "outputId": "4a43b38f-b4ac-4cbc-d6ef-8211c7caab85"
   },
   "outputs": [],
   "source": [
    "#Check the shape of the dataset now: We have 253,680 cleaned rows and 22 columns (1 of which is our dependent variable)\n",
    "brfss_df_selected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "id": "IucXUK1C2ReC",
    "outputId": "1937ad64-2bf7-4311-9724-953d60bbcc0a"
   },
   "outputs": [],
   "source": [
    "#Let's see what the data looks like after Modifying Values\n",
    "brfss_df_selected.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "id": "uWt_1G9gKtUE",
    "outputId": "d80370ca-5baf-4846-ff03-b7731864415b"
   },
   "outputs": [],
   "source": [
    " #Check Class Sizes\n",
    " brfss_df_selected.groupby(['_MICHD']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5kVmXvCHx3Kb"
   },
   "source": [
    "####Make Feature Names More Readable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QAIsY3Offgsw"
   },
   "outputs": [],
   "source": [
    " #Rename the columns to make them more readable\n",
    " brfss = brfss_df_selected.rename(columns = {'_MICHD':'HeartDiseaseorAttack', \n",
    "                                         '_RFHYPE5':'HighBP',  \n",
    "                                         'TOLDHI2':'HighChol', '_CHOLCHK':'CholCheck', \n",
    "                                         '_BMI5':'BMI', \n",
    "                                         'SMOKE100':'Smoker', \n",
    "                                         'CVDSTRK3':'Stroke', 'DIABETE3':'Diabetes', \n",
    "                                         '_TOTINDA':'PhysActivity', \n",
    "                                         '_FRTLT1':'Fruits', '_VEGLT1':\"Veggies\", \n",
    "                                         '_RFDRHV5':'HvyAlcoholConsump', \n",
    "                                         'HLTHPLN1':'AnyHealthcare', 'MEDCOST':'NoDocbcCost', \n",
    "                                         'GENHLTH':'GenHlth', 'MENTHLTH':'MentHlth', 'PHYSHLTH':'PhysHlth', 'DIFFWALK':'DiffWalk', \n",
    "                                         'SEX':'Sex', '_AGEG5YR':'Age', 'EDUCA':'Education', 'INCOME2':'Income' })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "id": "rAE4OwUrpyjm",
    "outputId": "5f35afc1-250d-4209-aee1-b05f79e55370"
   },
   "outputs": [],
   "source": [
    "#See the cleaned dataset with \n",
    "brfss.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "vmBfrX_Ss8cG",
    "outputId": "1eb56b3d-8a7d-40b6-ce41-24fe9e006ea7"
   },
   "outputs": [],
   "source": [
    "#Double check shape of the dataset (rows and columns)\n",
    "brfss.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "id": "GJoX16tY9qq3",
    "outputId": "7d8b0e25-23e8-4553-ed99-85efb24fdf57"
   },
   "outputs": [],
   "source": [
    " #Check how many respondents have had heart disease or a heart attack. Note the class imbalance!\n",
    " brfss.groupby(['HeartDiseaseorAttack']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CJ2CXYf5BimQ"
   },
   "source": [
    "#### Save Finalized Dataset to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6LoL8_01-4pv"
   },
   "outputs": [],
   "source": [
    "#************************************************************************************************\n",
    "brfss.to_csv('brfss2015_cleaned.csv', sep=\",\", index=False)\n",
    "#************************************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jCeBJRyMaGio"
   },
   "source": [
    "#### Get a BALANCED 50-50 Dataset Randomly Selected\n",
    "*  The brfss dataset is clearly imbalanced. When training my models, I get about 90% accuracy on many models with AUC between 70 and 80. This may be caused by the models are learning the distribution in the data. \n",
    "*  To check these concerns, I will create a second dataset with a 50-50 balance for the HeartDiseaseorAttack response variable - just to compare performance. \n",
    "*  To do this, I will take a random sample of 23,893 instances of the 0 (or No heart Disease / Attack) and all of the 23,893 instances of the 1 (or Yes Heart Disease / Attack).\n",
    "* The if the new dataset performs comparably, then I can rest assured that it\n",
    "* With roughly 48,000 datapoints, I hope that this is sufficient to train the model and that the random selection will not greatly change the results. I have the random seed set to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DHLkrTgsaH08"
   },
   "outputs": [],
   "source": [
    "#Separate the 0 and 1\n",
    "\n",
    "#Get the 1s\n",
    "is1 = brfss['HeartDiseaseorAttack'] == 1\n",
    "brfss_5050_1 = brfss[is1]\n",
    "\n",
    "#Get the 0s\n",
    "is0 = brfss['HeartDiseaseorAttack'] == 0\n",
    "brfss_5050_0 = brfss[is0] \n",
    "\n",
    "#Select the 23893 random cases for 0\n",
    "brfss_5050_0_rand1 = brfss_5050_0.take(np.random.permutation(len(brfss_5050_0))[:23893])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Je48a7lshFke"
   },
   "outputs": [],
   "source": [
    "#Append the 23893 1s to the 23893 randomly selected 0s\n",
    "brfss_5050 = brfss_5050_0_rand1.append(brfss_5050_1, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TKcAPE0Vfpyp",
    "outputId": "48271a9e-c38f-440b-edb0-92d7448f9de5"
   },
   "outputs": [],
   "source": [
    "#Check that it worked. Now we have a dataset of 47,786 rows that is equally balanced with 50% 1 and 50% 0 for the target variable HeartDiseaseorAttack\n",
    "brfss_5050"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MklB0DbKicGs",
    "outputId": "d2e4bca9-39fc-49f3-df37-8fbfea23064b"
   },
   "outputs": [],
   "source": [
    "#See the classes are perfectly balanced now\n",
    "brfss_5050.groupby(['HeartDiseaseorAttack']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kWhJLzPfil9Q"
   },
   "outputs": [],
   "source": [
    "#Save the 50-50 balanced dataset to csv\n",
    "\n",
    "#************************************************************************************************\n",
    "brfss_5050.to_csv('brfss2015_5050_cleaned.csv', sep=\",\", index=False)\n",
    "#************************************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LE4FUQGkpihm"
   },
   "source": [
    "#### Also Get a 60-40 Dataset Randomly Selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bnZO1Eojo6Dm",
    "outputId": "d25fe8c8-8cc5-4f9e-f09a-fe831404d5a5"
   },
   "outputs": [],
   "source": [
    "#Also make a 60-40 dataset\n",
    "brfss_6040_0_rand1 = brfss_5050_0.take(np.random.permutation(len(brfss_5050_0))[:47786])\n",
    "brfss_6040 = brfss_6040_0_rand1.append(brfss_5050_1, ignore_index = True)\n",
    "#Save the 6040 balanced dataset to csv\n",
    "#************************************************************************************************\n",
    "brfss_6040.to_csv('brfss2015_6040_cleaned.csv', sep=\",\", index=False)\n",
    "#************************************************************************************************\n",
    "brfss_6040"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rFZ2SN8OByr0"
   },
   "source": [
    "#Part 2: Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GTM7dYfi4UyD"
   },
   "source": [
    "## Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F4NNhL9SHtOr"
   },
   "source": [
    "### Random Forest - w/ Feature Selection - Full Dataset\n",
    "\n",
    "* 10 trees & 50 trees Tested (n_estimator changes)\n",
    "* RF 10 trees - 5-fold cv - with Feature Selection \n",
    ": 0.89 (+/- 0.00)  |   AUC: 0.71 (+/- 0.01)  |   Runtime: 9.93 seconds\n",
    "* RF 50 trees - 5-fold cv - with Feature Selection \n",
    " ACC: 0.89 (+/- 0.00)  |   AUC: 0.74 (+/- 0.01)  |   Runtime: 48.17 seconds\n",
    "* RF 50 trees - 10-fold cv - with Feature Selection \n",
    " ACC: 0.89 (+/- 0.00)  |   AUC: 0.74 (+/- 0.01)  |   Runtime: 103.57 seconds\n",
    "* RF Selected Features: ['BMI', 'GenHlth', 'MentHlth', 'PhysHlth', 'Age', 'Education', 'Income']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OYGWH7zkNV-f",
    "outputId": "886cebb0-59ad-4708-df23-3f82b139331c"
   },
   "outputs": [],
   "source": [
    "#SciKit DSC540 HW1\n",
    "'''created by Casey Bennett 2018, www.CaseyBennett.com'''\n",
    "\n",
    "import sys\n",
    "import csv\n",
    "import math\n",
    "from operator import itemgetter\n",
    "import time\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.feature_selection import RFE, VarianceThreshold, SelectFromModel\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression, mutual_info_classif, chi2\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "from sklearn.preprocessing import KBinsDiscretizer, scale\n",
    "\n",
    "\n",
    "#Handle annoying warnings\n",
    "import warnings, sklearn.exceptions\n",
    "warnings.filterwarnings(\"ignore\", category=sklearn.exceptions.ConvergenceWarning)\n",
    "\n",
    "\n",
    "#############################################################################\n",
    "#\n",
    "# Global parameters\n",
    "#\n",
    "#####################\n",
    "\n",
    "target_idx=0                                        #Index of Target variable\n",
    "cross_val=1                                         #Control Switch for CV                                                                                      \n",
    "norm_target=0                                       #Normalize target switch\n",
    "norm_features=0                                     #Normalize target switch\n",
    "binning=0                                           #Control Switch for Bin Target\n",
    "bin_cnt=2                                           #If bin target, this sets number of classes\n",
    "feat_select=1                                       #Control Switch for Feature Selection\n",
    "fs_type=4                                           #Feature Selection type (1=Stepwise Backwards Removal, 2=Wrapper Select, 3=Univariate Selection)\n",
    "lv_filter=0                                         #Control switch for low variance filter on features\n",
    "feat_start=1                                        #Start column of features\n",
    "\n",
    "#Set global model parameters\n",
    "rand_st=1                                           #Set Random State variable for randomizing splits on runs\n",
    "\n",
    "\n",
    "#############################################################################\n",
    "#\n",
    "# Load Data\n",
    "#\n",
    "#####################\n",
    "\n",
    "file1= csv.reader(open('brfss2015_cleaned.csv'), delimiter=',', quotechar='\"')\n",
    "\n",
    "#Read Header Line\n",
    "header=next(file1)            \n",
    "\n",
    "#Read data\n",
    "data=[]\n",
    "target=[]\n",
    "for row in file1:\n",
    "    #Load Target\n",
    "    if row[target_idx]=='':                         #If target is blank, skip row                       \n",
    "        continue\n",
    "    else:\n",
    "        target.append(float(row[target_idx]))       #If pre-binned class, change float to int\n",
    "\n",
    "    #Load row into temp array, cast columns  \n",
    "    temp=[]\n",
    "                 \n",
    "    for j in range(feat_start,len(header)):\n",
    "        if row[j]=='':\n",
    "            temp.append(float())\n",
    "        else:\n",
    "            temp.append(float(row[j]))\n",
    "\n",
    "    #Load temp into Data array\n",
    "    data.append(temp)\n",
    "  \n",
    "#Test Print\n",
    "print(header)\n",
    "print(len(target),len(data))\n",
    "print('\\n')\n",
    "\n",
    "data_np=np.asarray(data)\n",
    "target_np=np.asarray(target)\n",
    "\n",
    "\n",
    "#############################################################################\n",
    "#\n",
    "# Preprocess data\n",
    "#\n",
    "##########################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#############################################################################\n",
    "#\n",
    "# Feature Selection\n",
    "#\n",
    "##########################################\n",
    "\n",
    "#Low Variance Filter\n",
    "if lv_filter==1:\n",
    "    print('--LOW VARIANCE FILTER ON--', '\\n')\n",
    "    \n",
    "    #LV Threshold\n",
    "    sel = VarianceThreshold(threshold=0.5)                                          #Removes any feature with less than 20% variance\n",
    "    fit_mod=sel.fit(data_np)\n",
    "    fitted=sel.transform(data_np)\n",
    "    sel_idx=fit_mod.get_support()\n",
    "\n",
    "    #Get lists of selected and non-selected features (names and indexes)\n",
    "    temp=[]\n",
    "    temp_idx=[]\n",
    "    temp_del=[]\n",
    "    for i in range(len(data_np[0])):\n",
    "        if sel_idx[i]==1:                                                           #Selected Features get added to temp header\n",
    "            temp.append(header[i+feat_start])\n",
    "            temp_idx.append(i)\n",
    "        else:                                                                       #Indexes of non-selected features get added to delete array\n",
    "            temp_del.append(i)\n",
    "\n",
    "    print('Selected:', temp)\n",
    "    print('Features (total, selected):', len(data_np[0]), len(temp))\n",
    "    print('\\n')\n",
    "\n",
    "    #Filter selected columns from original dataset\n",
    "    header = header[0:feat_start]\n",
    "    for field in temp:\n",
    "        header.append(field)\n",
    "    data_np = np.delete(data_np, temp_del, axis=1)                                 #Deletes non-selected features by index\n",
    "\n",
    "\n",
    "#Feature Selection\n",
    "if feat_select==1:\n",
    "    '''Three steps:\n",
    "       1) Run Feature Selection\n",
    "       2) Get lists of selected and non-selected features\n",
    "       3) Filter columns from original dataset\n",
    "       '''\n",
    "    \n",
    "    print('--FEATURE SELECTION ON--', '\\n')\n",
    "    \n",
    "    ##1) Run Feature Selection #######\n",
    "    #Wrapper Select via model\n",
    "    if fs_type==2:\n",
    "        clf = RandomForestClassifier( n_estimators=50, max_depth=None, min_samples_split=3,criterion='entropy', random_state=rand_st)                \n",
    "        sel = SelectFromModel(clf, prefit=False, threshold='mean', max_features=None)                   \n",
    "        print ('Wrapper Select: ')\n",
    "\n",
    "        fit_mod=sel.fit(data_np, target_np)    \n",
    "        sel_idx=fit_mod.get_support()\n",
    "\n",
    "    if fs_type==4:\n",
    "        clf= RandomForestClassifier( n_estimators=50, max_depth=None, min_samples_split=3,criterion='entropy', random_state=rand_st)\n",
    "        clf.fit(data_np,target_np)\n",
    "        sel_idx = []\n",
    "        print('clf.feature_importances_ = ', clf.feature_importances_)\n",
    "        for x in clf.feature_importances_:\n",
    "          if x >= np.mean(clf.feature_importances_):\n",
    "            sel_idx.append(1)\n",
    "          else:\n",
    "            sel_idx.append(0)\n",
    "\n",
    "    ##2) Get lists of selected and non-selected features (names and indexes) #######\n",
    "    temp=[]\n",
    "    temp_idx=[]\n",
    "    temp_del=[]\n",
    "    for i in range(len(data_np[0])):\n",
    "        if sel_idx[i]==1:                                                           #Selected Features get added to temp header\n",
    "            temp.append(header[i+feat_start])\n",
    "            temp_idx.append(i)\n",
    "        else:                                                                       #Indexes of non-selected features get added to delete array\n",
    "            temp_del.append(i)\n",
    "    print('Selected:', temp)\n",
    "    print('Features (total/selected):', len(data_np[0]), len(temp))\n",
    "    print('\\n')\n",
    "            \n",
    "               \n",
    "    ##3) Filter selected columns from original dataset #########\n",
    "    header = header[0:feat_start]\n",
    "    for field in temp:\n",
    "        header.append(field)\n",
    "    data_np = np.delete(data_np, temp_del, axis=1)                                 #Deletes non-selected features by index\n",
    "    \n",
    "\n",
    "#############################################################################\n",
    "#\n",
    "# Train SciKit Models\n",
    "#\n",
    "##########################################\n",
    "\n",
    "print('--ML Model Output--', '\\n')\n",
    "\n",
    "#Test/Train split\n",
    "data_train, data_test, target_train, target_test = train_test_split(data_np, target_np, test_size=0.35)\n",
    "\n",
    "####Classifiers####\n",
    "if cross_val==0:    \n",
    "    #SciKit Random Forest\n",
    "    clf = RandomForestClassifier( n_estimators=50, max_depth=None, min_samples_split=3,criterion='entropy', random_state=rand_st)  \n",
    "    clf.fit(data_train,target_train)\n",
    "\n",
    "    scores_ACC = clf.score(data_test, target_test)                                                                                                                          \n",
    "    print('Random Forest Acc:', scores_ACC)\n",
    "    scores_AUC = metrics.roc_auc_score(target_test, clf.predict_proba(data_test)[:,1])                                                                                      \n",
    "    print('Random Forest AUC:', scores_AUC)                                                                     #AUC only works with binary classes, not multiclass            \n",
    " \n",
    "####Cross-Val Classifiers####\n",
    "if cross_val==1:\n",
    "    #Setup Crossval classifier scorers\n",
    "    scorers = {'Accuracy': 'accuracy', 'roc_auc': 'roc_auc'}                                                                                                                \n",
    "    \n",
    "    #SciKit Random Forest - Cross Val\n",
    "    start_ts=time.time()\n",
    "    clf = RandomForestClassifier( n_estimators=50, max_depth=None, min_samples_split=3,criterion='entropy', random_state=rand_st)   \n",
    "    scores = cross_validate(clf, data_np, target_np, scoring=scorers, cv=5)                                                                                                 \n",
    "\n",
    "    scores_Acc = scores['test_Accuracy']                                                                                                                                    \n",
    "    print(\"Random Forest Acc: %0.2f (+/- %0.2f)\" % (scores_Acc.mean(), scores_Acc.std() * 2))                                                                                                    \n",
    "    scores_AUC= scores['test_roc_auc']                                                                     #Only works with binary classes, not multiclass                  \n",
    "    print(\"Random Forest AUC: %0.2f (+/- %0.2f)\" % (scores_AUC.mean(), scores_AUC.std() * 2))                           \n",
    "    print(\"CV Runtime:\", time.time()-start_ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rLzcRDPKO1F_"
   },
   "source": [
    "###Random Forest - w/o Feature Selection - Full Dataset\n",
    "\n",
    "\n",
    "* 10 trees & 50 trees Tested (n_estimator changes)\n",
    "* RF 10 trees - 5-fold cv ACC: 0.89 (+/- 0.00)  |   AUC: 0.71 (+/- 0.01)  |   Runtime: 9.93 seconds\n",
    "* RF 50 trees - 5-fold cv ACC: 0.90 (+/- 0.00)  |   AUC: 0.82 (+/- 0.01)  |   Runtime: 66.19 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "yyXic4OlTxgQ",
    "outputId": "0c67b95c-a57d-448b-e922-b19eebc21794"
   },
   "outputs": [],
   "source": [
    "#SciKit DSC540 HW1\n",
    "'''created by Casey Bennett 2018, www.CaseyBennett.com'''\n",
    "\n",
    "import sys\n",
    "import csv\n",
    "import math\n",
    "import numpy as np\n",
    "from operator import itemgetter\n",
    "import time\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.feature_selection import RFE, VarianceThreshold, SelectFromModel\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression, mutual_info_classif, chi2\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "from sklearn.preprocessing import KBinsDiscretizer, scale\n",
    "\n",
    "\n",
    "#Handle annoying warnings\n",
    "import warnings, sklearn.exceptions\n",
    "warnings.filterwarnings(\"ignore\", category=sklearn.exceptions.ConvergenceWarning)\n",
    "\n",
    "\n",
    "#############################################################################\n",
    "#\n",
    "# Global parameters\n",
    "#\n",
    "#####################\n",
    "\n",
    "target_idx=0                                        #Index of Target variable\n",
    "cross_val=1                                         #Control Switch for CV                                                                                      \n",
    "norm_target=0                                       #Normalize target switch\n",
    "norm_features=0                                     #Normalize target switch\n",
    "binning=0                                           #Control Switch for Bin Target\n",
    "bin_cnt=2                                           #If bin target, this sets number of classes\n",
    "feat_select=0                                       #Control Switch for Feature Selection\n",
    "fs_type=4                                           #Feature Selection type (1=Stepwise Backwards Removal, 2=Wrapper Select, 3=Univariate Selection)\n",
    "lv_filter=0                                         #Control switch for low variance filter on features\n",
    "feat_start=1                                        #Start column of features\n",
    "\n",
    "#Set global model parameters\n",
    "rand_st=1                                           #Set Random State variable for randomizing splits on runs\n",
    "\n",
    "\n",
    "#############################################################################\n",
    "#\n",
    "# Load Data\n",
    "#\n",
    "#####################\n",
    "\n",
    "file1= csv.reader(open('brfss2015_cleaned.csv'), delimiter=',', quotechar='\"')\n",
    "\n",
    "#Read Header Line\n",
    "header=next(file1)            \n",
    "\n",
    "#Read data\n",
    "data=[]\n",
    "target=[]\n",
    "for row in file1:\n",
    "    #Load Target\n",
    "    if row[target_idx]=='':                         #If target is blank, skip row                       \n",
    "        continue\n",
    "    else:\n",
    "        target.append(float(row[target_idx]))       #If pre-binned class, change float to int\n",
    "\n",
    "    #Load row into temp array, cast columns  \n",
    "    temp=[]\n",
    "                 \n",
    "    for j in range(feat_start,len(header)):\n",
    "        if row[j]=='':\n",
    "            temp.append(float())\n",
    "        else:\n",
    "            temp.append(float(row[j]))\n",
    "\n",
    "    #Load temp into Data array\n",
    "    data.append(temp)\n",
    "  \n",
    "#Test Print\n",
    "print(header)\n",
    "print(len(target),len(data))\n",
    "print('\\n')\n",
    "\n",
    "data_np=np.asarray(data)\n",
    "target_np=np.asarray(target)\n",
    "\n",
    "\n",
    "#############################################################################\n",
    "#\n",
    "# Preprocess data\n",
    "#\n",
    "##########################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#############################################################################\n",
    "#\n",
    "# Feature Selection\n",
    "#\n",
    "##########################################\n",
    "\n",
    "#Low Variance Filter\n",
    "if lv_filter==1:\n",
    "    print('--LOW VARIANCE FILTER ON--', '\\n')\n",
    "    \n",
    "    #LV Threshold\n",
    "    sel = VarianceThreshold(threshold=0.5)                                          #Removes any feature with less than 20% variance\n",
    "    fit_mod=sel.fit(data_np)\n",
    "    fitted=sel.transform(data_np)\n",
    "    sel_idx=fit_mod.get_support()\n",
    "\n",
    "    #Get lists of selected and non-selected features (names and indexes)\n",
    "    temp=[]\n",
    "    temp_idx=[]\n",
    "    temp_del=[]\n",
    "    for i in range(len(data_np[0])):\n",
    "        if sel_idx[i]==1:                                                           #Selected Features get added to temp header\n",
    "            temp.append(header[i+feat_start])\n",
    "            temp_idx.append(i)\n",
    "        else:                                                                       #Indexes of non-selected features get added to delete array\n",
    "            temp_del.append(i)\n",
    "\n",
    "    print('Selected:', temp)\n",
    "    print('Features (total, selected):', len(data_np[0]), len(temp))\n",
    "    print('\\n')\n",
    "\n",
    "    #Filter selected columns from original dataset\n",
    "    header = header[0:feat_start]\n",
    "    for field in temp:\n",
    "        header.append(field)\n",
    "    data_np = np.delete(data_np, temp_del, axis=1)                                 #Deletes non-selected features by index\n",
    "\n",
    "\n",
    "#Feature Selection\n",
    "if feat_select==1:\n",
    "    '''Three steps:\n",
    "       1) Run Feature Selection\n",
    "       2) Get lists of selected and non-selected features\n",
    "       3) Filter columns from original dataset\n",
    "       '''\n",
    "    \n",
    "    print('--FEATURE SELECTION ON--', '\\n')\n",
    "    \n",
    "    ##1) Run Feature Selection #######\n",
    "    #Wrapper Select via model\n",
    "    if fs_type==2:\n",
    "        clf = RandomForestClassifier( n_estimators=100, max_depth=None, min_samples_split=3,criterion='entropy', random_state=rand_st)                \n",
    "        sel = SelectFromModel(clf, prefit=False, threshold='mean', max_features=None)                   \n",
    "        print ('Wrapper Select: ')\n",
    "\n",
    "        fit_mod=sel.fit(data_np, target_np)    \n",
    "        sel_idx=fit_mod.get_support()\n",
    "\n",
    "    if fs_type==4:\n",
    "        clf= RandomForestClassifier( n_estimators=10, max_depth=None, min_samples_split=3,criterion='entropy', random_state=rand_st)\n",
    "        clf.fit(data_np,target_np)\n",
    "        sel_idx = []\n",
    "        print('clf.feature_importances_ = ', clf.feature_importances_)\n",
    "        for x in clf.feature_importances_:\n",
    "          if x >= np.mean(clf.feature_importances_):\n",
    "            sel_idx.append(1)\n",
    "          else:\n",
    "            sel_idx.append(0)\n",
    "\n",
    "    ##2) Get lists of selected and non-selected features (names and indexes) #######\n",
    "    temp=[]\n",
    "    temp_idx=[]\n",
    "    temp_del=[]\n",
    "    for i in range(len(data_np[0])):\n",
    "        if sel_idx[i]==1:                                                           #Selected Features get added to temp header\n",
    "            temp.append(header[i+feat_start])\n",
    "            temp_idx.append(i)\n",
    "        else:                                                                       #Indexes of non-selected features get added to delete array\n",
    "            temp_del.append(i)\n",
    "    print('Selected:', temp)\n",
    "    print('Features (total/selected):', len(data_np[0]), len(temp))\n",
    "    print('\\n')\n",
    "            \n",
    "               \n",
    "    ##3) Filter selected columns from original dataset #########\n",
    "    header = header[0:feat_start]\n",
    "    for field in temp:\n",
    "        header.append(field)\n",
    "    data_np = np.delete(data_np, temp_del, axis=1)                                 #Deletes non-selected features by index\n",
    "    \n",
    "\n",
    "#############################################################################\n",
    "#\n",
    "# Train SciKit Models\n",
    "#\n",
    "##########################################\n",
    "\n",
    "print('--ML Model Output--', '\\n')\n",
    "\n",
    "#Test/Train split\n",
    "data_train, data_test, target_train, target_test = train_test_split(data_np, target_np, test_size=0.35)\n",
    "\n",
    "####Classifiers####\n",
    "if cross_val==0:    \n",
    "    #SciKit Random Forest\n",
    "    clf = RandomForestClassifier( n_estimators=10, max_depth=None, min_samples_split=3,criterion='entropy', random_state=rand_st)  \n",
    "    clf.fit(data_train,target_train)\n",
    "\n",
    "    scores_ACC = clf.score(data_test, target_test)                                                                                                                          \n",
    "    print('Random Forest Acc:', scores_ACC)\n",
    "    scores_AUC = metrics.roc_auc_score(target_test, clf.predict_proba(data_test)[:,1])                                                                                      \n",
    "    print('Random Forest AUC:', scores_AUC)                                                                     #AUC only works with binary classes, not multiclass            \n",
    " \n",
    "####Cross-Val Classifiers####\n",
    "if cross_val==1:\n",
    "    #Setup Crossval classifier scorers\n",
    "    scorers = {'Accuracy': 'accuracy', 'roc_auc': 'roc_auc'}                                                                                                                \n",
    "    \n",
    "    #SciKit Random Forest - Cross Val\n",
    "    start_ts=time.time()\n",
    "    clf = RandomForestClassifier( n_estimators=100, max_depth=None, min_samples_split=3,criterion='entropy', random_state=rand_st)   \n",
    "    scores = cross_validate(clf, data_np, target_np, scoring=scorers, cv=5)                                                                                                 \n",
    "\n",
    "    scores_Acc = scores['test_Accuracy']                                                                                                                                    \n",
    "    print(\"Random Forest Acc: %0.2f (+/- %0.2f)\" % (scores_Acc.mean(), scores_Acc.std() * 2))                                                                                                    \n",
    "    scores_AUC= scores['test_roc_auc']                                                                     #Only works with binary classes, not multiclass                  \n",
    "    print(\"Random Forest AUC: %0.2f (+/- %0.2f)\" % (scores_AUC.mean(), scores_AUC.std() * 2))                           \n",
    "    print(\"CV Runtime:\", time.time()-start_ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DLPd712bjKN8"
   },
   "source": [
    "###Random Forest - w/ and w/o Feature Selection - 50-50 Balanced Dataset\n",
    "\n",
    "* 10 trees & 50 trees Tested (n_estimator changes)\n",
    "* RF 10 trees - 5-fold cv ACC: 0.75 (+/- 0.01) |   AUC: 0.82 (+/- 0.01)  |\n",
    "Runtime: 2.51 seconds\n",
    "* RF 50 trees - 5-fold cv ACC: 0.76 (+/- 0.02)  |   AUC: 0.83 (+/- 0.01)  |   Runtime: 12.40 seconds\n",
    "* RF 50 trees w/feat_select - 5-fold cv ACC: 0.72 (+/- 0.01)  |   AUC: 0.78 (+/- 0.01)  |   Runtime: 10.62 seconds\n",
    "* Selected Features: ['HighBP', 'BMI', 'GenHlth', 'MentHlth', 'PhysHlth', 'Age', 'Education', 'Income']\n",
    "\n",
    "Notes:\n",
    "* clf features: ['HighBP', 'HighChol', 'CholCheck', 'BMI', 'Smoker', 'Stroke', 'Diabetes', 'PhysActivity', 'Fruits', 'Veggies', 'HvyAlcoholConsump', 'AnyHealthcare', 'NoDocbcCost', 'GenHlth', 'MentHlth', 'PhysHlth', 'DiffWalk', 'Sex', 'Age', 'Education', 'Income']\n",
    "* clf.feature_importances_ =  [0.051, 0.038, 0.005, 0.146, 0.024, 0.025, 0.032, 0.022, 0.026, 0.022, 0.009, 0.007, 0.012, 0.093, 0.053, 0.072, 0.030, 0.029, 0.153, 0.056, 0.084]\n",
    "* Age, BMI , GenHlth, Income, PhysHlth, Education, MentHlth, and HighBP all seem to play an important role. Though Age and BMI are the most important.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1FoyUJDUUHyQ",
    "outputId": "c2e78a59-6a78-464e-9372-c9e63749187a"
   },
   "outputs": [],
   "source": [
    "#SciKit DSC540 HW1\n",
    "'''created by Casey Bennett 2018, www.CaseyBennett.com'''\n",
    "\n",
    "import sys\n",
    "import csv\n",
    "import math\n",
    "import numpy as np\n",
    "from operator import itemgetter\n",
    "import time\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.feature_selection import RFE, VarianceThreshold, SelectFromModel\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression, mutual_info_classif, chi2\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "from sklearn.preprocessing import KBinsDiscretizer, scale\n",
    "\n",
    "\n",
    "#Handle annoying warnings\n",
    "import warnings, sklearn.exceptions\n",
    "warnings.filterwarnings(\"ignore\", category=sklearn.exceptions.ConvergenceWarning)\n",
    "\n",
    "\n",
    "#############################################################################\n",
    "#\n",
    "# Global parameters\n",
    "#\n",
    "#####################\n",
    "\n",
    "target_idx=0                                        #Index of Target variable\n",
    "cross_val=1                                         #Control Switch for CV                                                                                      \n",
    "norm_target=0                                       #Normalize target switch\n",
    "norm_features=0                                     #Normalize target switch\n",
    "binning=0                                           #Control Switch for Bin Target\n",
    "bin_cnt=2                                           #If bin target, this sets number of classes\n",
    "feat_select=1                                       #Control Switch for Feature Selection\n",
    "fs_type=4                                           #Feature Selection type (1=Stepwise Backwards Removal, 2=Wrapper Select, 3=Univariate Selection)\n",
    "lv_filter=0                                         #Control switch for low variance filter on features\n",
    "feat_start=1                                        #Start column of features\n",
    "\n",
    "#Set global model parameters\n",
    "rand_st=1                                           #Set Random State variable for randomizing splits on runs\n",
    "\n",
    "\n",
    "#############################################################################\n",
    "#\n",
    "# Load Data\n",
    "#\n",
    "#####################\n",
    "\n",
    "file1= csv.reader(open('brfss2015_5050_cleaned.csv'), delimiter=',', quotechar='\"')\n",
    "\n",
    "#Read Header Line\n",
    "header=next(file1)            \n",
    "\n",
    "#Read data\n",
    "data=[]\n",
    "target=[]\n",
    "for row in file1:\n",
    "    #Load Target\n",
    "    if row[target_idx]=='':                         #If target is blank, skip row                       \n",
    "        continue\n",
    "    else:\n",
    "        target.append(float(row[target_idx]))       #If pre-binned class, change float to int\n",
    "\n",
    "    #Load row into temp array, cast columns  \n",
    "    temp=[]\n",
    "                 \n",
    "    for j in range(feat_start,len(header)):\n",
    "        if row[j]=='':\n",
    "            temp.append(float())\n",
    "        else:\n",
    "            temp.append(float(row[j]))\n",
    "\n",
    "    #Load temp into Data array\n",
    "    data.append(temp)\n",
    "  \n",
    "#Test Print\n",
    "print(header)\n",
    "print(len(target),len(data))\n",
    "print('\\n')\n",
    "\n",
    "data_np=np.asarray(data)\n",
    "target_np=np.asarray(target)\n",
    "\n",
    "\n",
    "#############################################################################\n",
    "#\n",
    "# Preprocess data\n",
    "#\n",
    "##########################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#############################################################################\n",
    "#\n",
    "# Feature Selection\n",
    "#\n",
    "##########################################\n",
    "\n",
    "#Low Variance Filter\n",
    "if lv_filter==1:\n",
    "    print('--LOW VARIANCE FILTER ON--', '\\n')\n",
    "    \n",
    "    #LV Threshold\n",
    "    sel = VarianceThreshold(threshold=0.5)                                          #Removes any feature with less than 20% variance\n",
    "    fit_mod=sel.fit(data_np)\n",
    "    fitted=sel.transform(data_np)\n",
    "    sel_idx=fit_mod.get_support()\n",
    "\n",
    "    #Get lists of selected and non-selected features (names and indexes)\n",
    "    temp=[]\n",
    "    temp_idx=[]\n",
    "    temp_del=[]\n",
    "    for i in range(len(data_np[0])):\n",
    "        if sel_idx[i]==1:                                                           #Selected Features get added to temp header\n",
    "            temp.append(header[i+feat_start])\n",
    "            temp_idx.append(i)\n",
    "        else:                                                                       #Indexes of non-selected features get added to delete array\n",
    "            temp_del.append(i)\n",
    "\n",
    "    print('Selected:', temp)\n",
    "    print('Features (total, selected):', len(data_np[0]), len(temp))\n",
    "    print('\\n')\n",
    "\n",
    "    #Filter selected columns from original dataset\n",
    "    header = header[0:feat_start]\n",
    "    for field in temp:\n",
    "        header.append(field)\n",
    "    data_np = np.delete(data_np, temp_del, axis=1)                                 #Deletes non-selected features by index\n",
    "\n",
    "\n",
    "#Feature Selection\n",
    "if feat_select==1:\n",
    "    '''Three steps:\n",
    "       1) Run Feature Selection\n",
    "       2) Get lists of selected and non-selected features\n",
    "       3) Filter columns from original dataset\n",
    "       '''\n",
    "    \n",
    "    print('--FEATURE SELECTION ON--', '\\n')\n",
    "    \n",
    "    ##1) Run Feature Selection #######\n",
    "    #Wrapper Select via model\n",
    "    if fs_type==2:\n",
    "        clf = RandomForestClassifier( n_estimators=50, max_depth=None, min_samples_split=3,criterion='entropy', random_state=rand_st)                \n",
    "        sel = SelectFromModel(clf, prefit=False, threshold='mean', max_features=None)                   \n",
    "        print ('Wrapper Select: ')\n",
    "\n",
    "        fit_mod=sel.fit(data_np, target_np)    \n",
    "        sel_idx=fit_mod.get_support()\n",
    "\n",
    "    if fs_type==4:\n",
    "        clf= RandomForestClassifier( n_estimators=50, max_depth=None, min_samples_split=3,criterion='entropy', random_state=rand_st)\n",
    "        clf.fit(data_np,target_np)\n",
    "        sel_idx = []\n",
    "        print('clf.feature_importances_ = ', clf.feature_importances_)\n",
    "        for x in clf.feature_importances_:\n",
    "          if x >= np.mean(clf.feature_importances_):\n",
    "            sel_idx.append(1)\n",
    "          else:\n",
    "            sel_idx.append(0)\n",
    "\n",
    "    ##2) Get lists of selected and non-selected features (names and indexes) #######\n",
    "    temp=[]\n",
    "    temp_idx=[]\n",
    "    temp_del=[]\n",
    "    for i in range(len(data_np[0])):\n",
    "        if sel_idx[i]==1:                                                           #Selected Features get added to temp header\n",
    "            temp.append(header[i+feat_start])\n",
    "            temp_idx.append(i)\n",
    "        else:                                                                       #Indexes of non-selected features get added to delete array\n",
    "            temp_del.append(i)\n",
    "    print('Selected:', temp)\n",
    "    print('Features (total/selected):', len(data_np[0]), len(temp))\n",
    "    print('\\n')\n",
    "            \n",
    "               \n",
    "    ##3) Filter selected columns from original dataset #########\n",
    "    header = header[0:feat_start]\n",
    "    for field in temp:\n",
    "        header.append(field)\n",
    "    data_np = np.delete(data_np, temp_del, axis=1)                                 #Deletes non-selected features by index\n",
    "    \n",
    "\n",
    "#############################################################################\n",
    "#\n",
    "# Train SciKit Models\n",
    "#\n",
    "##########################################\n",
    "\n",
    "print('--ML Model Output--', '\\n')\n",
    "\n",
    "#Test/Train split\n",
    "data_train, data_test, target_train, target_test = train_test_split(data_np, target_np, test_size=0.35)\n",
    "\n",
    "####Classifiers####\n",
    "if cross_val==0:    \n",
    "    #SciKit Random Forest\n",
    "    clf = RandomForestClassifier( n_estimators=50, max_depth=None, min_samples_split=3,criterion='entropy', random_state=rand_st)  \n",
    "    clf.fit(data_train,target_train)\n",
    "\n",
    "    scores_ACC = clf.score(data_test, target_test)                                                                                                                          \n",
    "    print('Random Forest Acc:', scores_ACC)\n",
    "    scores_AUC = metrics.roc_auc_score(target_test, clf.predict_proba(data_test)[:,1])                                                                                      \n",
    "    print('Random Forest AUC:', scores_AUC)                                                                     #AUC only works with binary classes, not multiclass            \n",
    " \n",
    "####Cross-Val Classifiers####\n",
    "if cross_val==1:\n",
    "    #Setup Crossval classifier scorers\n",
    "    scorers = {'Accuracy': 'accuracy', 'roc_auc': 'roc_auc'}                                                                                                                \n",
    "    \n",
    "    #SciKit Random Forest - Cross Val\n",
    "    start_ts=time.time()\n",
    "    clf = RandomForestClassifier( n_estimators=50, max_depth=None, min_samples_split=3,criterion='entropy', random_state=rand_st)   \n",
    "    scores = cross_validate(clf, data_np, target_np, scoring=scorers, cv=5)                                                                                                 \n",
    "\n",
    "    scores_Acc = scores['test_Accuracy']                                                                                                                                    \n",
    "    print(\"Random Forest Acc: %0.2f (+/- %0.2f)\" % (scores_Acc.mean(), scores_Acc.std() * 2))                                                                                                    \n",
    "    scores_AUC= scores['test_roc_auc']                                                                     #Only works with binary classes, not multiclass                  \n",
    "    print(\"Random Forest AUC: %0.2f (+/- %0.2f)\" % (scores_AUC.mean(), scores_AUC.std() * 2))                           \n",
    "    print(\"CV Runtime:\", time.time()-start_ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VTleJ-2HqBRm"
   },
   "source": [
    "###Random Forest - w/ Feature Selection - 60-40 Balanced Dataset\n",
    "RF 50 trees  \n",
    "* 5-fold cv Acc: 0.73 (+/- 0.01) | AUC: 0.78 (+/- 0.01) | Runtime: 15.27\n",
    "* Selected: ['HighBP', 'BMI', 'GenHlth', 'MentHlth', 'PhysHlth', 'Age', 'Education', 'Income']\n",
    "* Features (total/selected): 21 8\n",
    "* Same important features identified here. Age and BMI especially important\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZupbZ9mhfoF_",
    "outputId": "b9309b51-b471-4f37-fb65-cd05bbedf389"
   },
   "outputs": [],
   "source": [
    "#SciKit DSC540 HW1\n",
    "'''created by Casey Bennett 2018, www.CaseyBennett.com'''\n",
    "\n",
    "import sys\n",
    "import csv\n",
    "import math\n",
    "import numpy as np\n",
    "from operator import itemgetter\n",
    "import time\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.feature_selection import RFE, VarianceThreshold, SelectFromModel\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression, mutual_info_classif, chi2\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "from sklearn.preprocessing import KBinsDiscretizer, scale\n",
    "\n",
    "\n",
    "#Handle annoying warnings\n",
    "import warnings, sklearn.exceptions\n",
    "warnings.filterwarnings(\"ignore\", category=sklearn.exceptions.ConvergenceWarning)\n",
    "\n",
    "\n",
    "#############################################################################\n",
    "#\n",
    "# Global parameters\n",
    "#\n",
    "#####################\n",
    "\n",
    "target_idx=0                                        #Index of Target variable\n",
    "cross_val=1                                         #Control Switch for CV                                                                                      \n",
    "norm_target=0                                       #Normalize target switch\n",
    "norm_features=0                                     #Normalize target switch\n",
    "binning=0                                           #Control Switch for Bin Target\n",
    "bin_cnt=2                                           #If bin target, this sets number of classes\n",
    "feat_select=1                                       #Control Switch for Feature Selection\n",
    "fs_type=4                                           #Feature Selection type (1=Stepwise Backwards Removal, 2=Wrapper Select, 3=Univariate Selection)\n",
    "lv_filter=0                                         #Control switch for low variance filter on features\n",
    "feat_start=1                                        #Start column of features\n",
    "\n",
    "#Set global model parameters\n",
    "rand_st=1                                           #Set Random State variable for randomizing splits on runs\n",
    "\n",
    "\n",
    "#############################################################################\n",
    "#\n",
    "# Load Data\n",
    "#\n",
    "#####################\n",
    "\n",
    "file1= csv.reader(open('brfss2015_6040_cleaned.csv'), delimiter=',', quotechar='\"')\n",
    "\n",
    "#Read Header Line\n",
    "header=next(file1)            \n",
    "\n",
    "#Read data\n",
    "data=[]\n",
    "target=[]\n",
    "for row in file1:\n",
    "    #Load Target\n",
    "    if row[target_idx]=='':                         #If target is blank, skip row                       \n",
    "        continue\n",
    "    else:\n",
    "        target.append(float(row[target_idx]))       #If pre-binned class, change float to int\n",
    "\n",
    "    #Load row into temp array, cast columns  \n",
    "    temp=[]\n",
    "                 \n",
    "    for j in range(feat_start,len(header)):\n",
    "        if row[j]=='':\n",
    "            temp.append(float())\n",
    "        else:\n",
    "            temp.append(float(row[j]))\n",
    "\n",
    "    #Load temp into Data array\n",
    "    data.append(temp)\n",
    "  \n",
    "#Test Print\n",
    "print(header)\n",
    "print(len(target),len(data))\n",
    "print('\\n')\n",
    "\n",
    "data_np=np.asarray(data)\n",
    "target_np=np.asarray(target)\n",
    "\n",
    "\n",
    "#############################################################################\n",
    "#\n",
    "# Preprocess data\n",
    "#\n",
    "##########################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#############################################################################\n",
    "#\n",
    "# Feature Selection\n",
    "#\n",
    "##########################################\n",
    "\n",
    "#Low Variance Filter\n",
    "if lv_filter==1:\n",
    "    print('--LOW VARIANCE FILTER ON--', '\\n')\n",
    "    \n",
    "    #LV Threshold\n",
    "    sel = VarianceThreshold(threshold=0.5)                                          #Removes any feature with less than 20% variance\n",
    "    fit_mod=sel.fit(data_np)\n",
    "    fitted=sel.transform(data_np)\n",
    "    sel_idx=fit_mod.get_support()\n",
    "\n",
    "    #Get lists of selected and non-selected features (names and indexes)\n",
    "    temp=[]\n",
    "    temp_idx=[]\n",
    "    temp_del=[]\n",
    "    for i in range(len(data_np[0])):\n",
    "        if sel_idx[i]==1:                                                           #Selected Features get added to temp header\n",
    "            temp.append(header[i+feat_start])\n",
    "            temp_idx.append(i)\n",
    "        else:                                                                       #Indexes of non-selected features get added to delete array\n",
    "            temp_del.append(i)\n",
    "\n",
    "    print('Selected:', temp)\n",
    "    print('Features (total, selected):', len(data_np[0]), len(temp))\n",
    "    print('\\n')\n",
    "\n",
    "    #Filter selected columns from original dataset\n",
    "    header = header[0:feat_start]\n",
    "    for field in temp:\n",
    "        header.append(field)\n",
    "    data_np = np.delete(data_np, temp_del, axis=1)                                 #Deletes non-selected features by index\n",
    "\n",
    "\n",
    "#Feature Selection\n",
    "if feat_select==1:\n",
    "    '''Three steps:\n",
    "       1) Run Feature Selection\n",
    "       2) Get lists of selected and non-selected features\n",
    "       3) Filter columns from original dataset\n",
    "       '''\n",
    "    \n",
    "    print('--FEATURE SELECTION ON--', '\\n')\n",
    "    \n",
    "    ##1) Run Feature Selection #######\n",
    "    #Wrapper Select via model\n",
    "    if fs_type==2:\n",
    "        clf = RandomForestClassifier( n_estimators=50, max_depth=None, min_samples_split=3,criterion='entropy', random_state=rand_st)                \n",
    "        sel = SelectFromModel(clf, prefit=False, threshold='mean', max_features=None)                   \n",
    "        print ('Wrapper Select: ')\n",
    "\n",
    "        fit_mod=sel.fit(data_np, target_np)    \n",
    "        sel_idx=fit_mod.get_support()\n",
    "\n",
    "    if fs_type==4:\n",
    "        clf= RandomForestClassifier( n_estimators=50, max_depth=None, min_samples_split=3,criterion='entropy', random_state=rand_st)\n",
    "        clf.fit(data_np,target_np)\n",
    "        sel_idx = []\n",
    "        print('clf.feature_importances_ = ', clf.feature_importances_)\n",
    "        for x in clf.feature_importances_:\n",
    "          if x >= np.mean(clf.feature_importances_):\n",
    "            sel_idx.append(1)\n",
    "          else:\n",
    "            sel_idx.append(0)\n",
    "\n",
    "    ##2) Get lists of selected and non-selected features (names and indexes) #######\n",
    "    temp=[]\n",
    "    temp_idx=[]\n",
    "    temp_del=[]\n",
    "    for i in range(len(data_np[0])):\n",
    "        if sel_idx[i]==1:                                                           #Selected Features get added to temp header\n",
    "            temp.append(header[i+feat_start])\n",
    "            temp_idx.append(i)\n",
    "        else:                                                                       #Indexes of non-selected features get added to delete array\n",
    "            temp_del.append(i)\n",
    "    print('Selected:', temp)\n",
    "    print('Features (total/selected):', len(data_np[0]), len(temp))\n",
    "    print('\\n')\n",
    "            \n",
    "               \n",
    "    ##3) Filter selected columns from original dataset #########\n",
    "    header = header[0:feat_start]\n",
    "    for field in temp:\n",
    "        header.append(field)\n",
    "    data_np = np.delete(data_np, temp_del, axis=1)                                 #Deletes non-selected features by index\n",
    "    \n",
    "\n",
    "#############################################################################\n",
    "#\n",
    "# Train SciKit Models\n",
    "#\n",
    "##########################################\n",
    "\n",
    "print('--ML Model Output--', '\\n')\n",
    "\n",
    "#Test/Train split\n",
    "data_train, data_test, target_train, target_test = train_test_split(data_np, target_np, test_size=0.35)\n",
    "\n",
    "####Classifiers####\n",
    "if cross_val==0:    \n",
    "    #SciKit Random Forest\n",
    "    clf = RandomForestClassifier( n_estimators=50, max_depth=None, min_samples_split=3,criterion='entropy', random_state=rand_st)  \n",
    "    clf.fit(data_train,target_train)\n",
    "\n",
    "    scores_ACC = clf.score(data_test, target_test)                                                                                                                          \n",
    "    print('Random Forest Acc:', scores_ACC)\n",
    "    scores_AUC = metrics.roc_auc_score(target_test, clf.predict_proba(data_test)[:,1])                                                                                      \n",
    "    print('Random Forest AUC:', scores_AUC)                                                                     #AUC only works with binary classes, not multiclass            \n",
    " \n",
    "####Cross-Val Classifiers####\n",
    "if cross_val==1:\n",
    "    #Setup Crossval classifier scorers\n",
    "    scorers = {'Accuracy': 'accuracy', 'roc_auc': 'roc_auc'}                                                                                                                \n",
    "    \n",
    "    #SciKit Random Forest - Cross Val\n",
    "    start_ts=time.time()\n",
    "    clf = RandomForestClassifier( n_estimators=50, max_depth=None, min_samples_split=3,criterion='entropy', random_state=rand_st)   \n",
    "    scores = cross_validate(clf, data_np, target_np, scoring=scorers, cv=5)                                                                                                 \n",
    "\n",
    "    scores_Acc = scores['test_Accuracy']                                                                                                                                    \n",
    "    print(\"Random Forest Acc: %0.2f (+/- %0.2f)\" % (scores_Acc.mean(), scores_Acc.std() * 2))                                                                                                    \n",
    "    scores_AUC= scores['test_roc_auc']                                                                     #Only works with binary classes, not multiclass                  \n",
    "    print(\"Random Forest AUC: %0.2f (+/- %0.2f)\" % (scores_AUC.mean(), scores_AUC.std() * 2))                           \n",
    "    print(\"CV Runtime:\", time.time()-start_ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AQbmgfdc4eB3"
   },
   "source": [
    "## AdaBoost, GradientBoost, and Neural Networks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qDn5nRMjuXi_"
   },
   "source": [
    "### AdaBoost, GradientBoost, and Neural Network - w/o Feature Selection - Full Dataset\n",
    "Gradient Boosting:\n",
    "* Gradient Boosting - Acc: 0.91 (+/- 0.00)\n",
    "* Gradient Boosting - AUC: 0.85 (+/- 0.01)\n",
    "* GB - CV Runtime: 153.49 seconds\n",
    "\n",
    "Ada Boost:\n",
    "* Ada Boost - Acc: 0.91 (+/- 0.00)\n",
    "* Ada Boost - AUC: 0.84 (+/- 0.01)\n",
    "* Ada - CV Runtime: 92.66 seconds\n",
    "\n",
    "Neural Network:\n",
    "* Neural Network - Acc: 0.91 (+/- 0.00)\n",
    "* Neural Network - AUC: 0.85 (+/- 0.01)\n",
    "* NN - CV Runtime: 113.11 seconds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YxnhJzWGuuBz",
    "outputId": "c7f6bea1-e6af-4ccf-c23d-312003497897"
   },
   "outputs": [],
   "source": [
    "#SciKit DSC540 HW1\n",
    "'''created by Casey Bennett 2018, www.CaseyBennett.com'''\n",
    "\n",
    "import sys\n",
    "import csv\n",
    "import math\n",
    "import numpy as np\n",
    "from operator import itemgetter\n",
    "import time\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.feature_selection import RFE, VarianceThreshold, SelectFromModel\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression, mutual_info_classif, chi2\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "from sklearn.preprocessing import KBinsDiscretizer, scale\n",
    "\n",
    "#Handle annoying warnings\n",
    "import warnings, sklearn.exceptions\n",
    "warnings.filterwarnings(\"ignore\", category=sklearn.exceptions.ConvergenceWarning)\n",
    "\n",
    "\n",
    "#############################################################################\n",
    "#\n",
    "# Global parameters\n",
    "#\n",
    "#####################\n",
    "\n",
    "target_idx=0                                        #Index of Target variable\n",
    "cross_val=1                                         #Control Switch for CV                                                                                                                                                      \n",
    "norm_target=0                                       #Normalize target switch\n",
    "norm_features=0                                     #Normalize target switch\n",
    "binning=1                                           #Control Switch for Bin Target\n",
    "bin_cnt=2                                           #If bin target, this sets number of classes\n",
    "feat_select=0                                       #Control Switch for Feature Selection                                                                                   \n",
    "fs_type=2                                           #Feature Selection type (1=Stepwise Backwards Removal, 2=Wrapper Select, 3=Univariate Selection)                        \n",
    "lv_filter=0                                         #Control switch for low variance filter on features\n",
    "feat_start=1                                        #Start column of features\n",
    "k_cnt=5                                             #Number of 'Top k' best ranked features to select, only applies for fs_types 1 and 3\n",
    "\n",
    "#Set global model parameters\n",
    "rand_st=1                                           #Set Random State variable for randomizing splits on runs\n",
    "\n",
    "\n",
    "#############################################################################\n",
    "#\n",
    "# Load Data\n",
    "#\n",
    "#####################\n",
    "\n",
    "file1= csv.reader(open('brfss2015_cleaned.csv'), delimiter=',', quotechar='\"')\n",
    "\n",
    "#Read Header Line\n",
    "header=next(file1)            \n",
    "\n",
    "#Read data\n",
    "data=[]\n",
    "target=[]\n",
    "for row in file1:\n",
    "    #Load Target\n",
    "    if row[target_idx]=='':                         #If target is blank, skip row                       \n",
    "        continue\n",
    "    else:\n",
    "        target.append(float(row[target_idx]))       #If pre-binned class, change float to int\n",
    "\n",
    "    #Load row into temp array, cast columns  \n",
    "    temp=[]\n",
    "                 \n",
    "    for j in range(feat_start,len(header)):\n",
    "        if row[j]=='':\n",
    "            temp.append(float())\n",
    "        else:\n",
    "            temp.append(float(row[j]))\n",
    "\n",
    "    #Load temp into Data array\n",
    "    data.append(temp)\n",
    "  \n",
    "#Test Print\n",
    "print(header)\n",
    "print(len(target),len(data))\n",
    "print('\\n')\n",
    "\n",
    "data_np=np.asarray(data)\n",
    "target_np=np.asarray(target)\n",
    "\n",
    "\n",
    "#############################################################################\n",
    "#\n",
    "# Preprocess data\n",
    "#\n",
    "##########################################\n",
    "\n",
    "if norm_target==1:\n",
    "    #Target normalization for continuous values\n",
    "    target_np=scale(target_np)\n",
    "\n",
    "if norm_features==1:\n",
    "    #Feature normalization for continuous values\n",
    "    data_np=scale(data_np)\n",
    "\n",
    "'''if binning==1:\n",
    "    #Discretize Target variable with KBinsDiscretizer\n",
    "    enc = KBinsDiscretizer(n_bins=[bin_cnt], encode='ordinal', strategy='quantile')                         #Strategy here is important, quantile creating equal bins, but kmeans prob being more valid \"clusters\"\n",
    "    target_np_bin = enc.fit_transform(target_np.reshape(-1,1))\n",
    "\n",
    "    #Get Bin min/max\n",
    "    temp=[[] for x in range(bin_cnt+1)]\n",
    "    for i in range(len(target_np)):\n",
    "        for j in range(bin_cnt):\n",
    "            if target_np_bin[i]==j:\n",
    "                temp[j].append(target_np[i])\n",
    "\n",
    "    for j in range(bin_cnt):\n",
    "        print('Bin', j, ':', min(temp[j]), max(temp[j]), len(temp[j]))\n",
    "    print('\\n')\n",
    "\n",
    "    #Convert Target array back to correct shape\n",
    "    target_np=np.ravel(target_np_bin)'''\n",
    "\n",
    "\n",
    "#############################################################################\n",
    "#\n",
    "# Feature Selection\n",
    "#\n",
    "##########################################\n",
    "\n",
    "#Low Variance Filter\n",
    "if lv_filter==1:\n",
    "    print('--LOW VARIANCE FILTER ON--', '\\n')\n",
    "    \n",
    "    #LV Threshold\n",
    "    sel = VarianceThreshold(threshold=0.5)                                      #Removes any feature with less than 20% variance\n",
    "    fit_mod=sel.fit(data_np)\n",
    "    fitted=sel.transform(data_np)\n",
    "    sel_idx=fit_mod.get_support()\n",
    "\n",
    "    #Get lists of selected and non-selected features (names and indexes)\n",
    "    temp=[]\n",
    "    temp_idx=[]\n",
    "    temp_del=[]\n",
    "    for i in range(len(data_np[0])):\n",
    "        if sel_idx[i]==1:                                                           #Selected Features get added to temp header\n",
    "            temp.append(header[i+feat_start])\n",
    "            temp_idx.append(i)\n",
    "        else:                                                                       #Indexes of non-selected features get added to delete array\n",
    "            temp_del.append(i)\n",
    "\n",
    "    print('Selected', temp)\n",
    "    print('Features (total, selected):', len(data_np[0]), len(temp))\n",
    "    print('\\n')\n",
    "\n",
    "    #Filter selected columns from original dataset\n",
    "    header = header[0:feat_start]\n",
    "    for field in temp:\n",
    "        header.append(field)\n",
    "    data_np = np.delete(data_np, temp_del, axis=1)                                 #Deletes non-selected features by index\n",
    "\n",
    "\n",
    "#Feature Selection\n",
    "if feat_select==1:\n",
    "    '''Three steps:\n",
    "       1) Run Feature Selection\n",
    "       2) Get lists of selected and non-selected features\n",
    "       3) Filter columns from original dataset\n",
    "       '''\n",
    "    \n",
    "    print('--FEATURE SELECTION ON--', '\\n')\n",
    "    \n",
    "    ##1) Run Feature Selection #######\n",
    "    if fs_type==1:\n",
    "        #Stepwise Recursive Backwards Feature removal\n",
    "        if binning==1:\n",
    "            clf = RandomForestClassifier(n_estimators=200, max_depth=None, min_samples_split=3, criterion='entropy', random_state=rand_st)\n",
    "            sel = RFE(clf, n_features_to_select=k_cnt, step=.1)\n",
    "            print('Stepwise Recursive Backwards - Random Forest: ')\n",
    "        if binning==0:\n",
    "            rgr = RandomForestRegressor(n_estimators=500, max_depth=None, min_samples_split=3, criterion='mse', random_state=rand_st)\n",
    "            sel = RFE(rgr, n_features_to_select=k_cnt, step=.1)\n",
    "            print('Stepwise Recursive Backwards - Random Forest: ')\n",
    "            \n",
    "        fit_mod=sel.fit(data_np, target_np)\n",
    "        print(sel.ranking_)\n",
    "        sel_idx=fit_mod.get_support()      \n",
    "\n",
    "    if fs_type==2:\n",
    "        #Wrapper Select via model\n",
    "        if binning==1:\n",
    "            clf = GradientBoostingClassifier(n_estimators=100, loss='deviance', learning_rate=0.1, max_depth=3, min_samples_split=3, random_state=rand_st)\n",
    "            sel = SelectFromModel(clf, prefit=False, threshold='mean', max_features=None)                                                           #to select only based on max_features, set to integer value and set threshold=-np.inf\n",
    "            print ('Wrapper Select: ')\n",
    "        if binning==0:\n",
    "            rgr = '''Unused in this homework'''\n",
    "            sel = SelectFromModel(rgr, prefit=False, threshold='mean', max_features=None)\n",
    "            print ('Wrapper Select: ')\n",
    "            \n",
    "        fit_mod=sel.fit(data_np, target_np)    \n",
    "        sel_idx=fit_mod.get_support()\n",
    "\n",
    "    if fs_type==3:\n",
    "        if binning==1:                                                              ######Only work if the Target is binned###########\n",
    "            #Univariate Feature Selection - Chi-squared\n",
    "            sel=SelectKBest(chi2, k=k_cnt)\n",
    "            fit_mod=sel.fit(data_np, target_np)                                         #will throw error if any negative values in features, so turn off feature normalization, or switch to mutual_info_classif\n",
    "            print ('Univariate Feature Selection - Chi2: ')\n",
    "            sel_idx=fit_mod.get_support()\n",
    "\n",
    "        if binning==0:                                                              ######Only work if the Target is continuous###########\n",
    "            #Univariate Feature Selection - Mutual Info Regression\n",
    "            sel=SelectKBest(mutual_info_regression, k=k_cnt)\n",
    "            fit_mod=sel.fit(data_np, target_np)\n",
    "            print ('Univariate Feature Selection - Mutual Info: ')\n",
    "            sel_idx=fit_mod.get_support()\n",
    "\n",
    "        #Print ranked variables out sorted\n",
    "        temp=[]\n",
    "        scores=fit_mod.scores_\n",
    "        for i in range(feat_start, len(header)):            \n",
    "            temp.append([header[i], float(scores[i-feat_start])])\n",
    "\n",
    "        print('Ranked Features')\n",
    "        temp_sort=sorted(temp, key=itemgetter(1), reverse=True)\n",
    "        for i in range(len(temp_sort)):\n",
    "            print(i, temp_sort[i][0], ':', temp_sort[i][1])\n",
    "        print('\\n')\n",
    "\n",
    "    ##2) Get lists of selected and non-selected features (names and indexes) #######\n",
    "    temp=[]\n",
    "    temp_idx=[]\n",
    "    temp_del=[]\n",
    "    for i in range(len(data_np[0])):\n",
    "        if sel_idx[i]==1:                                                           #Selected Features get added to temp header\n",
    "            temp.append(header[i+feat_start])\n",
    "            temp_idx.append(i)\n",
    "        else:                                                                       #Indexes of non-selected features get added to delete array\n",
    "            temp_del.append(i)\n",
    "    print('Selected', temp)\n",
    "    print('Features (total/selected):', len(data_np[0]), len(temp))\n",
    "    print('\\n')\n",
    "            \n",
    "                \n",
    "    ##3) Filter selected columns from original dataset #########\n",
    "    header = header[0:feat_start]\n",
    "    for field in temp:\n",
    "        header.append(field)\n",
    "    data_np = np.delete(data_np, temp_del, axis=1)                                 #Deletes non-selected features by index)\n",
    "    \n",
    "    \n",
    "\n",
    "#############################################################################\n",
    "#\n",
    "# Train SciKit Models\n",
    "#\n",
    "##########################################\n",
    "\n",
    "print('--ML Model Output--', '\\n')\n",
    "\n",
    "#Test/Train split\n",
    "data_train, data_test, target_train, target_test = train_test_split(data_np, target_np, test_size=0.35)\n",
    "\n",
    "####Classifiers####\n",
    "if binning==1 and cross_val==0:\n",
    "    #SciKit\n",
    "    '''Test/Train split unused in this homework, skip down to CV section'''\n",
    " \n",
    "\n",
    "                                                                                                                         \n",
    " \n",
    "####Cross-Val Classifiers####\n",
    "if binning==1 and cross_val==1:\n",
    "    #Setup Crossval classifier scorers\n",
    "    scorers = {'Accuracy': 'accuracy', 'roc_auc': 'roc_auc'}                                                                                                                \n",
    "    \n",
    "    #SciKit Gradient Boosting - Cross Val\n",
    "    start_ts=time.time()\n",
    "    clf=GradientBoostingClassifier(n_estimators=100, loss='deviance', learning_rate=0.1, max_depth=3, min_samples_split=3, random_state=rand_st)\n",
    "    scores= cross_validate(clf, data_np, target_np, scoring=scorers, cv=5)\n",
    "\n",
    "    scores_Acc = scores['test_Accuracy']                                                                                                                                    \n",
    "    print(\"Gradient Boosting - Random Forest Acc: %0.2f (+/- %0.2f)\" % (scores_Acc.mean(), scores_Acc.std() * 2))                                                                                                    \n",
    "    scores_AUC= scores['test_roc_auc']                                                                     #Only works with binary classes, not multiclass                  \n",
    "    print(\"Gradient Boosting - Random Forest AUC: %0.2f (+/- %0.2f)\" % (scores_AUC.mean(), scores_AUC.std() * 2))                           \n",
    "    print(\"GB - CV Runtime:\", time.time()-start_ts)\n",
    "\n",
    "\n",
    "    #SciKit Ada Boosting - Cross Val\n",
    "    start_ts=time.time()\n",
    "    clf=AdaBoostClassifier(n_estimators=100, base_estimator=None, learning_rate=0.1, random_state=rand_st)\n",
    "    scores= cross_validate(clf, data_np, target_np, scoring=scorers, cv=5)\n",
    "\n",
    "    scores_Acc = scores['test_Accuracy']                                                                                                                                    \n",
    "    print(\"Ada Boost - Random Forest Acc: %0.2f (+/- %0.2f)\" % (scores_Acc.mean(), scores_Acc.std() * 2))                                                                                                    \n",
    "    scores_AUC= scores['test_roc_auc']                                                                     #Only works with binary classes, not multiclass                  \n",
    "    print(\"Ada Boost - Random Forest AUC: %0.2f (+/- %0.2f)\" % (scores_AUC.mean(), scores_AUC.std() * 2))                           \n",
    "    print(\"Ada - CV Runtime:\", time.time()-start_ts)\n",
    "\n",
    "\n",
    "    #SciKit Neural Network - Cross Val\n",
    "    start_ts=time.time()\n",
    "    clf=MLPClassifier(activation='logistic', solver='adam', alpha=0.0001, max_iter=1000, hidden_layer_sizes=(10,), random_state=rand_st)\n",
    "    scores= cross_validate(clf, data_np, target_np, scoring=scorers, cv=5)\n",
    "\n",
    "    scores_Acc = scores['test_Accuracy']                                                                                                                                    \n",
    "    print(\"Neural Network - Acc: %0.2f (+/- %0.2f)\" % (scores_Acc.mean(), scores_Acc.std() * 2))                                                                                                    \n",
    "    scores_AUC= scores['test_roc_auc']                                                                     #Only works with binary classes, not multiclass                  \n",
    "    print(\"Neural Network - AUC: %0.2f (+/- %0.2f)\" % (scores_AUC.mean(), scores_AUC.std() * 2))                           \n",
    "    print(\"NN - CV Runtime:\", time.time()-start_ts) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_DhGgU7bp1aO"
   },
   "source": [
    "### AdaBoost, GradientBoost, and Neural Network - w/ Feature Selection - Full Dataset\n",
    "Gradient Boosting:\n",
    "* Gradient Boosting - Acc: 0.91 (+/- 0.00)\n",
    "* Gradient Boosting - AUC: 0.85 (+/- 0.01)\n",
    "* GB - CV Runtime: 54.26 seconds\n",
    "\n",
    "Ada Boost:\n",
    "* Ada Boost - Acc: 0.91 (+/- 0.00)\n",
    "* Ada Boost - AUC: 0.84 (+/- 0.01)\n",
    "* Ada - CV Runtime: 49.80 seconds\n",
    "\n",
    "Neural Network:\n",
    "* Neural Network - Acc: 0.91 (+/- 0.00)\n",
    "* Neural Network - AUC: 0.84 (+/- 0.01)\n",
    "* NN - CV Runtime: 36.23 seconds\n",
    "\n",
    "Notes:\n",
    "* Selected Features: ['HighBP', 'HighChol', 'Stroke', 'GenHlth', 'DiffWalk', 'Sex', 'Age']\n",
    "* Features (total/selected): 21 7\n",
    "* Note that the selected features are different from the ones identified in the Random Forest feature important and selection.\n",
    "* No significant change in ACC or AUC when using feature selection, just faster runtimes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n0wZbpKnq7da",
    "outputId": "417b1ff5-f6c6-4204-82b8-46aaad9850d2"
   },
   "outputs": [],
   "source": [
    "#SciKit DSC540 HW1\n",
    "'''created by Casey Bennett 2018, www.CaseyBennett.com'''\n",
    "\n",
    "import sys\n",
    "import csv\n",
    "import math\n",
    "import numpy as np\n",
    "from operator import itemgetter\n",
    "import time\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.feature_selection import RFE, VarianceThreshold, SelectFromModel\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression, mutual_info_classif, chi2\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "from sklearn.preprocessing import KBinsDiscretizer, scale\n",
    "\n",
    "#Handle annoying warnings\n",
    "import warnings, sklearn.exceptions\n",
    "warnings.filterwarnings(\"ignore\", category=sklearn.exceptions.ConvergenceWarning)\n",
    "\n",
    "\n",
    "#############################################################################\n",
    "#\n",
    "# Global parameters\n",
    "#\n",
    "#####################\n",
    "\n",
    "target_idx=0                                        #Index of Target variable\n",
    "cross_val=1                                         #Control Switch for CV                                                                                                                                                      \n",
    "norm_target=0                                       #Normalize target switch\n",
    "norm_features=0                                     #Normalize target switch\n",
    "binning=1                                           #Control Switch for Bin Target\n",
    "bin_cnt=2                                           #If bin target, this sets number of classes\n",
    "feat_select=1                                       #Control Switch for Feature Selection                                                                                   \n",
    "fs_type=2                                           #Feature Selection type (1=Stepwise Backwards Removal, 2=Wrapper Select, 3=Univariate Selection)                        \n",
    "lv_filter=0                                         #Control switch for low variance filter on features\n",
    "feat_start=1                                        #Start column of features\n",
    "k_cnt=5                                             #Number of 'Top k' best ranked features to select, only applies for fs_types 1 and 3\n",
    "\n",
    "#Set global model parameters\n",
    "rand_st=1                                           #Set Random State variable for randomizing splits on runs\n",
    "\n",
    "\n",
    "#############################################################################\n",
    "#\n",
    "# Load Data\n",
    "#\n",
    "#####################\n",
    "\n",
    "file1= csv.reader(open('brfss2015_cleaned.csv'), delimiter=',', quotechar='\"')\n",
    "\n",
    "#Read Header Line\n",
    "header=next(file1)            \n",
    "\n",
    "#Read data\n",
    "data=[]\n",
    "target=[]\n",
    "for row in file1:\n",
    "    #Load Target\n",
    "    if row[target_idx]=='':                         #If target is blank, skip row                       \n",
    "        continue\n",
    "    else:\n",
    "        target.append(float(row[target_idx]))       #If pre-binned class, change float to int\n",
    "\n",
    "    #Load row into temp array, cast columns  \n",
    "    temp=[]\n",
    "                 \n",
    "    for j in range(feat_start,len(header)):\n",
    "        if row[j]=='':\n",
    "            temp.append(float())\n",
    "        else:\n",
    "            temp.append(float(row[j]))\n",
    "\n",
    "    #Load temp into Data array\n",
    "    data.append(temp)\n",
    "  \n",
    "#Test Print\n",
    "print(header)\n",
    "print(len(target),len(data))\n",
    "print('\\n')\n",
    "\n",
    "data_np=np.asarray(data)\n",
    "target_np=np.asarray(target)\n",
    "\n",
    "\n",
    "#############################################################################\n",
    "#\n",
    "# Preprocess data\n",
    "#\n",
    "##########################################\n",
    "\n",
    "if norm_target==1:\n",
    "    #Target normalization for continuous values\n",
    "    target_np=scale(target_np)\n",
    "\n",
    "if norm_features==1:\n",
    "    #Feature normalization for continuous values\n",
    "    data_np=scale(data_np)\n",
    "\n",
    "'''if binning==1:\n",
    "    #Discretize Target variable with KBinsDiscretizer\n",
    "    enc = KBinsDiscretizer(n_bins=[bin_cnt], encode='ordinal', strategy='quantile')                         #Strategy here is important, quantile creating equal bins, but kmeans prob being more valid \"clusters\"\n",
    "    target_np_bin = enc.fit_transform(target_np.reshape(-1,1))\n",
    "\n",
    "    #Get Bin min/max\n",
    "    temp=[[] for x in range(bin_cnt+1)]\n",
    "    for i in range(len(target_np)):\n",
    "        for j in range(bin_cnt):\n",
    "            if target_np_bin[i]==j:\n",
    "                temp[j].append(target_np[i])\n",
    "\n",
    "    for j in range(bin_cnt):\n",
    "        print('Bin', j, ':', min(temp[j]), max(temp[j]), len(temp[j]))\n",
    "    print('\\n')\n",
    "\n",
    "    #Convert Target array back to correct shape\n",
    "    target_np=np.ravel(target_np_bin)'''\n",
    "\n",
    "\n",
    "#############################################################################\n",
    "#\n",
    "# Feature Selection\n",
    "#\n",
    "##########################################\n",
    "\n",
    "#Low Variance Filter\n",
    "if lv_filter==1:\n",
    "    print('--LOW VARIANCE FILTER ON--', '\\n')\n",
    "    \n",
    "    #LV Threshold\n",
    "    sel = VarianceThreshold(threshold=0.5)                                      #Removes any feature with less than 20% variance\n",
    "    fit_mod=sel.fit(data_np)\n",
    "    fitted=sel.transform(data_np)\n",
    "    sel_idx=fit_mod.get_support()\n",
    "\n",
    "    #Get lists of selected and non-selected features (names and indexes)\n",
    "    temp=[]\n",
    "    temp_idx=[]\n",
    "    temp_del=[]\n",
    "    for i in range(len(data_np[0])):\n",
    "        if sel_idx[i]==1:                                                           #Selected Features get added to temp header\n",
    "            temp.append(header[i+feat_start])\n",
    "            temp_idx.append(i)\n",
    "        else:                                                                       #Indexes of non-selected features get added to delete array\n",
    "            temp_del.append(i)\n",
    "\n",
    "    print('Selected', temp)\n",
    "    print('Features (total, selected):', len(data_np[0]), len(temp))\n",
    "    print('\\n')\n",
    "\n",
    "    #Filter selected columns from original dataset\n",
    "    header = header[0:feat_start]\n",
    "    for field in temp:\n",
    "        header.append(field)\n",
    "    data_np = np.delete(data_np, temp_del, axis=1)                                 #Deletes non-selected features by index\n",
    "\n",
    "\n",
    "#Feature Selection\n",
    "if feat_select==1:\n",
    "    '''Three steps:\n",
    "       1) Run Feature Selection\n",
    "       2) Get lists of selected and non-selected features\n",
    "       3) Filter columns from original dataset\n",
    "       '''\n",
    "    \n",
    "    print('--FEATURE SELECTION ON--', '\\n')\n",
    "    \n",
    "    ##1) Run Feature Selection #######\n",
    "    if fs_type==1:\n",
    "        #Stepwise Recursive Backwards Feature removal\n",
    "        if binning==1:\n",
    "            clf = RandomForestClassifier(n_estimators=200, max_depth=None, min_samples_split=3, criterion='entropy', random_state=rand_st)\n",
    "            sel = RFE(clf, n_features_to_select=k_cnt, step=.1)\n",
    "            print('Stepwise Recursive Backwards - Random Forest: ')\n",
    "        if binning==0:\n",
    "            rgr = RandomForestRegressor(n_estimators=500, max_depth=None, min_samples_split=3, criterion='mse', random_state=rand_st)\n",
    "            sel = RFE(rgr, n_features_to_select=k_cnt, step=.1)\n",
    "            print('Stepwise Recursive Backwards - Random Forest: ')\n",
    "            \n",
    "        fit_mod=sel.fit(data_np, target_np)\n",
    "        print(sel.ranking_)\n",
    "        sel_idx=fit_mod.get_support()      \n",
    "\n",
    "    if fs_type==2:\n",
    "        #Wrapper Select via model\n",
    "        if binning==1:\n",
    "            clf = GradientBoostingClassifier(n_estimators=100, loss='deviance', learning_rate=0.1, max_depth=3, min_samples_split=3, random_state=rand_st)\n",
    "            sel = SelectFromModel(clf, prefit=False, threshold='mean', max_features=None)                                                           #to select only based on max_features, set to integer value and set threshold=-np.inf\n",
    "            print ('Wrapper Select: ')\n",
    "        if binning==0:\n",
    "            rgr = '''Unused in this homework'''\n",
    "            sel = SelectFromModel(rgr, prefit=False, threshold='mean', max_features=None)\n",
    "            print ('Wrapper Select: ')\n",
    "            \n",
    "        fit_mod=sel.fit(data_np, target_np)    \n",
    "        sel_idx=fit_mod.get_support()\n",
    "\n",
    "    if fs_type==3:\n",
    "        if binning==1:                                                              ######Only work if the Target is binned###########\n",
    "            #Univariate Feature Selection - Chi-squared\n",
    "            sel=SelectKBest(chi2, k=k_cnt)\n",
    "            fit_mod=sel.fit(data_np, target_np)                                         #will throw error if any negative values in features, so turn off feature normalization, or switch to mutual_info_classif\n",
    "            print ('Univariate Feature Selection - Chi2: ')\n",
    "            sel_idx=fit_mod.get_support()\n",
    "\n",
    "        if binning==0:                                                              ######Only work if the Target is continuous###########\n",
    "            #Univariate Feature Selection - Mutual Info Regression\n",
    "            sel=SelectKBest(mutual_info_regression, k=k_cnt)\n",
    "            fit_mod=sel.fit(data_np, target_np)\n",
    "            print ('Univariate Feature Selection - Mutual Info: ')\n",
    "            sel_idx=fit_mod.get_support()\n",
    "\n",
    "        #Print ranked variables out sorted\n",
    "        temp=[]\n",
    "        scores=fit_mod.scores_\n",
    "        for i in range(feat_start, len(header)):            \n",
    "            temp.append([header[i], float(scores[i-feat_start])])\n",
    "\n",
    "        print('Ranked Features')\n",
    "        temp_sort=sorted(temp, key=itemgetter(1), reverse=True)\n",
    "        for i in range(len(temp_sort)):\n",
    "            print(i, temp_sort[i][0], ':', temp_sort[i][1])\n",
    "        print('\\n')\n",
    "\n",
    "    ##2) Get lists of selected and non-selected features (names and indexes) #######\n",
    "    temp=[]\n",
    "    temp_idx=[]\n",
    "    temp_del=[]\n",
    "    for i in range(len(data_np[0])):\n",
    "        if sel_idx[i]==1:                                                           #Selected Features get added to temp header\n",
    "            temp.append(header[i+feat_start])\n",
    "            temp_idx.append(i)\n",
    "        else:                                                                       #Indexes of non-selected features get added to delete array\n",
    "            temp_del.append(i)\n",
    "    print('Selected', temp)\n",
    "    print('Features (total/selected):', len(data_np[0]), len(temp))\n",
    "    print('\\n')\n",
    "            \n",
    "                \n",
    "    ##3) Filter selected columns from original dataset #########\n",
    "    header = header[0:feat_start]\n",
    "    for field in temp:\n",
    "        header.append(field)\n",
    "    data_np = np.delete(data_np, temp_del, axis=1)                                 #Deletes non-selected features by index)\n",
    "    \n",
    "    \n",
    "\n",
    "#############################################################################\n",
    "#\n",
    "# Train SciKit Models\n",
    "#\n",
    "##########################################\n",
    "\n",
    "print('--ML Model Output--', '\\n')\n",
    "\n",
    "#Test/Train split\n",
    "data_train, data_test, target_train, target_test = train_test_split(data_np, target_np, test_size=0.35)\n",
    "\n",
    "####Classifiers####\n",
    "if binning==1 and cross_val==0:\n",
    "    #SciKit\n",
    "    '''Test/Train split unused in this homework, skip down to CV section'''\n",
    " \n",
    "\n",
    "                                                                                                                         \n",
    " \n",
    "####Cross-Val Classifiers####\n",
    "if binning==1 and cross_val==1:\n",
    "    #Setup Crossval classifier scorers\n",
    "    scorers = {'Accuracy': 'accuracy', 'roc_auc': 'roc_auc'}                                                                                                                \n",
    "    \n",
    "    #SciKit Gradient Boosting - Cross Val\n",
    "    start_ts=time.time()\n",
    "    clf=GradientBoostingClassifier(n_estimators=100, loss='deviance', learning_rate=0.1, max_depth=3, min_samples_split=3, random_state=rand_st)\n",
    "    scores= cross_validate(clf, data_np, target_np, scoring=scorers, cv=5)\n",
    "\n",
    "    scores_Acc = scores['test_Accuracy']                                                                                                                                    \n",
    "    print(\"Gradient Boosting - Random Forest Acc: %0.2f (+/- %0.2f)\" % (scores_Acc.mean(), scores_Acc.std() * 2))                                                                                                    \n",
    "    scores_AUC= scores['test_roc_auc']                                                                     #Only works with binary classes, not multiclass                  \n",
    "    print(\"Gradient Boosting - Random Forest AUC: %0.2f (+/- %0.2f)\" % (scores_AUC.mean(), scores_AUC.std() * 2))                           \n",
    "    print(\"GB - CV Runtime:\", time.time()-start_ts)\n",
    "\n",
    "\n",
    "    #SciKit Ada Boosting - Cross Val\n",
    "    start_ts=time.time()\n",
    "    clf=AdaBoostClassifier(n_estimators=100, base_estimator=None, learning_rate=0.1, random_state=rand_st)\n",
    "    scores= cross_validate(clf, data_np, target_np, scoring=scorers, cv=5)\n",
    "\n",
    "    scores_Acc = scores['test_Accuracy']                                                                                                                                    \n",
    "    print(\"Ada Boost - Random Forest Acc: %0.2f (+/- %0.2f)\" % (scores_Acc.mean(), scores_Acc.std() * 2))                                                                                                    \n",
    "    scores_AUC= scores['test_roc_auc']                                                                     #Only works with binary classes, not multiclass                  \n",
    "    print(\"Ada Boost - Random Forest AUC: %0.2f (+/- %0.2f)\" % (scores_AUC.mean(), scores_AUC.std() * 2))                           \n",
    "    print(\"Ada - CV Runtime:\", time.time()-start_ts)\n",
    "\n",
    "\n",
    "    #SciKit Neural Network - Cross Val\n",
    "    start_ts=time.time()\n",
    "    clf=MLPClassifier(activation='logistic', solver='adam', alpha=0.0001, max_iter=1000, hidden_layer_sizes=(10,), random_state=rand_st)\n",
    "    scores= cross_validate(clf, data_np, target_np, scoring=scorers, cv=5)\n",
    "\n",
    "    scores_Acc = scores['test_Accuracy']                                                                                                                                    \n",
    "    print(\"Neural Network - Acc: %0.2f (+/- %0.2f)\" % (scores_Acc.mean(), scores_Acc.std() * 2))                                                                                                    \n",
    "    scores_AUC= scores['test_roc_auc']                                                                     #Only works with binary classes, not multiclass                  \n",
    "    print(\"Neural Network - AUC: %0.2f (+/- %0.2f)\" % (scores_AUC.mean(), scores_AUC.std() * 2))                           \n",
    "    print(\"NN - CV Runtime:\", time.time()-start_ts) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iwZvYx6Qxmch"
   },
   "source": [
    "### AdaBoost, GradientBoost, and Neural Network - w/ Feature Selection - 50-50 Dataset\n",
    "Gradient Boosting:\n",
    "* Gradient Boosting - Acc: 0.76 (+/- 0.01)\n",
    "* Gradient Boosting - AUC: 0.84 (+/- 0.01)\n",
    "* GB - CV Runtime: 8.77 seconds\n",
    "\n",
    "Ada Boost:\n",
    "* Ada Boost - Acc: 0.76 (+/- 0.01)\n",
    "* Ada Boost - AUC: 0.83 (+/- 0.01)\n",
    "* Ada - CV Runtime: 8.85 seconds\n",
    "\n",
    "Neural Network:\n",
    "* Neural Network - Acc: 0.76 (+/- 0.01)\n",
    "* Neural Network - AUC: 0.84 (+/- 0.01)\n",
    "* NN - CV Runtime: 18.77 seconds\n",
    "\n",
    "Notes:\n",
    "* Selected Features: ['HighBP', 'HighChol', 'GenHlth', 'Sex', 'Age']\n",
    "* Features (total/selected): 21 5\n",
    "* w/o feature selection was also tested, but there was no significant change in ACC or AUC, just runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hWnl5Lvixml6",
    "outputId": "0e655c41-0c50-4ee5-bb59-faa4222334e3"
   },
   "outputs": [],
   "source": [
    "#SciKit DSC540 HW1\n",
    "'''created by Casey Bennett 2018, www.CaseyBennett.com'''\n",
    "\n",
    "import sys\n",
    "import csv\n",
    "import math\n",
    "import numpy as np\n",
    "from operator import itemgetter\n",
    "import time\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.feature_selection import RFE, VarianceThreshold, SelectFromModel\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression, mutual_info_classif, chi2\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "from sklearn.preprocessing import KBinsDiscretizer, scale\n",
    "\n",
    "#Handle annoying warnings\n",
    "import warnings, sklearn.exceptions\n",
    "warnings.filterwarnings(\"ignore\", category=sklearn.exceptions.ConvergenceWarning)\n",
    "\n",
    "\n",
    "#############################################################################\n",
    "#\n",
    "# Global parameters\n",
    "#\n",
    "#####################\n",
    "\n",
    "target_idx=0                                        #Index of Target variable\n",
    "cross_val=1                                         #Control Switch for CV                                                                                                                                                      \n",
    "norm_target=0                                       #Normalize target switch\n",
    "norm_features=0                                     #Normalize target switch\n",
    "binning=1                                           #Control Switch for Bin Target\n",
    "bin_cnt=2                                           #If bin target, this sets number of classes\n",
    "feat_select=0                                       #Control Switch for Feature Selection                                                                                   \n",
    "fs_type=2                                           #Feature Selection type (1=Stepwise Backwards Removal, 2=Wrapper Select, 3=Univariate Selection)                        \n",
    "lv_filter=0                                         #Control switch for low variance filter on features\n",
    "feat_start=1                                        #Start column of features\n",
    "k_cnt=5                                             #Number of 'Top k' best ranked features to select, only applies for fs_types 1 and 3\n",
    "\n",
    "#Set global model parameters\n",
    "rand_st=1                                           #Set Random State variable for randomizing splits on runs\n",
    "\n",
    "\n",
    "#############################################################################\n",
    "#\n",
    "# Load Data\n",
    "#\n",
    "#####################\n",
    "\n",
    "file1= csv.reader(open('brfss2015_5050_cleaned.csv'), delimiter=',', quotechar='\"')\n",
    "\n",
    "#Read Header Line\n",
    "header=next(file1)            \n",
    "\n",
    "#Read data\n",
    "data=[]\n",
    "target=[]\n",
    "for row in file1:\n",
    "    #Load Target\n",
    "    if row[target_idx]=='':                         #If target is blank, skip row                       \n",
    "        continue\n",
    "    else:\n",
    "        target.append(float(row[target_idx]))       #If pre-binned class, change float to int\n",
    "\n",
    "    #Load row into temp array, cast columns  \n",
    "    temp=[]\n",
    "                 \n",
    "    for j in range(feat_start,len(header)):\n",
    "        if row[j]=='':\n",
    "            temp.append(float())\n",
    "        else:\n",
    "            temp.append(float(row[j]))\n",
    "\n",
    "    #Load temp into Data array\n",
    "    data.append(temp)\n",
    "  \n",
    "#Test Print\n",
    "print(header)\n",
    "print(len(target),len(data))\n",
    "print('\\n')\n",
    "\n",
    "data_np=np.asarray(data)\n",
    "target_np=np.asarray(target)\n",
    "\n",
    "\n",
    "#############################################################################\n",
    "#\n",
    "# Preprocess data\n",
    "#\n",
    "##########################################\n",
    "\n",
    "if norm_target==1:\n",
    "    #Target normalization for continuous values\n",
    "    target_np=scale(target_np)\n",
    "\n",
    "if norm_features==1:\n",
    "    #Feature normalization for continuous values\n",
    "    data_np=scale(data_np)\n",
    "\n",
    "'''if binning==1:\n",
    "    #Discretize Target variable with KBinsDiscretizer\n",
    "    enc = KBinsDiscretizer(n_bins=[bin_cnt], encode='ordinal', strategy='quantile')                         #Strategy here is important, quantile creating equal bins, but kmeans prob being more valid \"clusters\"\n",
    "    target_np_bin = enc.fit_transform(target_np.reshape(-1,1))\n",
    "\n",
    "    #Get Bin min/max\n",
    "    temp=[[] for x in range(bin_cnt+1)]\n",
    "    for i in range(len(target_np)):\n",
    "        for j in range(bin_cnt):\n",
    "            if target_np_bin[i]==j:\n",
    "                temp[j].append(target_np[i])\n",
    "\n",
    "    for j in range(bin_cnt):\n",
    "        print('Bin', j, ':', min(temp[j]), max(temp[j]), len(temp[j]))\n",
    "    print('\\n')\n",
    "\n",
    "    #Convert Target array back to correct shape\n",
    "    target_np=np.ravel(target_np_bin)'''\n",
    "\n",
    "\n",
    "#############################################################################\n",
    "#\n",
    "# Feature Selection\n",
    "#\n",
    "##########################################\n",
    "\n",
    "#Low Variance Filter\n",
    "if lv_filter==1:\n",
    "    print('--LOW VARIANCE FILTER ON--', '\\n')\n",
    "    \n",
    "    #LV Threshold\n",
    "    sel = VarianceThreshold(threshold=0.5)                                      #Removes any feature with less than 20% variance\n",
    "    fit_mod=sel.fit(data_np)\n",
    "    fitted=sel.transform(data_np)\n",
    "    sel_idx=fit_mod.get_support()\n",
    "\n",
    "    #Get lists of selected and non-selected features (names and indexes)\n",
    "    temp=[]\n",
    "    temp_idx=[]\n",
    "    temp_del=[]\n",
    "    for i in range(len(data_np[0])):\n",
    "        if sel_idx[i]==1:                                                           #Selected Features get added to temp header\n",
    "            temp.append(header[i+feat_start])\n",
    "            temp_idx.append(i)\n",
    "        else:                                                                       #Indexes of non-selected features get added to delete array\n",
    "            temp_del.append(i)\n",
    "\n",
    "    print('Selected', temp)\n",
    "    print('Features (total, selected):', len(data_np[0]), len(temp))\n",
    "    print('\\n')\n",
    "\n",
    "    #Filter selected columns from original dataset\n",
    "    header = header[0:feat_start]\n",
    "    for field in temp:\n",
    "        header.append(field)\n",
    "    data_np = np.delete(data_np, temp_del, axis=1)                                 #Deletes non-selected features by index\n",
    "\n",
    "\n",
    "#Feature Selection\n",
    "if feat_select==1:\n",
    "    '''Three steps:\n",
    "       1) Run Feature Selection\n",
    "       2) Get lists of selected and non-selected features\n",
    "       3) Filter columns from original dataset\n",
    "       '''\n",
    "    \n",
    "    print('--FEATURE SELECTION ON--', '\\n')\n",
    "    \n",
    "    ##1) Run Feature Selection #######\n",
    "    if fs_type==1:\n",
    "        #Stepwise Recursive Backwards Feature removal\n",
    "        if binning==1:\n",
    "            clf = RandomForestClassifier(n_estimators=200, max_depth=None, min_samples_split=3, criterion='entropy', random_state=rand_st)\n",
    "            sel = RFE(clf, n_features_to_select=k_cnt, step=.1)\n",
    "            print('Stepwise Recursive Backwards - Random Forest: ')\n",
    "        if binning==0:\n",
    "            rgr = RandomForestRegressor(n_estimators=500, max_depth=None, min_samples_split=3, criterion='mse', random_state=rand_st)\n",
    "            sel = RFE(rgr, n_features_to_select=k_cnt, step=.1)\n",
    "            print('Stepwise Recursive Backwards - Random Forest: ')\n",
    "            \n",
    "        fit_mod=sel.fit(data_np, target_np)\n",
    "        print(sel.ranking_)\n",
    "        sel_idx=fit_mod.get_support()      \n",
    "\n",
    "    if fs_type==2:\n",
    "        #Wrapper Select via model\n",
    "        if binning==1:\n",
    "            clf = GradientBoostingClassifier(n_estimators=100, loss='deviance', learning_rate=0.1, max_depth=3, min_samples_split=3, random_state=rand_st)\n",
    "            sel = SelectFromModel(clf, prefit=False, threshold='mean', max_features=None)                                                           #to select only based on max_features, set to integer value and set threshold=-np.inf\n",
    "            print ('Wrapper Select: ')\n",
    "        if binning==0:\n",
    "            rgr = '''Unused in this homework'''\n",
    "            sel = SelectFromModel(rgr, prefit=False, threshold='mean', max_features=None)\n",
    "            print ('Wrapper Select: ')\n",
    "            \n",
    "        fit_mod=sel.fit(data_np, target_np)    \n",
    "        sel_idx=fit_mod.get_support()\n",
    "\n",
    "    if fs_type==3:\n",
    "        if binning==1:                                                              ######Only work if the Target is binned###########\n",
    "            #Univariate Feature Selection - Chi-squared\n",
    "            sel=SelectKBest(chi2, k=k_cnt)\n",
    "            fit_mod=sel.fit(data_np, target_np)                                         #will throw error if any negative values in features, so turn off feature normalization, or switch to mutual_info_classif\n",
    "            print ('Univariate Feature Selection - Chi2: ')\n",
    "            sel_idx=fit_mod.get_support()\n",
    "\n",
    "        if binning==0:                                                              ######Only work if the Target is continuous###########\n",
    "            #Univariate Feature Selection - Mutual Info Regression\n",
    "            sel=SelectKBest(mutual_info_regression, k=k_cnt)\n",
    "            fit_mod=sel.fit(data_np, target_np)\n",
    "            print ('Univariate Feature Selection - Mutual Info: ')\n",
    "            sel_idx=fit_mod.get_support()\n",
    "\n",
    "        #Print ranked variables out sorted\n",
    "        temp=[]\n",
    "        scores=fit_mod.scores_\n",
    "        for i in range(feat_start, len(header)):            \n",
    "            temp.append([header[i], float(scores[i-feat_start])])\n",
    "\n",
    "        print('Ranked Features')\n",
    "        temp_sort=sorted(temp, key=itemgetter(1), reverse=True)\n",
    "        for i in range(len(temp_sort)):\n",
    "            print(i, temp_sort[i][0], ':', temp_sort[i][1])\n",
    "        print('\\n')\n",
    "\n",
    "    ##2) Get lists of selected and non-selected features (names and indexes) #######\n",
    "    temp=[]\n",
    "    temp_idx=[]\n",
    "    temp_del=[]\n",
    "    for i in range(len(data_np[0])):\n",
    "        if sel_idx[i]==1:                                                           #Selected Features get added to temp header\n",
    "            temp.append(header[i+feat_start])\n",
    "            temp_idx.append(i)\n",
    "        else:                                                                       #Indexes of non-selected features get added to delete array\n",
    "            temp_del.append(i)\n",
    "    print('Selected', temp)\n",
    "    print('Features (total/selected):', len(data_np[0]), len(temp))\n",
    "    print('\\n')\n",
    "            \n",
    "                \n",
    "    ##3) Filter selected columns from original dataset #########\n",
    "    header = header[0:feat_start]\n",
    "    for field in temp:\n",
    "        header.append(field)\n",
    "    data_np = np.delete(data_np, temp_del, axis=1)                                 #Deletes non-selected features by index)\n",
    "    \n",
    "    \n",
    "\n",
    "#############################################################################\n",
    "#\n",
    "# Train SciKit Models\n",
    "#\n",
    "##########################################\n",
    "\n",
    "print('--ML Model Output--', '\\n')\n",
    "\n",
    "#Test/Train split\n",
    "data_train, data_test, target_train, target_test = train_test_split(data_np, target_np, test_size=0.35)\n",
    "\n",
    "####Classifiers####\n",
    "if binning==1 and cross_val==0:\n",
    "    #SciKit\n",
    "    '''Test/Train split unused in this homework, skip down to CV section'''\n",
    " \n",
    "\n",
    "                                                                                                                         \n",
    " \n",
    "####Cross-Val Classifiers####\n",
    "if binning==1 and cross_val==1:\n",
    "    #Setup Crossval classifier scorers\n",
    "    scorers = {'Accuracy': 'accuracy', 'roc_auc': 'roc_auc'}                                                                                                                \n",
    "    \n",
    "    #SciKit Gradient Boosting - Cross Val\n",
    "    start_ts=time.time()\n",
    "    clf=GradientBoostingClassifier(n_estimators=100, loss='deviance', learning_rate=0.1, max_depth=3, min_samples_split=3, random_state=rand_st)\n",
    "    scores= cross_validate(clf, data_np, target_np, scoring=scorers, cv=5)\n",
    "\n",
    "    scores_Acc = scores['test_Accuracy']                                                                                                                                    \n",
    "    print(\"Gradient Boosting - Random Forest Acc: %0.2f (+/- %0.2f)\" % (scores_Acc.mean(), scores_Acc.std() * 2))                                                                                                    \n",
    "    scores_AUC= scores['test_roc_auc']                                                                     #Only works with binary classes, not multiclass                  \n",
    "    print(\"Gradient Boosting - Random Forest AUC: %0.2f (+/- %0.2f)\" % (scores_AUC.mean(), scores_AUC.std() * 2))                           \n",
    "    print(\"GB - CV Runtime:\", time.time()-start_ts)\n",
    "\n",
    "\n",
    "    #SciKit Ada Boosting - Cross Val\n",
    "    start_ts=time.time()\n",
    "    clf=AdaBoostClassifier(n_estimators=100, base_estimator=None, learning_rate=0.1, random_state=rand_st)\n",
    "    scores= cross_validate(clf, data_np, target_np, scoring=scorers, cv=5)\n",
    "\n",
    "    scores_Acc = scores['test_Accuracy']                                                                                                                                    \n",
    "    print(\"Ada Boost - Random Forest Acc: %0.2f (+/- %0.2f)\" % (scores_Acc.mean(), scores_Acc.std() * 2))                                                                                                    \n",
    "    scores_AUC= scores['test_roc_auc']                                                                     #Only works with binary classes, not multiclass                  \n",
    "    print(\"Ada Boost - Random Forest AUC: %0.2f (+/- %0.2f)\" % (scores_AUC.mean(), scores_AUC.std() * 2))                           \n",
    "    print(\"Ada - CV Runtime:\", time.time()-start_ts)\n",
    "\n",
    "\n",
    "    #SciKit Neural Network - Cross Val\n",
    "    start_ts=time.time()\n",
    "    clf=MLPClassifier(activation='logistic', solver='adam', alpha=0.0001, max_iter=1000, hidden_layer_sizes=(10,), random_state=rand_st)\n",
    "    scores= cross_validate(clf, data_np, target_np, scoring=scorers, cv=5)\n",
    "\n",
    "    scores_Acc = scores['test_Accuracy']                                                                                                                                    \n",
    "    print(\"Neural Network - Acc: %0.2f (+/- %0.2f)\" % (scores_Acc.mean(), scores_Acc.std() * 2))                                                                                                    \n",
    "    scores_AUC= scores['test_roc_auc']                                                                     #Only works with binary classes, not multiclass                  \n",
    "    print(\"Neural Network - AUC: %0.2f (+/- %0.2f)\" % (scores_AUC.mean(), scores_AUC.std() * 2))                           \n",
    "    print(\"NN - CV Runtime:\", time.time()-start_ts) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ogba1a0zx9Df"
   },
   "source": [
    "### AdaBoost, GradientBoost, and Neural Network - w/ Feature Selection - 60-40 Dataset\n",
    "Gradient Boosting:\n",
    "* Gradient Boosting - Acc: 0.78 (+/- 0.01)\n",
    "* Gradient Boosting - AUC: 0.84 (+/- 0.01)\n",
    "* GB - CV Runtime: 13.71 seconds\n",
    "\n",
    "Ada Boost:\n",
    "* Ada Boost - Acc: 0.77 (+/- 0.01)\n",
    "* Ada Boost - AUC: 0.84 (+/- 0.01)\n",
    "* Ada - CV Runtime: 13.24 seconds\n",
    "\n",
    "Neural Network:\n",
    "* Neural Network - Acc: 0.78 (+/- 0.01)\n",
    "* Neural Network - AUC: 0.84 (+/- 0.01\n",
    "* NN - CV Runtime: 21.01 seconds\n",
    "\n",
    "Notes: \n",
    "* Selected Features['HighBP', 'HighChol', 'Stroke', 'GenHlth', 'Sex', 'Age']\n",
    "* Features (total/selected): 21 6\n",
    "* w/o feature selection was also tested, but there was no significant change in ACC or AUC, just runtime.\n",
    "* Changes to GB max_depth did not improve ACC or AUC.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m-S2IZGrr7jX",
    "outputId": "f8dddc0a-bb94-4556-d16b-f344aab49248"
   },
   "outputs": [],
   "source": [
    "#SciKit DSC540 HW1\n",
    "'''created by Casey Bennett 2018, www.CaseyBennett.com'''\n",
    "\n",
    "import sys\n",
    "import csv\n",
    "import math\n",
    "import numpy as np\n",
    "from operator import itemgetter\n",
    "import time\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.feature_selection import RFE, VarianceThreshold, SelectFromModel\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression, mutual_info_classif, chi2\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "from sklearn.preprocessing import KBinsDiscretizer, scale\n",
    "\n",
    "#Handle annoying warnings\n",
    "import warnings, sklearn.exceptions\n",
    "warnings.filterwarnings(\"ignore\", category=sklearn.exceptions.ConvergenceWarning)\n",
    "\n",
    "\n",
    "#############################################################################\n",
    "#\n",
    "# Global parameters\n",
    "#\n",
    "#####################\n",
    "\n",
    "target_idx=0                                        #Index of Target variable\n",
    "cross_val=1                                         #Control Switch for CV                                                                                                                                                      \n",
    "norm_target=0                                       #Normalize target switch\n",
    "norm_features=0                                     #Normalize target switch\n",
    "binning=1                                           #Control Switch for Bin Target\n",
    "bin_cnt=2                                           #If bin target, this sets number of classes\n",
    "feat_select=1                                       #Control Switch for Feature Selection                                                                                   \n",
    "fs_type=2                                           #Feature Selection type (1=Stepwise Backwards Removal, 2=Wrapper Select, 3=Univariate Selection)                        \n",
    "lv_filter=0                                         #Control switch for low variance filter on features\n",
    "feat_start=1                                        #Start column of features\n",
    "k_cnt=5                                             #Number of 'Top k' best ranked features to select, only applies for fs_types 1 and 3\n",
    "\n",
    "#Set global model parameters\n",
    "rand_st=1                                           #Set Random State variable for randomizing splits on runs\n",
    "\n",
    "\n",
    "#############################################################################\n",
    "#\n",
    "# Load Data\n",
    "#\n",
    "#####################\n",
    "\n",
    "file1= csv.reader(open('brfss2015_6040_cleaned.csv'), delimiter=',', quotechar='\"')\n",
    "\n",
    "#Read Header Line\n",
    "header=next(file1)            \n",
    "\n",
    "#Read data\n",
    "data=[]\n",
    "target=[]\n",
    "for row in file1:\n",
    "    #Load Target\n",
    "    if row[target_idx]=='':                         #If target is blank, skip row                       \n",
    "        continue\n",
    "    else:\n",
    "        target.append(float(row[target_idx]))       #If pre-binned class, change float to int\n",
    "\n",
    "    #Load row into temp array, cast columns  \n",
    "    temp=[]\n",
    "                 \n",
    "    for j in range(feat_start,len(header)):\n",
    "        if row[j]=='':\n",
    "            temp.append(float())\n",
    "        else:\n",
    "            temp.append(float(row[j]))\n",
    "\n",
    "    #Load temp into Data array\n",
    "    data.append(temp)\n",
    "  \n",
    "#Test Print\n",
    "print(header)\n",
    "print(len(target),len(data))\n",
    "print('\\n')\n",
    "\n",
    "data_np=np.asarray(data)\n",
    "target_np=np.asarray(target)\n",
    "\n",
    "\n",
    "#############################################################################\n",
    "#\n",
    "# Preprocess data\n",
    "#\n",
    "##########################################\n",
    "\n",
    "if norm_target==1:\n",
    "    #Target normalization for continuous values\n",
    "    target_np=scale(target_np)\n",
    "\n",
    "if norm_features==1:\n",
    "    #Feature normalization for continuous values\n",
    "    data_np=scale(data_np)\n",
    "\n",
    "'''if binning==1:\n",
    "    #Discretize Target variable with KBinsDiscretizer\n",
    "    enc = KBinsDiscretizer(n_bins=[bin_cnt], encode='ordinal', strategy='quantile')                         #Strategy here is important, quantile creating equal bins, but kmeans prob being more valid \"clusters\"\n",
    "    target_np_bin = enc.fit_transform(target_np.reshape(-1,1))\n",
    "\n",
    "    #Get Bin min/max\n",
    "    temp=[[] for x in range(bin_cnt+1)]\n",
    "    for i in range(len(target_np)):\n",
    "        for j in range(bin_cnt):\n",
    "            if target_np_bin[i]==j:\n",
    "                temp[j].append(target_np[i])\n",
    "\n",
    "    for j in range(bin_cnt):\n",
    "        print('Bin', j, ':', min(temp[j]), max(temp[j]), len(temp[j]))\n",
    "    print('\\n')\n",
    "\n",
    "    #Convert Target array back to correct shape\n",
    "    target_np=np.ravel(target_np_bin)'''\n",
    "\n",
    "\n",
    "#############################################################################\n",
    "#\n",
    "# Feature Selection\n",
    "#\n",
    "##########################################\n",
    "\n",
    "#Low Variance Filter\n",
    "if lv_filter==1:\n",
    "    print('--LOW VARIANCE FILTER ON--', '\\n')\n",
    "    \n",
    "    #LV Threshold\n",
    "    sel = VarianceThreshold(threshold=0.5)                                      #Removes any feature with less than 20% variance\n",
    "    fit_mod=sel.fit(data_np)\n",
    "    fitted=sel.transform(data_np)\n",
    "    sel_idx=fit_mod.get_support()\n",
    "\n",
    "    #Get lists of selected and non-selected features (names and indexes)\n",
    "    temp=[]\n",
    "    temp_idx=[]\n",
    "    temp_del=[]\n",
    "    for i in range(len(data_np[0])):\n",
    "        if sel_idx[i]==1:                                                           #Selected Features get added to temp header\n",
    "            temp.append(header[i+feat_start])\n",
    "            temp_idx.append(i)\n",
    "        else:                                                                       #Indexes of non-selected features get added to delete array\n",
    "            temp_del.append(i)\n",
    "\n",
    "    print('Selected', temp)\n",
    "    print('Features (total, selected):', len(data_np[0]), len(temp))\n",
    "    print('\\n')\n",
    "\n",
    "    #Filter selected columns from original dataset\n",
    "    header = header[0:feat_start]\n",
    "    for field in temp:\n",
    "        header.append(field)\n",
    "    data_np = np.delete(data_np, temp_del, axis=1)                                 #Deletes non-selected features by index\n",
    "\n",
    "\n",
    "#Feature Selection\n",
    "if feat_select==1:\n",
    "    '''Three steps:\n",
    "       1) Run Feature Selection\n",
    "       2) Get lists of selected and non-selected features\n",
    "       3) Filter columns from original dataset\n",
    "       '''\n",
    "    \n",
    "    print('--FEATURE SELECTION ON--', '\\n')\n",
    "    \n",
    "    ##1) Run Feature Selection #######\n",
    "    if fs_type==1:\n",
    "        #Stepwise Recursive Backwards Feature removal\n",
    "        if binning==1:\n",
    "            clf = RandomForestClassifier(n_estimators=200, max_depth=None, min_samples_split=3, criterion='entropy', random_state=rand_st)\n",
    "            sel = RFE(clf, n_features_to_select=k_cnt, step=.1)\n",
    "            print('Stepwise Recursive Backwards - Random Forest: ')\n",
    "        if binning==0:\n",
    "            rgr = RandomForestRegressor(n_estimators=500, max_depth=None, min_samples_split=3, criterion='mse', random_state=rand_st)\n",
    "            sel = RFE(rgr, n_features_to_select=k_cnt, step=.1)\n",
    "            print('Stepwise Recursive Backwards - Random Forest: ')\n",
    "            \n",
    "        fit_mod=sel.fit(data_np, target_np)\n",
    "        print(sel.ranking_)\n",
    "        sel_idx=fit_mod.get_support()      \n",
    "\n",
    "    if fs_type==2:\n",
    "        #Wrapper Select via model\n",
    "        if binning==1:\n",
    "            clf = GradientBoostingClassifier(n_estimators=100, loss='deviance', learning_rate=0.1, max_depth=3, min_samples_split=3, random_state=rand_st)\n",
    "            sel = SelectFromModel(clf, prefit=False, threshold='mean', max_features=None)                                                           #to select only based on max_features, set to integer value and set threshold=-np.inf\n",
    "            print ('Wrapper Select: ')\n",
    "        if binning==0:\n",
    "            rgr = '''Unused in this homework'''\n",
    "            sel = SelectFromModel(rgr, prefit=False, threshold='mean', max_features=None)\n",
    "            print ('Wrapper Select: ')\n",
    "            \n",
    "        fit_mod=sel.fit(data_np, target_np)    \n",
    "        sel_idx=fit_mod.get_support()\n",
    "\n",
    "    if fs_type==3:\n",
    "        if binning==1:                                                              ######Only work if the Target is binned###########\n",
    "            #Univariate Feature Selection - Chi-squared\n",
    "            sel=SelectKBest(chi2, k=k_cnt)\n",
    "            fit_mod=sel.fit(data_np, target_np)                                         #will throw error if any negative values in features, so turn off feature normalization, or switch to mutual_info_classif\n",
    "            print ('Univariate Feature Selection - Chi2: ')\n",
    "            sel_idx=fit_mod.get_support()\n",
    "\n",
    "        if binning==0:                                                              ######Only work if the Target is continuous###########\n",
    "            #Univariate Feature Selection - Mutual Info Regression\n",
    "            sel=SelectKBest(mutual_info_regression, k=k_cnt)\n",
    "            fit_mod=sel.fit(data_np, target_np)\n",
    "            print ('Univariate Feature Selection - Mutual Info: ')\n",
    "            sel_idx=fit_mod.get_support()\n",
    "\n",
    "        #Print ranked variables out sorted\n",
    "        temp=[]\n",
    "        scores=fit_mod.scores_\n",
    "        for i in range(feat_start, len(header)):            \n",
    "            temp.append([header[i], float(scores[i-feat_start])])\n",
    "\n",
    "        print('Ranked Features')\n",
    "        temp_sort=sorted(temp, key=itemgetter(1), reverse=True)\n",
    "        for i in range(len(temp_sort)):\n",
    "            print(i, temp_sort[i][0], ':', temp_sort[i][1])\n",
    "        print('\\n')\n",
    "\n",
    "    ##2) Get lists of selected and non-selected features (names and indexes) #######\n",
    "    temp=[]\n",
    "    temp_idx=[]\n",
    "    temp_del=[]\n",
    "    for i in range(len(data_np[0])):\n",
    "        if sel_idx[i]==1:                                                           #Selected Features get added to temp header\n",
    "            temp.append(header[i+feat_start])\n",
    "            temp_idx.append(i)\n",
    "        else:                                                                       #Indexes of non-selected features get added to delete array\n",
    "            temp_del.append(i)\n",
    "    print('Selected', temp)\n",
    "    print('Features (total/selected):', len(data_np[0]), len(temp))\n",
    "    print('\\n')\n",
    "            \n",
    "                \n",
    "    ##3) Filter selected columns from original dataset #########\n",
    "    header = header[0:feat_start]\n",
    "    for field in temp:\n",
    "        header.append(field)\n",
    "    data_np = np.delete(data_np, temp_del, axis=1)                                 #Deletes non-selected features by index)\n",
    "    \n",
    "    \n",
    "\n",
    "#############################################################################\n",
    "#\n",
    "# Train SciKit Models\n",
    "#\n",
    "##########################################\n",
    "\n",
    "print('--ML Model Output--', '\\n')\n",
    "\n",
    "#Test/Train split\n",
    "data_train, data_test, target_train, target_test = train_test_split(data_np, target_np, test_size=0.35)\n",
    "\n",
    "####Classifiers####\n",
    "if binning==1 and cross_val==0:\n",
    "    #SciKit\n",
    "    '''Test/Train split unused in this homework, skip down to CV section'''\n",
    " \n",
    "\n",
    "                                                                                                                         \n",
    " \n",
    "####Cross-Val Classifiers####\n",
    "if binning==1 and cross_val==1:\n",
    "    #Setup Crossval classifier scorers\n",
    "    scorers = {'Accuracy': 'accuracy', 'roc_auc': 'roc_auc'}                                                                                                                \n",
    "    \n",
    "    #SciKit Gradient Boosting - Cross Val\n",
    "    start_ts=time.time()\n",
    "    clf=GradientBoostingClassifier(n_estimators=100, loss='deviance', learning_rate=0.1, max_depth=3, min_samples_split=3, random_state=rand_st)\n",
    "    scores= cross_validate(clf, data_np, target_np, scoring=scorers, cv=5)\n",
    "\n",
    "    scores_Acc = scores['test_Accuracy']                                                                                                                                    \n",
    "    print(\"Gradient Boosting - Random Forest Acc: %0.2f (+/- %0.2f)\" % (scores_Acc.mean(), scores_Acc.std() * 2))                                                                                                    \n",
    "    scores_AUC= scores['test_roc_auc']                                                                     #Only works with binary classes, not multiclass                  \n",
    "    print(\"Gradient Boosting - Random Forest AUC: %0.2f (+/- %0.2f)\" % (scores_AUC.mean(), scores_AUC.std() * 2))                           \n",
    "    print(\"GB - CV Runtime:\", time.time()-start_ts)\n",
    "\n",
    "\n",
    "    #SciKit Ada Boosting - Cross Val\n",
    "    start_ts=time.time()\n",
    "    clf=AdaBoostClassifier(n_estimators=100, base_estimator=None, learning_rate=0.1, random_state=rand_st)\n",
    "    scores= cross_validate(clf, data_np, target_np, scoring=scorers, cv=5)\n",
    "\n",
    "    scores_Acc = scores['test_Accuracy']                                                                                                                                    \n",
    "    print(\"Ada Boost - Random Forest Acc: %0.2f (+/- %0.2f)\" % (scores_Acc.mean(), scores_Acc.std() * 2))                                                                                                    \n",
    "    scores_AUC= scores['test_roc_auc']                                                                     #Only works with binary classes, not multiclass                  \n",
    "    print(\"Ada Boost - Random Forest AUC: %0.2f (+/- %0.2f)\" % (scores_AUC.mean(), scores_AUC.std() * 2))                           \n",
    "    print(\"Ada - CV Runtime:\", time.time()-start_ts)\n",
    "\n",
    "\n",
    "    #SciKit Neural Network - Cross Val\n",
    "    start_ts=time.time()\n",
    "    clf=MLPClassifier(activation='logistic', solver='adam', alpha=0.0001, max_iter=1000, hidden_layer_sizes=(10,), random_state=rand_st)\n",
    "    scores= cross_validate(clf, data_np, target_np, scoring=scorers, cv=5)\n",
    "\n",
    "    scores_Acc = scores['test_Accuracy']                                                                                                                                    \n",
    "    print(\"Neural Network - Acc: %0.2f (+/- %0.2f)\" % (scores_Acc.mean(), scores_Acc.std() * 2))                                                                                                    \n",
    "    scores_AUC= scores['test_roc_auc']                                                                     #Only works with binary classes, not multiclass                  \n",
    "    print(\"Neural Network - AUC: %0.2f (+/- %0.2f)\" % (scores_AUC.mean(), scores_AUC.std() * 2))                           \n",
    "    print(\"NN - CV Runtime:\", time.time()-start_ts) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CpP6dxuS3OFB"
   },
   "source": [
    "## Support Vector Machines - Dataset too Large - Stuck on Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a13nw6p94D6a",
    "outputId": "dde4d03e-ef2d-4a74-ac5a-755c87e19c11"
   },
   "outputs": [],
   "source": [
    "#SciKit DSC540 HW4\n",
    "'''created by Casey Bennett 2018, www.CaseyBennett.com'''\n",
    "\n",
    "import sys\n",
    "import csv\n",
    "import math\n",
    "import numpy as np\n",
    "from operator import itemgetter\n",
    "import time\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.feature_selection import RFE, VarianceThreshold, SelectFromModel\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression, mutual_info_classif, chi2\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "from sklearn.preprocessing import KBinsDiscretizer, scale\n",
    "\n",
    "#Handle annoying warnings\n",
    "import warnings, sklearn.exceptions\n",
    "warnings.filterwarnings(\"ignore\", category=sklearn.exceptions.ConvergenceWarning)\n",
    "\n",
    "\n",
    "\n",
    "#############################################################################\n",
    "#\n",
    "# Global parameters\n",
    "#\n",
    "#####################\n",
    "\n",
    "target_idx=0                                        #Index of Target variable\n",
    "cross_val=1                                         #Control Switch for CV                                                                                                                                                      \n",
    "norm_target=0                                       #Normalize target switch\n",
    "norm_features=0                                     #Normalize target switch\n",
    "binning=1                                           #Control Switch for Bin Target\n",
    "bin_cnt=2                                           #If bin target, this sets number of classes\n",
    "feat_select=1                                       #Control Switch for Feature Selection                                                                                   \n",
    "fs_type=2                                           #Feature Selection type (1=Stepwise Backwards Removal, 2=Wrapper Select, 3=Univariate Selection)                        \n",
    "lv_filter=0                                         #Control switch for low variance filter on features\n",
    "feat_start=1                                        #Start column of features\n",
    "k_cnt=5                                             #Number of 'Top k' best ranked features to select, only applies for fs_types 1 and 3\n",
    "\n",
    "#Set global model parameters\n",
    "rand_st=1                                           #Set Random State variable for randomizing splits on runs\n",
    "\n",
    "\n",
    "#############################################################################\n",
    "#\n",
    "# Load Data\n",
    "#\n",
    "#####################\n",
    "\n",
    "file1= csv.reader(open('brfss2015_5050_cleaned.csv'), delimiter=',', quotechar='\"')\n",
    "\n",
    "#Read Header Line\n",
    "header=next(file1)            \n",
    "\n",
    "#Read data\n",
    "data=[]\n",
    "target=[]\n",
    "for row in file1:\n",
    "    #Load Target\n",
    "    if row[target_idx]=='':                         #If target is blank, skip row                       \n",
    "        continue\n",
    "    else:\n",
    "        target.append(float(row[target_idx]))       #If pre-binned class, change float to int\n",
    "\n",
    "    #Load row into temp array, cast columns  \n",
    "    temp=[]\n",
    "                 \n",
    "    for j in range(feat_start,len(header)):\n",
    "        if row[j]=='':\n",
    "            temp.append(float())\n",
    "        else:\n",
    "            temp.append(float(row[j]))\n",
    "\n",
    "    #Load temp into Data array\n",
    "    data.append(temp)\n",
    "  \n",
    "#Test Print\n",
    "print(header)\n",
    "print(len(target),len(data))\n",
    "print('\\n')\n",
    "\n",
    "data_np=np.asarray(data)\n",
    "target_np=np.asarray(target)\n",
    "\n",
    "\n",
    "#############################################################################\n",
    "#\n",
    "# Preprocess data\n",
    "#\n",
    "##########################################\n",
    "\n",
    "if norm_target==1:\n",
    "    #Target normalization for continuous values\n",
    "    target_np=scale(target_np)\n",
    "\n",
    "if norm_features==1:\n",
    "    #Feature normalization for continuous values\n",
    "    data_np=scale(data_np)\n",
    "\n",
    "'''if binning==1:\n",
    "    #Discretize Target variable with KBinsDiscretizer\n",
    "    enc = KBinsDiscretizer(n_bins=[bin_cnt], encode='ordinal', strategy='quantile')                         #Strategy here is important, quantile creating equal bins, but kmeans prob being more valid \"clusters\"\n",
    "    target_np_bin = enc.fit_transform(target_np.reshape(-1,1))\n",
    "\n",
    "    #Get Bin min/max\n",
    "    temp=[[] for x in range(bin_cnt+1)]\n",
    "    for i in range(len(target_np)):\n",
    "        for j in range(bin_cnt):\n",
    "            if target_np_bin[i]==j:\n",
    "                temp[j].append(target_np[i])\n",
    "\n",
    "    for j in range(bin_cnt):\n",
    "        print('Bin', j, ':', min(temp[j]), max(temp[j]), len(temp[j]))\n",
    "    print('\\n')\n",
    "\n",
    "    #Convert Target array back to correct shape\n",
    "    target_np=np.ravel(target_np_bin)'''\n",
    "\n",
    "\n",
    "#############################################################################\n",
    "#\n",
    "# Feature Selection\n",
    "#\n",
    "##########################################\n",
    "\n",
    "#Low Variance Filter\n",
    "if lv_filter==1:\n",
    "    print('--LOW VARIANCE FILTER ON--', '\\n')\n",
    "    \n",
    "    #LV Threshold\n",
    "    sel = VarianceThreshold(threshold=0.5)                                      #Removes any feature with less than 20% variance\n",
    "    fit_mod=sel.fit(data_np)\n",
    "    fitted=sel.transform(data_np)\n",
    "    sel_idx=fit_mod.get_support()\n",
    "\n",
    "    #Get lists of selected and non-selected features (names and indexes)\n",
    "    temp=[]\n",
    "    temp_idx=[]\n",
    "    temp_del=[]\n",
    "    for i in range(len(data_np[0])):\n",
    "        if sel_idx[i]==1:                                                           #Selected Features get added to temp header\n",
    "            temp.append(header[i+feat_start])\n",
    "            temp_idx.append(i)\n",
    "        else:                                                                       #Indexes of non-selected features get added to delete array\n",
    "            temp_del.append(i)\n",
    "\n",
    "    print('Selected', temp)\n",
    "    print('Features (total, selected):', len(data_np[0]), len(temp))\n",
    "    print('\\n')\n",
    "\n",
    "    #Filter selected columns from original dataset\n",
    "    header = header[0:feat_start]\n",
    "    for field in temp:\n",
    "        header.append(field)\n",
    "    data_np = np.delete(data_np, temp_del, axis=1)                                 #Deletes non-selected features by index\n",
    "\n",
    "\n",
    "#Feature Selection\n",
    "if feat_select==1:\n",
    "    '''Three steps:\n",
    "       1) Run Feature Selection\n",
    "       2) Get lists of selected and non-selected features\n",
    "       3) Filter columns from original dataset\n",
    "       '''\n",
    "    \n",
    "    print('--FEATURE SELECTION ON--', '\\n')\n",
    "    \n",
    "    ##1) Run Feature Selection #######\n",
    "    if fs_type==1:\n",
    "        #Stepwise Recursive Backwards Feature removal\n",
    "        if binning==1:\n",
    "            clf = RandomForestClassifier(n_estimators=200, max_depth=None, min_samples_split=3, criterion='entropy', random_state=rand_st)\n",
    "            sel = RFE(clf, n_features_to_select=k_cnt, step=.1)\n",
    "            print('Stepwise Recursive Backwards - Random Forest: ')\n",
    "        if binning==0:\n",
    "            rgr = RandomForestRegressor(n_estimators=500, max_depth=None, min_samples_split=3, criterion='mse', random_state=rand_st)\n",
    "            sel = RFE(rgr, n_features_to_select=k_cnt, step=.1)\n",
    "            print('Stepwise Recursive Backwards - Random Forest: ')\n",
    "            \n",
    "        fit_mod=sel.fit(data_np, target_np)\n",
    "        print(sel.ranking_)\n",
    "        sel_idx=fit_mod.get_support()      \n",
    "\n",
    "    if fs_type==2:\n",
    "        #Wrapper Select via model\n",
    "        if binning==1:\n",
    "            clf = SVC(kernel='linear', gamma='scale', C=1.0, probability=True, random_state=rand_st)\n",
    "            sel = SelectFromModel(clf, prefit=False, threshold='mean', max_features=None)                                                           #to select only based on max_features, set to integer value and set threshold=-np.inf\n",
    "            print ('Wrapper Select: ')\n",
    "        if binning==0:\n",
    "            rgr = '''Unused in this homework'''\n",
    "            sel = SelectFromModel(rgr, prefit=False, threshold='mean', max_features=None)\n",
    "            print ('Wrapper Select: ')\n",
    "            \n",
    "        fit_mod=sel.fit(data_np, target_np)    \n",
    "        sel_idx=fit_mod.get_support()\n",
    "\n",
    "    if fs_type==3:\n",
    "        if binning==1:                                                              ######Only work if the Target is binned###########\n",
    "            #Univariate Feature Selection - Chi-squared\n",
    "            sel=SelectKBest(chi2, k=k_cnt)\n",
    "            fit_mod=sel.fit(data_np, target_np)                                         #will throw error if any negative values in features, so turn off feature normalization, or switch to mutual_info_classif\n",
    "            print ('Univariate Feature Selection - Chi2: ')\n",
    "            sel_idx=fit_mod.get_support()\n",
    "\n",
    "        if binning==0:                                                              ######Only work if the Target is continuous###########\n",
    "            #Univariate Feature Selection - Mutual Info Regression\n",
    "            sel=SelectKBest(mutual_info_regression, k=k_cnt)\n",
    "            fit_mod=sel.fit(data_np, target_np)\n",
    "            print ('Univariate Feature Selection - Mutual Info: ')\n",
    "            sel_idx=fit_mod.get_support()\n",
    "\n",
    "        #Print ranked variables out sorted\n",
    "        temp=[]\n",
    "        scores=fit_mod.scores_\n",
    "        for i in range(feat_start, len(header)):            \n",
    "            temp.append([header[i], float(scores[i-feat_start])])\n",
    "\n",
    "        print('Ranked Features')\n",
    "        temp_sort=sorted(temp, key=itemgetter(1), reverse=True)\n",
    "        for i in range(len(temp_sort)):\n",
    "            print(i, temp_sort[i][0], ':', temp_sort[i][1])\n",
    "        print('\\n')\n",
    "\n",
    "    ##2) Get lists of selected and non-selected features (names and indexes) #######\n",
    "    temp=[]\n",
    "    temp_idx=[]\n",
    "    temp_del=[]\n",
    "    for i in range(len(data_np[0])):\n",
    "        if sel_idx[i]==1:                                                           #Selected Features get added to temp header\n",
    "            temp.append(header[i+feat_start])\n",
    "            temp_idx.append(i)\n",
    "        else:                                                                       #Indexes of non-selected features get added to delete array\n",
    "            temp_del.append(i)\n",
    "    print('Selected', temp)\n",
    "    print('Features (total/selected):', len(data_np[0]), len(temp))\n",
    "    print('\\n')\n",
    "            \n",
    "                \n",
    "    ##3) Filter selected columns from original dataset #########\n",
    "    header = header[0:feat_start]\n",
    "    for field in temp:\n",
    "        header.append(field)\n",
    "    data_np = np.delete(data_np, temp_del, axis=1)                                 #Deletes non-selected features by index)\n",
    "    \n",
    "    \n",
    "\n",
    "#############################################################################\n",
    "#\n",
    "# Train SciKit Models\n",
    "#\n",
    "##########################################\n",
    "\n",
    "print('--ML Model Output--', '\\n')\n",
    "\n",
    "#Test/Train split\n",
    "data_train, data_test, target_train, target_test = train_test_split(data_np, target_np, test_size=0.35)\n",
    "\n",
    "####Classifiers####\n",
    "if binning==1 and cross_val==0:\n",
    "    #SciKit\n",
    "    '''Test/Train split unused in this homework, skip down to CV section'''\n",
    " \n",
    "\n",
    "                                                                                                                         \n",
    " \n",
    "####Cross-Val Classifiers####\n",
    "if binning==1 and cross_val==1:\n",
    "    #Setup Crossval classifier scorers\n",
    "    scorers = {'Accuracy': 'accuracy', 'roc_auc': 'roc_auc'}                                                                                                                \n",
    "    \n",
    "    #SciKit RBF - SVM - Cross Val\n",
    "#    start_ts=time.time()\n",
    "#    clf=SVC(kernel='rbf', gamma='scale', C=1.0, probability=True, random_state=rand_st)\n",
    "#    scores=cross_validate(clf, data_np, target_np, scoring=scorers, cv=5)\n",
    "\n",
    "#    scores_Acc = scores['test_Accuracy']                                                                                                                                    \n",
    "#    print(\"RBF-SVM Acc: %0.2f (+/- %0.2f)\" % (scores_Acc.mean(), scores_Acc.std() * 2))                                                                                                    \n",
    "#    scores_AUC= scores['test_roc_auc']                                                                     #Only works with binary classes, not multiclass                  \n",
    "#    print(\"RBF-SVM AUC: %0.2f (+/- %0.2f)\" % (scores_AUC.mean(), scores_AUC.std() * 2))                           \n",
    "#    print(\"RBF-SVM CV Runtime:\", time.time()-start_ts)\n",
    "\n",
    "    #SciKit Linear - SVM - Cross Val\n",
    "    start_ts=time.time()\n",
    "    clf=SVC(kernel='linear', gamma='scale', C=1.0, probability=True, random_state=rand_st)\n",
    "    scores=cross_validate(clf, data_np, target_np, scoring=scorers, cv=5)\n",
    "\n",
    "    scores_Acc = scores['test_Accuracy']                                                                                                                                    \n",
    "    print(\"Linear-SVM Acc: %0.2f (+/- %0.2f)\" % (scores_Acc.mean(), scores_Acc.std() * 2))                                                                                                    \n",
    "    scores_AUC= scores['test_roc_auc']                                                                     #Only works with binary classes, not multiclass                  \n",
    "    print(\"Linear-SVM AUC: %0.2f (+/- %0.2f)\" % (scores_AUC.mean(), scores_AUC.std() * 2))                           \n",
    "    print(\"Linear-CV Runtime:\", time.time()-start_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gmHg-K0g87it"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DSC540_FinalProject_AlexTeboul.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
